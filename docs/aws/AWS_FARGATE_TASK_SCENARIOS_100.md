# üì¶ CloudWaste - Couverture 100% AWS Fargate Tasks

CloudWaste d√©tecte maintenant **100% des sc√©narios de gaspillage** pour AWS Fargate (Serverless Containers) !

## üéØ Sc√©narios Couverts (10/10 = 100%)

### Phase 1 - D√©tection Simple (5 sc√©narios - M√©tadonn√©es + ECS/CloudWatch APIs)
1. ‚úÖ **fargate_stopped_tasks** - Tasks Arr√™t√©es Jamais Supprim√©es (STOPPED > 30 Jours)
2. ‚úÖ **fargate_idle_tasks** - Tasks Running Mais Sans Traffic (0 NetworkIn/Out > 7 Jours)
3. ‚úÖ **fargate_over_provisioned** - CPU/Memory Over-Provisioned (<10% Utilization > 30 Jours)
4. ‚úÖ **fargate_inactive_services** - Services ECS √† 0 Desired Count (Inactifs > 90 Jours)
5. ‚úÖ **fargate_no_spot** - Pas de Fargate Spot (100% On-Demand ‚Üí Surco√ªt 70%)

### Phase 2 - Optimisation Avanc√©e (5 sc√©narios - CloudWatch + Cost Optimization)
6. ‚úÖ **fargate_excessive_logs** - CloudWatch Logs Retention Excessive (>90 Jours)
7. ‚úÖ **fargate_ec2_opportunity** - Wrong Compute Type (Workloads 24/7 Mieux sur EC2)
8. ‚úÖ **fargate_standalone_orphaned** - Tasks Standalone Jamais Nettoy√©es (RunTask Sans Service)
9. ‚úÖ **fargate_bad_autoscaling** - Auto Scaling Mal Configur√© (Target <30% ou >70%)
10. ‚úÖ **fargate_outdated_platform** - Platform Version Obsol√®te (< LATEST-1 ‚Üí S√©curit√© + Bugs)

---

## üìã Introduction

**AWS Fargate** est un moteur de calcul serverless pour containers qui √©limine la gestion de l'infrastructure EC2. Fargate fonctionne avec:
- **Amazon ECS** (Elastic Container Service) - Orchestration AWS native
- **Amazon EKS** (Elastic Kubernetes Service) - Kubernetes manag√©

Malgr√© son approche serverless, Fargate repr√©sente une **source majeure de gaspillage cloud**:

- **Co√ªt √©lev√© vs EC2**: 30-50% plus cher que EC2 Spot pour workloads 24/7
- **Over-provisioning facile**: Tasks avec CPU/Memory mal dimensionn√©s ‚Üí surco√ªt 200-300%
- **Fargate Spot sous-utilis√©**: 70% d'√©conomies ignor√©es (Spot vs On-Demand)
- **Services inactifs oubli√©s**: Services ECS desired=0 mais load balancers actifs ‚Üí $20-50/mois gaspill√©s
- **Logs retention excessive**: CloudWatch Logs indefinite ‚Üí $0.50/GB/mois √ó accumulation

### Pourquoi Fargate est critique ?

| Probl√®me | Impact Annuel (Organisation 200 Tasks, Avg 1 vCPU + 2 GB) |
|----------|-----------------------------------------------------------|
| Tasks idle (10%) | 20 tasks √ó $35.86/mois = **$7,000/an** üî¥ |
| Over-provisioned (40%) | 80 tasks √ó right-size 70% = **$28,000/an** üî¥ |
| No Fargate Spot (50%) | 100 tasks √ó 70% savings = **$29,400/an** üî¥ |
| Services inactifs (5%) | 10 services √ó $20 ALB = **$1,200/an** üü° |
| STOPPED tasks (pollution) | Cleanup namespace | üü¢ |
| Excessive logs (20%) | 40 tasks √ó 5 GB √ó $0.50 √ó 12 = **$1,200/an** üü° |
| Wrong compute (15%) | 30 tasks ‚Üí EC2 30% savings = **$6,300/an** üî¥ |
| Standalone orphaned (5%) | 10 tasks √ó $35/mois = **$1,800/an** üü° |
| Bad autoscaling (20%) | 40 tasks √ó over-scaled 30% = **$5,000/an** üü¢ |
| Outdated platform | Security risk (no direct cost) | üü¢ |
| **TOTAL** | **~$80,000/an** üí∞ |

---

## üí∞ Pricing AWS Fargate

### Fargate On-Demand Pricing (us-east-1)

| Ressource | Co√ªt par heure | Co√ªt mensuel (730h) | Use Case |
|-----------|----------------|---------------------|----------|
| **1 vCPU** | **$0.04048** | **$29.55** | Baseline compute |
| **1 GB Memory** | **$0.004445** | **$3.24** | Baseline memory |

### Exemples de Configurations Typiques

| Config | vCPU | Memory | Co√ªt/Heure | Co√ªt/Mois (730h) | Co√ªt/An |
|--------|------|--------|-----------|------------------|---------|
| **Micro** | 0.25 | 0.5 GB | $0.01234 | **$9.01** | $108 |
| **Small** | 0.5 | 1 GB | $0.02468 | **$18.02** | $216 |
| **Medium** | 1 | 2 GB | **$0.04937** | **$36.04** | $432 |
| **Large** | 2 | 4 GB | $0.09874 | **$72.08** | $865 |
| **XLarge** | 4 | 8 GB | $0.19748 | **$144.16** | $1,730 |

### Fargate Spot Pricing (-70% vs On-Demand)

| Config | On-Demand | **Fargate Spot** | √âconomie/Mois | √âconomie/An |
|--------|-----------|------------------|---------------|-------------|
| 1 vCPU + 2 GB | $36.04 | **$10.81** | **$25.23** | **$303** üéâ |
| 2 vCPU + 4 GB | $72.08 | **$21.62** | **$50.46** | **$606** üéâ |
| 4 vCPU + 8 GB | $144.16 | **$43.25** | **$100.91** | **$1,211** üéâ |

üí° **Fargate Spot = -70% de co√ªt** (tasks interruptibles, ideal pour batch processing, dev/staging)

---

### Fargate vs EC2 Cost Comparison

| Workload Type | Fargate On-Demand | Fargate Spot | EC2 On-Demand | EC2 Spot | Meilleur Choix |
|---------------|-------------------|--------------|---------------|----------|----------------|
| **Short-lived (<4h)** | $0.20 | $0.06 | $0.15 + overhead | N/A | **Fargate Spot** ‚úÖ |
| **Intermittent (4-12h)** | $0.50 | $0.15 | $0.30 + overhead | $0.10 | **Fargate Spot** ‚úÖ |
| **24/7 Production** | $36/mois | $11/mois | $25/mois | **$8/mois** | **EC2 Spot** ‚úÖ |
| **Batch Processing** | $0.50/batch | **$0.15/batch** | $0.30 | $0.10 | **Fargate Spot** ‚úÖ |

üí° **R√®gle g√©n√©rale**:
- **Fargate**: Workloads sporadiques, event-driven, auto-scaling fr√©quent
- **EC2**: Workloads 24/7, predicable, long-running (>95% uptime)

---

### ECS vs EKS avec Fargate

| Feature | ECS (Native AWS) | EKS (Kubernetes) | Diff√©rence |
|---------|------------------|------------------|------------|
| **Control Plane Cost** | **Gratuit** üéâ | **$73/mois** üî¥ | EKS = +$876/an |
| **Task Pricing** | Identique | Identique | M√™me co√ªt Fargate |
| **Overhead** | Minimal | K8s complexity | ECS plus simple |
| **Portability** | Locked-in AWS | Multi-cloud | K8s portable |
| **Use Case** | AWS-only, simplicit√© | Multi-cloud, K8s ecosystem | D√©pend strat√©gie |

üí° **EKS Control Plane** = $73/mois √ó 12 = **$876/an de surco√ªt** vs ECS (si mono-AWS)

---

## üîç Sc√©nario 1: Tasks Arr√™t√©es Jamais Supprim√©es (STOPPED > 30 Jours)

### üìã Description du Probl√®me

Lorsqu'une **Fargate task** est arr√™t√©e (manuellement, par scaling, ou par erreur), elle passe √† l'√©tat **STOPPED** mais n'est **PAS automatiquement supprim√©e** par AWS. Ces tasks STOPPED restent dans le namespace ECS ind√©finiment, cr√©ant:

- **Pollution du namespace**: Difficile de distinguer tasks actives vs anciennes
- **Confusion op√©rationnelle**: Logs/metadata de tasks obsol√®tes
- **Audit complexe**: 500+ STOPPED tasks m√©lang√©es aux actives
- **Pas de co√ªt direct** (mais overhead management)

### üî¥ Sc√©narios de Gaspillage

1. **Scaling down** ‚Üí Tasks stopped mais jamais nettoy√©es (auto-scaling)
2. **Deployments** ‚Üí Anciens task definitions stopped (rolling updates)
3. **Tests/Debug** ‚Üí Tasks manuelles stopped puis oubli√©es
4. **Services supprim√©s** ‚Üí Tasks stopped du service persistent
5. **Erreurs** ‚Üí Tasks crash√©es en STOPPED (jamais investigated)

---

## üí∞ Impact Financier

### Co√ªt Direct: $0/mois

Les tasks STOPPED ne consomment **aucune ressource compute** (pas de vCPU/Memory factur√©s).

### Co√ªt Indirect: Op√©rationnel

```
Entreprise avec 1,000 STOPPED tasks (sur 200 services ECS):

Probl√®mes:
  - Namespace pollution: aws ecs list-tasks retourne 1,200 tasks (1,000 STOPPED + 200 RUNNING)
  - Filtering required: Tous les scripts doivent filter --desired-status RUNNING
  - Audit complexity: Impossible de savoir quelles tasks sont importantes
  - Log retention: CloudWatch Logs de 1,000 tasks STOPPED conserv√©s (si retention indefinite)

Overhead Op√©rationnel:
  - Temps ing√©nieur: 2h/semaine √ó $100/h = $200/semaine = $800/mois
  - Scripts custom filtering: Maintenance overhead
  - Monitoring complexity: 1,000 tasks STOPPED = noise dans m√©triques

üí∞ Co√ªt Indirect: ~$10,000/an (temps ing√©nieur + complexit√©)
```

---

## üîç D√©tection du Gaspillage

### Crit√®res de D√©tection

1. **Task status = STOPPED**
2. **Stopped since > 30 jours** (configurble: `stopped_tasks_min_age_days`)
3. **Task NOT associated with active service** (standalone tasks)
4. **No recent investigation** (pas de CloudWatch Logs access)

### üìä Exemple Concret

```
Task ARN:          arn:aws:ecs:us-east-1:123456789012:task/prod-cluster/abc123def456
Task Definition:   web-app:47
Cluster:           prod-cluster
Launch Type:       FARGATE
Desired Status:    STOPPED
Last Status:       STOPPED
Stopped At:        2024-04-15 14:23:00 UTC (205 days ago) üî¥

Stop Reason:       "Task failed health checks" (ELB health check failure)
Stop Code:         TaskFailedToStart

Task Configuration:
  - vCPU: 1.0
  - Memory: 2 GB
  - Container: web-app:v2.3.1

Created At:        2024-04-15 14:20:00 UTC
Started At:        2024-04-15 14:21:30 UTC
Stopped At:        2024-04-15 14:23:00 UTC (ran for 90 seconds)

Associated Service: web-app-service (DELETED 2024-05-01)

Timeline:
  - April 15, 2024: Task started for deployment test
  - April 15, 2024: Health check failed ‚Üí STOPPED
  - May 1, 2024: Service deleted (migration to new service)
  - Today (Nov 5, 2024): Task STOPPED still exists (205 days) üî¥

üî¥ WASTE DETECTED: STOPPED task (205 days) never cleaned up
üí∞ COST: $0/direct (operational overhead)
üìã ACTION: DELETE task definition revision (cleanup namespace)
üí° ROOT CAUSE: No automatic cleanup policy for STOPPED tasks
```

---

## üêç Impl√©mentation Python

### Code de D√©tection

```python
async def scan_fargate_stopped_tasks(
    region: str,
    stopped_tasks_min_age_days: int = 30,
    min_age_days: int = 7
) -> List[Dict]:
    """
    D√©tecte les Fargate tasks STOPPED jamais supprim√©es.

    Analyse:
    - Task lastStatus = STOPPED
    - stoppedAt > stopped_tasks_min_age_days
    - Identifie tasks standalone (sans service parent)

    Args:
        region: R√©gion AWS
        stopped_tasks_min_age_days: √Çge minimum STOPPED (d√©faut: 30 jours)
        min_age_days: √Çge minimum de la task (d√©faut: 7 jours)

    Returns:
        Liste des tasks STOPPED avec m√©tadonn√©es
    """
    orphans = []

    ecs_client = boto3.client('ecs', region_name=region)

    try:
        # 1. Liste tous les clusters ECS
        clusters_resp = await ecs_client.list_clusters()
        cluster_arns = clusters_resp.get('clusterArns', [])

        logger.info(f"Found {len(cluster_arns)} ECS clusters in {region}")

        # 2. Pour chaque cluster, liste les tasks
        for cluster_arn in cluster_arns:
            try:
                # Liste tasks STOPPED (max 100 √† la fois)
                tasks_resp = await ecs_client.list_tasks(
                    cluster=cluster_arn,
                    desiredStatus='STOPPED',
                    maxResults=100
                )

                task_arns = tasks_resp.get('taskArns', [])

                if not task_arns:
                    continue

                # Describe tasks pour obtenir d√©tails
                tasks_desc = await ecs_client.describe_tasks(
                    cluster=cluster_arn,
                    tasks=task_arns
                )

                tasks = tasks_desc.get('tasks', [])

                # Analyse chaque task STOPPED
                for task in tasks:
                    try:
                        stopped_at = task.get('stoppedAt')
                        created_at = task.get('createdAt')
                        task_arn = task.get('taskArn')
                        task_definition = task.get('taskDefinitionArn')
                        launch_type = task.get('launchType', 'UNKNOWN')

                        # Filtrer: Fargate uniquement
                        if launch_type != 'FARGATE':
                            continue

                        # Calcule √¢ge de la task
                        if not stopped_at:
                            continue

                        age_days = (datetime.now(timezone.utc) - stopped_at).days

                        # Filtre: √¢ge minimum
                        if age_days < stopped_tasks_min_age_days:
                            continue

                        # M√©tadonn√©es
                        stop_reason = task.get('stopCode', 'UNKNOWN')
                        stop_code_reason = task.get('stoppedReason', 'Unknown')
                        group_name = task.get('group', '')
                        service_name = group_name.replace('service:', '') if 'service:' in group_name else None

                        # V√©rifier si service parent existe encore
                        service_exists = False
                        if service_name:
                            try:
                                service_desc = await ecs_client.describe_services(
                                    cluster=cluster_arn,
                                    services=[service_name]
                                )
                                services = service_desc.get('services', [])
                                service_exists = len(services) > 0 and services[0].get('status') == 'ACTIVE'

                            except Exception:
                                service_exists = False

                        # Niveau de confiance
                        if age_days >= 180:
                            confidence = "critical"
                        elif age_days >= 90:
                            confidence = "high"
                        else:
                            confidence = "medium"

                        # M√©tadonn√©es
                        metadata = {
                            "task_arn": task_arn,
                            "task_definition": task_definition,
                            "cluster_arn": cluster_arn,
                            "cluster_name": cluster_arn.split('/')[-1],
                            "launch_type": launch_type,
                            "stopped_at": stopped_at.isoformat(),
                            "age_days": age_days,
                            "stop_reason": stop_reason,
                            "stop_code_reason": stop_code_reason,
                            "service_name": service_name,
                            "service_exists": service_exists,
                            "confidence": confidence
                        }

                        # Co√ªt estim√©: $0 direct
                        monthly_cost = 0.0

                        orphan = {
                            "resource_id": task_arn,
                            "resource_name": f"{task_definition.split('/')[-1]} (STOPPED)",
                            "resource_type": "fargate_task",
                            "region": region,
                            "orphan_type": "stopped_task",
                            "estimated_monthly_cost": round(monthly_cost, 2),
                            "metadata": metadata,
                            "detection_timestamp": datetime.now(timezone.utc).isoformat()
                        }

                        orphans.append(orphan)

                        logger.info(
                            f"STOPPED Fargate task: {task_definition.split('/')[-1]} "
                            f"(stopped {age_days} days ago)"
                        )

                    except Exception as e:
                        logger.error(f"Error analyzing task {task.get('taskArn')}: {e}")
                        continue

            except ClientError as e:
                error_code = e.response.get('Error', {}).get('Code', '')
                logger.error(f"Error listing tasks for cluster {cluster_arn}: {error_code}")
                continue

        logger.info(f"Found {len(orphans)} STOPPED Fargate tasks in {region}")
        return orphans

    except Exception as e:
        logger.error(f"Error scanning Fargate STOPPED tasks in {region}: {e}")
        raise
```

---

## üß™ Test Unitaire

```python
import pytest
from moto import mock_ecs
import boto3
from datetime import datetime, timedelta, timezone

@mock_ecs
async def test_scan_fargate_stopped_tasks():
    """Test de d√©tection des Fargate tasks STOPPED."""

    region = 'us-east-1'

    # Setup
    ecs = boto3.client('ecs', region_name=region)

    # Cr√©er cluster
    cluster_resp = ecs.create_cluster(clusterName='test-cluster')
    cluster_arn = cluster_resp['cluster']['clusterArn']

    # Enregistrer task definition
    ecs.register_task_definition(
        family='web-app',
        requiresCompatibilities=['FARGATE'],
        networkMode='awsvpc',
        cpu='256',
        memory='512',
        containerDefinitions=[
            {
                'name': 'web',
                'image': 'nginx:latest',
                'memory': 512
            }
        ]
    )

    # Note: moto ne supporte pas compl√®tement run_task avec Fargate
    # Dans un vrai test, on cr√©erait des tasks STOPPED

    # Ex√©cution
    orphans = await scan_fargate_stopped_tasks(
        region=region,
        stopped_tasks_min_age_days=30,
        min_age_days=7
    )

    # V√©rifications
    # Note: moto limitations - dans un environnement r√©el:

    # 1. V√©rifier detection tasks STOPPED
    # stopped_tasks = [o for o in orphans if o['orphan_type'] == 'stopped_task']
    # assert len(stopped_tasks) > 0, "STOPPED tasks should be detected"

    # 2. V√©rifier m√©tadonn√©es
    for orphan in orphans:
        assert orphan['metadata']['launch_type'] == 'FARGATE'
        assert orphan['metadata']['age_days'] >= 30
        assert orphan['estimated_monthly_cost'] == 0  # Pas de co√ªt direct

    print(f"‚úÖ Test passed: {len(orphans)} STOPPED tasks detected")
```

---

## ‚úÖ Recommandations

1. **Automatic Cleanup Policy** (EventBridge + Lambda):
   ```python
   # Lambda triggered daily
   # Delete STOPPED tasks > 30 days
   for task in stopped_tasks:
       if task['age_days'] > 30 and not task['service_exists']:
           # Safe to delete (no parent service)
           delete_stopped_task(task_arn)
   ```

2. **Lifecycle Management**:
   - **STOPPED tasks**: Auto-delete after 30 days (configurable)
   - **Failed tasks**: Investigate within 7 days ‚Üí delete after 14 days
   - **Standalone tasks**: Delete immediately after completion

3. **Tagging Strategy**:
   ```json
   {
     "Environment": "production",
     "Owner": "platform-team",
     "AutoCleanup": "true",
     "RetentionDays": "30"
   }
   ```

4. **Monitoring**:
   - CloudWatch metric: Custom metric `StoppedTasksCount`
   - Alert si > 100 STOPPED tasks dans cluster

---

# ‚ö° Sc√©nario 2: Tasks Idle (Running Mais 0 Traffic R√©seau)

## üìã Description du Probl√®me

Une **Fargate task idle** est une task en √©tat **RUNNING** mais qui ne traite **aucun traffic r√©seau** depuis 7+ jours. Ces tasks consomment des ressources (vCPU/Memory) **24/7** sans g√©n√©rer aucune valeur business.

### üî¥ Causes Typiques

1. **Services oubli√©s apr√®s tests** ‚Üí Task running mais plus utilis√©e
2. **Backend workers sans jobs** ‚Üí Queue vide depuis semaines
3. **API deprecated** ‚Üí Ancien endpoint plus appel√©
4. **Scaling mal configur√©** ‚Üí Min tasks = 1 m√™me si 0 traffic
5. **Migration incompl√®te** ‚Üí Ancien service running pendant migration

---

## üí∞ Impact Financier

### Calcul du Co√ªt

**Formule**:
```
Co√ªt Idle Task = (vCPU √ó $0.04048 + Memory GB √ó $0.004445) √ó 730 heures/mois
```

**Exemple: Task 1 vCPU + 2 GB idle**

```
Configuration:
  - vCPU: 1.0
  - Memory: 2 GB
  - √âtat: RUNNING 24/7
  - Traffic: 0 bytes IN/OUT (7 derniers jours)

Co√ªt Mensuel:
  - vCPU: 1.0 √ó $0.04048 √ó 730h = $29.55/mois
  - Memory: 2 GB √ó $0.004445 √ó 730h = $6.49/mois
  - TOTAL: $36.04/mois = $432/an üî¥

üí∞ GASPILLAGE: $432/an per idle task (100% waste)
```

### üìä Exemple R√©el: 20 Idle Tasks

```
Entreprise: SaaS B2B avec 200 Fargate tasks total

Audit r√©v√®le:
  - 20 tasks idle (10% du total)
  - Configuration moyenne: 1 vCPU + 2 GB
  - Co√ªt moyen: $36/task/mois

D√©tails des tasks idle:
  1. legacy-api-v1 (deprecated 6 mois ago) ‚Üí $36/mois
  2. batch-worker-old (queue vide) ‚Üí $36/mois
  3. test-service-staging (oubli√©e) ‚Üí $36/mois
  ... (17 autres tasks)

Co√ªt ACTUEL (idle tasks):
  20 tasks √ó $36/mois = $720/mois = $8,640/an üî¥

Co√ªt OPTIMIS√â (apr√®s cleanup):
  0 tasks idle = $0/mois ‚úÖ

üí∞ √âCONOMIE: $8,640/an (delete ou scale to 0)
```

---

## üîç D√©tection du Gaspillage

### Crit√®res de D√©tection

1. **Task status = RUNNING**
2. **Launch type = FARGATE**
3. **NetworkIn + NetworkOut = 0 bytes** (7 derniers jours via CloudWatch)
4. **Task age > 7 jours** (pas une task qui vient de d√©marrer)
5. **No active connections** (optional: v√©rifier ActiveConnectionCount si ALB/NLB)

### üìä Exemple Concret

```
Task ARN:          arn:aws:ecs:us-east-1:123456789012:task/prod-cluster/xyz789
Task Definition:   legacy-api:23
Cluster:           prod-cluster
Service:           legacy-api-service
Launch Type:       FARGATE
Desired Status:    RUNNING
Last Status:       RUNNING
Started At:        2024-03-10 09:15:00 UTC (240 days ago)

Task Configuration:
  - vCPU: 1.0
  - Memory: 2 GB
  - Platform Version: LATEST
  - Public IP: 54.123.45.67

CloudWatch Metrics (7 derniers jours):
  - NetworkIn: 0 bytes üî¥
  - NetworkOut: 0 bytes üî¥
  - CPUUtilization: 0.2% (idle)
  - MemoryUtilization: 15% (minimal baseline)

Load Balancer:
  - Target Group: legacy-api-tg
  - Health Status: Healthy ‚úÖ (responds to health checks)
  - Active Connections: 0 (7 jours)
  - Request Count: 0 requests (7 jours) üî¥

Service Configuration:
  - Desired Count: 1
  - Min Healthy Percent: 100
  - Auto Scaling: DISABLED

Timeline:
  - March 10, 2024: Task started (new deployment)
  - March 15, 2024: Last API request received
  - April 1, 2024: API v2 released (migration)
  - April - Nov 2024: 0 traffic (240 days idle) üî¥

Co√ªt Mensuel (idle):
  - vCPU: 1.0 √ó $0.04048 √ó 730h = $29.55/mois
  - Memory: 2 GB √ó $0.004445 √ó 730h = $6.49/mois
  - Load Balancer: ALB $16/mois (idle aussi)
  - TOTAL: $52.04/mois = $625/an üî¥

üî¥ WASTE DETECTED: Task idle (0 traffic for 240 days)
üí∞ COST: $52.04/mois = $625/an GASPILL√âS
üìã ACTION: Scale service to 0 OR delete service + task
üí° ROOT CAUSE: API v2 migration complete but v1 service not decommissioned
```

---

## üêç Impl√©mentation Python

### Code de D√©tection

```python
async def scan_fargate_idle_tasks(
    region: str,
    lookback_days: int = 7,
    min_age_days: int = 7
) -> List[Dict]:
    """
    D√©tecte les Fargate tasks idle (RUNNING mais 0 traffic r√©seau).

    Analyse:
    - Task lastStatus = RUNNING
    - NetworkIn + NetworkOut = 0 bytes (lookback_days)
    - Task age > min_age_days

    Args:
        region: R√©gion AWS
        lookback_days: P√©riode CloudWatch (d√©faut: 7 jours)
        min_age_days: √Çge minimum task (d√©faut: 7 jours)

    Returns:
        Liste des tasks idle avec co√ªts
    """
    orphans = []

    ecs_client = boto3.client('ecs', region_name=region)
    cloudwatch = boto3.client('cloudwatch', region_name=region)

    try:
        # 1. Liste clusters
        clusters_resp = await ecs_client.list_clusters()
        cluster_arns = clusters_resp.get('clusterArns', [])

        logger.info(f"Found {len(cluster_arns)} ECS clusters in {region}")

        # 2. Pour chaque cluster, liste tasks RUNNING
        for cluster_arn in cluster_arns:
            try:
                # Liste tasks RUNNING
                tasks_resp = await ecs_client.list_tasks(
                    cluster=cluster_arn,
                    desiredStatus='RUNNING',
                    maxResults=100
                )

                task_arns = tasks_resp.get('taskArns', [])

                if not task_arns:
                    continue

                # Describe tasks
                tasks_desc = await ecs_client.describe_tasks(
                    cluster=cluster_arn,
                    tasks=task_arns
                )

                tasks = tasks_desc.get('tasks', [])

                # Analyse chaque task RUNNING
                for task in tasks:
                    try:
                        started_at = task.get('startedAt')
                        task_arn = task.get('taskArn')
                        task_definition_arn = task.get('taskDefinitionArn')
                        launch_type = task.get('launchType', 'UNKNOWN')

                        # Filtrer: Fargate uniquement
                        if launch_type != 'FARGATE':
                            continue

                        # Calcule √¢ge de la task
                        if not started_at:
                            continue

                        age_days = (datetime.now(timezone.utc) - started_at).days

                        # Filtre: √¢ge minimum
                        if age_days < min_age_days:
                            continue

                        # R√©cup√®re task definition pour CPU/Memory
                        task_def_resp = await ecs_client.describe_task_definition(
                            taskDefinition=task_definition_arn
                        )
                        task_def = task_def_resp['taskDefinition']

                        cpu = int(task_def.get('cpu', '256'))  # CPU units (256 = 0.25 vCPU)
                        memory = int(task_def.get('memory', '512'))  # Memory MB

                        # Convertir CPU units ‚Üí vCPU
                        vcpu = cpu / 1024.0
                        memory_gb = memory / 1024.0

                        # CloudWatch metrics: NetworkIn + NetworkOut
                        end_time = datetime.now(timezone.utc)
                        start_time = end_time - timedelta(days=lookback_days)

                        # NetworkIn
                        network_in_metrics = await cloudwatch.get_metric_statistics(
                            Namespace='ECS/ContainerInsights',
                            MetricName='NetworkRxBytes',
                            Dimensions=[
                                {'Name': 'ClusterName', 'Value': cluster_arn.split('/')[-1]},
                                {'Name': 'TaskId', 'Value': task_arn.split('/')[-1]}
                            ],
                            StartTime=start_time,
                            EndTime=end_time,
                            Period=86400,  # 1 jour
                            Statistics=['Sum']
                        )

                        # NetworkOut
                        network_out_metrics = await cloudwatch.get_metric_statistics(
                            Namespace='ECS/ContainerInsights',
                            MetricName='NetworkTxBytes',
                            Dimensions=[
                                {'Name': 'ClusterName', 'Value': cluster_arn.split('/')[-1]},
                                {'Name': 'TaskId', 'Value': task_arn.split('/')[-1]}
                            ],
                            StartTime=start_time,
                            EndTime=end_time,
                            Period=86400,  # 1 jour
                            Statistics=['Sum']
                        )

                        total_network_in = sum(
                            point['Sum'] for point in network_in_metrics.get('Datapoints', [])
                        )
                        total_network_out = sum(
                            point['Sum'] for point in network_out_metrics.get('Datapoints', [])
                        )

                        total_network = total_network_in + total_network_out

                        # üî¥ D√âTECTION: 0 bytes network traffic
                        if total_network == 0:

                            # Calcule co√ªt mensuel
                            vcpu_cost = vcpu * 0.04048 * 730
                            memory_cost = memory_gb * 0.004445 * 730
                            monthly_cost = vcpu_cost + memory_cost

                            # Niveau de confiance
                            if age_days >= 90:
                                confidence = "critical"
                            elif age_days >= 30:
                                confidence = "high"
                            else:
                                confidence = "medium"

                            # M√©tadonn√©es
                            metadata = {
                                "task_arn": task_arn,
                                "task_definition": task_definition_arn.split('/')[-1],
                                "cluster_name": cluster_arn.split('/')[-1],
                                "vcpu": vcpu,
                                "memory_gb": round(memory_gb, 2),
                                "age_days": age_days,
                                "network_in_bytes_7d": int(total_network_in),
                                "network_out_bytes_7d": int(total_network_out),
                                "total_network_bytes": int(total_network),
                                "confidence": confidence
                            }

                            orphan = {
                                "resource_id": task_arn,
                                "resource_name": task_definition_arn.split('/')[-1],
                                "resource_type": "fargate_task",
                                "region": region,
                                "orphan_type": "idle_task",
                                "estimated_monthly_cost": round(monthly_cost, 2),
                                "metadata": metadata,
                                "detection_timestamp": datetime.now(timezone.utc).isoformat()
                            }

                            orphans.append(orphan)

                            logger.info(
                                f"Idle Fargate task: {task_definition_arn.split('/')[-1]} "
                                f"(0 network traffic, ${monthly_cost:.2f}/mois)"
                            )

                    except Exception as e:
                        logger.error(f"Error analyzing task {task.get('taskArn')}: {e}")
                        continue

            except ClientError as e:
                error_code = e.response.get('Error', {}).get('Code', '')
                logger.error(f"Error listing tasks for cluster {cluster_arn}: {error_code}")
                continue

        logger.info(f"Found {len(orphans)} idle Fargate tasks in {region}")
        return orphans

    except Exception as e:
        logger.error(f"Error scanning Fargate idle tasks in {region}: {e}")
        raise
```

---

## üß™ Test Unitaire

```python
import pytest
from moto import mock_ecs, mock_cloudwatch
import boto3
from datetime import datetime, timezone

@mock_ecs
@mock_cloudwatch
async def test_scan_fargate_idle_tasks():
    """Test de d√©tection des Fargate tasks idle."""

    region = 'us-east-1'

    # Setup
    ecs = boto3.client('ecs', region_name=region)
    cloudwatch = boto3.client('cloudwatch', region_name=region)

    # Cr√©er cluster
    cluster_resp = ecs.create_cluster(clusterName='test-cluster')
    cluster_arn = cluster_resp['cluster']['clusterArn']

    # Enregistrer task definition
    ecs.register_task_definition(
        family='web-app',
        requiresCompatibilities=['FARGATE'],
        networkMode='awsvpc',
        cpu='1024',  # 1 vCPU
        memory='2048',  # 2 GB
        containerDefinitions=[
            {
                'name': 'web',
                'image': 'nginx:latest',
                'memory': 2048
            }
        ]
    )

    # Note: moto limitations pour CloudWatch metrics
    # Dans un environnement r√©el, on mockerait NetworkIn/Out metrics

    # Ex√©cution
    orphans = await scan_fargate_idle_tasks(
        region=region,
        lookback_days=7,
        min_age_days=7
    )

    # V√©rifications
    # Note: Test simplifi√© car moto ne supporte pas compl√®tement ECS Container Insights

    # 1. V√©rifier structure orphans
    for orphan in orphans:
        assert orphan['orphan_type'] == 'idle_task'
        assert orphan['metadata']['total_network_bytes'] == 0
        assert orphan['estimated_monthly_cost'] > 0  # Co√ªt vCPU + Memory

    # 2. V√©rifier calcul co√ªt (1 vCPU + 2 GB)
    if orphans:
        # 1 vCPU = 1024 CPU units, 2 GB = 2048 MB
        expected_cost = (1.0 * 0.04048 * 730) + (2.0 * 0.004445 * 730)
        assert abs(orphans[0]['estimated_monthly_cost'] - expected_cost) < 0.01

    print(f"‚úÖ Test passed: {len(orphans)} idle tasks detected")
```

---

## ‚úÖ Recommandations

1. **Auto-scaling √† 0**:
   ```python
   # Configure service min tasks = 0 (si traffic sporadique)
   ecs.update_service(
       cluster='prod-cluster',
       service='legacy-api',
       desiredCount=0  # Scale to 0
   )
   ```

2. **Monitoring Alerts**:
   - CloudWatch alarm: NetworkIn + NetworkOut = 0 pendant 7 jours ‚Üí Alert
   - Lambda weekly scan: Identifier tasks idle ‚Üí Slack notification

3. **Tagging pour Review**:
   ```json
   {
     "Environment": "production",
     "Owner": "backend-team",
     "LastReviewDate": "2024-11-01",
     "AutoScaleToZero": "true"
   }
   ```

4. **Grace Period**:
   - 7 jours idle ‚Üí Warning
   - 30 jours idle ‚Üí Scale to 0 automatic
   - 90 jours idle ‚Üí Delete service

---
# üìâ Sc√©nario 3: CPU/Memory Over-Provisioned (<10% Utilization)

## üìã Description du Probl√®me

Une **Fargate task over-provisioned** est une task avec des ressources CPU/Memory **largement surdimensionn√©es** par rapport √† son utilisation r√©elle. Sympt√¥mes:

- **CPU Utilization < 10%** (moyenne sur 30 jours)
- **Memory Utilization < 50%** (moyenne sur 30 jours)
- **Co√ªt gaspill√©** = (Provisioned - Used) √ó Prix

AWS Fargate facture uniquement les ressources **provisionn√©es** (pas utilis√©es). Une task configur√©e avec **4 vCPU + 8 GB** mais utilisant r√©ellement **0.5 vCPU + 2 GB** gaspille **87.5% de son co√ªt**.

### üî¥ Causes Typiques

1. **Copy-paste config** ‚Üí Copier config d'un service haute performance vers service l√©ger
2. **Provisioning "par s√©curit√©"** ‚Üí Allouer 4 vCPU "au cas o√π" alors que 0.5 vCPU suffisent
3. **Pas de right-sizing** ‚Üí Jamais revu la config depuis le lancement (2+ ans ago)
4. **Workload change** ‚Üí Traffic divis√© par 10 mais config identique
5. **Dev/Staging over-provisioned** ‚Üí M√™me config que prod mais 10√ó moins de traffic

---

## üí∞ Impact Financier

### Calcul du Co√ªt

**Formule Gaspillage**:
```
Co√ªt Gaspill√© = (vCPU Provisioned - vCPU Used) √ó $0.04048 √ó 730h
              + (Memory Provisioned - Memory Used) √ó $0.004445 √ó 730h
```

### üìä Exemple 1: Task 4 vCPU + 8 GB ‚Üí Right-Size 0.5 vCPU + 1 GB

```
Configuration ACTUELLE (Over-Provisioned):
  - vCPU: 4.0
  - Memory: 8 GB

Utilization R√âELLE (CloudWatch 30 jours):
  - CPU: 8% average (= 0.32 vCPU effective)
  - Memory: 12% average (= 0.96 GB effective)

Co√ªt ACTUEL:
  - vCPU: 4.0 √ó $0.04048 √ó 730h = $118.20/mois
  - Memory: 8 GB √ó $0.004445 √ó 730h = $25.94/mois
  - TOTAL: $144.14/mois = $1,730/an üî¥

Configuration OPTIMIS√âE (Right-Sized):
  - vCPU: 0.5 (avec 25% marge)
  - Memory: 1 GB (avec 10% marge)

Co√ªt OPTIMIS√â:
  - vCPU: 0.5 √ó $0.04048 √ó 730h = $14.78/mois
  - Memory: 1 GB √ó $0.004445 √ó 730h = $3.24/mois
  - TOTAL: $18.02/mois = $216/an ‚úÖ

üí∞ √âCONOMIE: $144.14 - $18.02 = $126.12/mois = $1,514/an per task (87.5% r√©duction!)
```

### üìä Exemple 2: 80 Tasks Over-Provisioned (Organisation Typique)

```
Entreprise: SaaS avec 200 Fargate tasks total

Audit CloudWatch (30 jours):
  - 120 tasks: Utilization OK (CPU >30%, Memory >50%)
  - 80 tasks: Over-provisioned (CPU <10%, Memory <50%) üî¥

D√©tails des 80 tasks over-provisioned:
  - Config moyenne: 2 vCPU + 4 GB
  - Utilization moyenne: CPU 7%, Memory 20%
  - Right-size optimal: 0.5 vCPU + 1 GB

Co√ªt ACTUEL (80 tasks over-provisioned):
  Config: 2 vCPU + 4 GB
  Co√ªt: (2 √ó $0.04048 + 4 √ó $0.004445) √ó 730 = $72.08/task/mois
  Total: 80 tasks √ó $72.08 = $5,766/mois = $69,192/an üî¥

Co√ªt OPTIMIS√â (apr√®s right-sizing):
  Config: 0.5 vCPU + 1 GB
  Co√ªt: (0.5 √ó $0.04048 + 1 √ó $0.004445) √ó 730 = $18.02/task/mois
  Total: 80 tasks √ó $18.02 = $1,442/mois = $17,304/an ‚úÖ

üí∞ √âCONOMIE: $5,766 - $1,442 = $4,324/mois = $51,888/an (75% r√©duction!)
üí° ROI: Right-sizing 80 tasks = 2 jours de travail ‚Üí $51,888/an saved ‚Üí ROI 1:10,000+
```

---

## üîç D√©tection du Gaspillage

### Crit√®res de D√©tection

1. **Task status = RUNNING**
2. **Launch type = FARGATE**
3. **CPU Utilization < 10%** (moyenne 30 jours CloudWatch)
4. **Memory Utilization < 50%** (moyenne 30 jours CloudWatch)
5. **Task age > 30 jours** (pas une task qui vient de d√©marrer)
6. **Right-sizing potential > 50%** (√©conomie ‚â• 50% possible)

### üìä Exemple Concret

```
Task ARN:          arn:aws:ecs:us-east-1:123456789012:task/prod-cluster/def456
Task Definition:   api-backend:67
Cluster:           prod-cluster
Service:           api-backend-service
Launch Type:       FARGATE
Desired Status:    RUNNING
Last Status:       RUNNING
Started At:        2023-01-15 10:30:00 UTC (660 days ago)

Task Configuration (ACTUELLE):
  - vCPU: 2.0
  - Memory: 4 GB
  - Platform Version: 1.4.0
  - Cost: $72.08/mois

CloudWatch Metrics (30 derniers jours):
  - CPUUtilization:
    - Average: 5.2% üî¥
    - Max: 18% (peak traffic)
    - P99: 12%
    - Effective vCPU used: 0.104 vCPU (5.2% √ó 2.0)

  - MemoryUtilization:
    - Average: 32% üî¥
    - Max: 48% (peak)
    - P99: 42%
    - Effective Memory used: 1.28 GB (32% √ó 4 GB)

Service Traffic Pattern:
  - Requests/day: ~50,000 (stable)
  - Peak requests/hour: 3,000
  - Response time P95: 45ms (tr√®s rapide = under-utilized)

Right-Sizing Analysis:
  - CPU Required (P99 + 25% marge): 0.12 √ó 1.25 = 0.15 vCPU
    ‚Üí Fargate config: 0.25 vCPU (minimum) ‚úÖ

  - Memory Required (P99 + 10% marge): 1.68 GB √ó 1.10 = 1.85 GB
    ‚Üí Fargate config: 2 GB ‚úÖ

Configuration OPTIMALE:
  - vCPU: 0.25 (vs 2.0 actuel = -87.5%)
  - Memory: 2 GB (vs 4 GB actuel = -50%)

Co√ªt ACTUEL:
  - vCPU: 2.0 √ó $0.04048 √ó 730 = $59.10/mois
  - Memory: 4 GB √ó $0.004445 √ó 730 = $12.98/mois
  - TOTAL: $72.08/mois = $865/an üî¥

Co√ªt OPTIMIS√â:
  - vCPU: 0.25 √ó $0.04048 √ó 730 = $7.39/mois
  - Memory: 2 GB √ó $0.004445 √ó 730 = $6.49/mois
  - TOTAL: $13.88/mois = $167/an ‚úÖ

üí∞ √âCONOMIE: $72.08 - $13.88 = $58.20/mois = $698/an per task (81% r√©duction!)

Timeline:
  - Jan 2023: Task launched with 2 vCPU + 4 GB (initial config)
  - Mar 2023: Traffic stable ~50K req/day (CPU <10%)
  - 2023-2024: Jamais de right-sizing review üî¥
  - Today (Nov 2024): 660 days over-provisioned

Total Wasted (660 days):
  $58.20/mois √ó 22 mois = $1,280 üî¥

üî¥ WASTE DETECTED: Over-provisioned (CPU 5%, Memory 32% for 660 days)
üí∞ COST: $58.20/mois = $698/an GASPILL√âS
üìã ACTION: Right-size to 0.25 vCPU + 2 GB (immediate 81% savings)
üí° ROOT CAUSE: Initial over-provisioning "par s√©curit√©" jamais revu

Performance Validation:
  ‚úÖ Response time OK apr√®s right-sizing (tested in staging)
  ‚úÖ CPU headroom 25% (0.15 used vs 0.25 provisioned)
  ‚úÖ Memory headroom 10% (1.85 GB used vs 2 GB provisioned)
  ‚úÖ Zero impact on SLA
```

---

## üêç Impl√©mentation Python

### Code de D√©tection

```python
async def scan_fargate_over_provisioned(
    region: str,
    cpu_threshold_percent: float = 10.0,
    memory_threshold_percent: float = 50.0,
    lookback_days: int = 30,
    min_age_days: int = 30
) -> List[Dict]:
    """
    D√©tecte les Fargate tasks over-provisioned (CPU/Memory sous-utilis√©s).

    Analyse:
    - Task lastStatus = RUNNING
    - CPUUtilization < cpu_threshold_percent (30 jours)
    - MemoryUtilization < memory_threshold_percent (30 jours)
    - Calcule right-sizing recommendations

    Args:
        region: R√©gion AWS
        cpu_threshold_percent: Seuil CPU (d√©faut: 10%)
        memory_threshold_percent: Seuil Memory (d√©faut: 50%)
        lookback_days: P√©riode CloudWatch (d√©faut: 30 jours)
        min_age_days: √Çge minimum task (d√©faut: 30 jours)

    Returns:
        Liste des tasks over-provisioned avec √©conomies potentielles
    """
    orphans = []

    ecs_client = boto3.client('ecs', region_name=region)
    cloudwatch = boto3.client('cloudwatch', region_name=region)

    try:
        # 1. Liste clusters
        clusters_resp = await ecs_client.list_clusters()
        cluster_arns = clusters_resp.get('clusterArns', [])

        logger.info(f"Found {len(cluster_arns)} ECS clusters in {region}")

        # 2. Pour chaque cluster, liste tasks RUNNING
        for cluster_arn in cluster_arns:
            try:
                # Liste tasks RUNNING
                tasks_resp = await ecs_client.list_tasks(
                    cluster=cluster_arn,
                    desiredStatus='RUNNING',
                    maxResults=100
                )

                task_arns = tasks_resp.get('taskArns', [])

                if not task_arns:
                    continue

                # Describe tasks
                tasks_desc = await ecs_client.describe_tasks(
                    cluster=cluster_arn,
                    tasks=task_arns
                )

                tasks = tasks_desc.get('tasks', [])

                # Analyse chaque task RUNNING
                for task in tasks:
                    try:
                        started_at = task.get('startedAt')
                        task_arn = task.get('taskArn')
                        task_definition_arn = task.get('taskDefinitionArn')
                        launch_type = task.get('launchType', 'UNKNOWN')

                        # Filtrer: Fargate uniquement
                        if launch_type != 'FARGATE':
                            continue

                        # Calcule √¢ge de la task
                        if not started_at:
                            continue

                        age_days = (datetime.now(timezone.utc) - started_at).days

                        # Filtre: √¢ge minimum
                        if age_days < min_age_days:
                            continue

                        # R√©cup√®re task definition pour CPU/Memory
                        task_def_resp = await ecs_client.describe_task_definition(
                            taskDefinition=task_definition_arn
                        )
                        task_def = task_def_resp['taskDefinition']

                        cpu = int(task_def.get('cpu', '256'))  # CPU units
                        memory = int(task_def.get('memory', '512'))  # Memory MB

                        # Convertir
                        vcpu = cpu / 1024.0
                        memory_gb = memory / 1024.0

                        # CloudWatch metrics: CPU + Memory Utilization
                        end_time = datetime.now(timezone.utc)
                        start_time = end_time - timedelta(days=lookback_days)

                        # CPU Utilization
                        cpu_metrics = await cloudwatch.get_metric_statistics(
                            Namespace='ECS/ContainerInsights',
                            MetricName='CpuUtilized',
                            Dimensions=[
                                {'Name': 'ClusterName', 'Value': cluster_arn.split('/')[-1]},
                                {'Name': 'TaskId', 'Value': task_arn.split('/')[-1]}
                            ],
                            StartTime=start_time,
                            EndTime=end_time,
                            Period=3600,  # 1 heure
                            Statistics=['Average']
                        )

                        # Memory Utilization
                        memory_metrics = await cloudwatch.get_metric_statistics(
                            Namespace='ECS/ContainerInsights',
                            MetricName='MemoryUtilized',
                            Dimensions=[
                                {'Name': 'ClusterName', 'Value': cluster_arn.split('/')[-1]},
                                {'Name': 'TaskId', 'Value': task_arn.split('/')[-1]}
                            ],
                            StartTime=start_time,
                            EndTime=end_time,
                            Period=3600,  # 1 heure
                            Statistics=['Average']
                        )

                        cpu_datapoints = cpu_metrics.get('Datapoints', [])
                        memory_datapoints = memory_metrics.get('Datapoints', [])

                        if not cpu_datapoints or not memory_datapoints:
                            continue  # Pas de metrics disponibles

                        # Calcule utilization moyenne
                        avg_cpu_utilized = sum(p['Average'] for p in cpu_datapoints) / len(cpu_datapoints)
                        avg_memory_utilized = sum(p['Average'] for p in memory_datapoints) / len(memory_datapoints)

                        # Convertir en %
                        cpu_utilization_percent = (avg_cpu_utilized / (vcpu * 1024)) * 100
                        memory_utilization_percent = (avg_memory_utilized / (memory_gb * 1024)) * 100

                        # üî¥ D√âTECTION: CPU <10% OU Memory <50%
                        if cpu_utilization_percent < cpu_threshold_percent or memory_utilization_percent < memory_threshold_percent:

                            # Right-sizing recommendations
                            # CPU: P99 + 25% marge
                            cpu_p99 = max((p['Average'] for p in cpu_datapoints), default=0)
                            recommended_vcpu = max(0.25, (cpu_p99 / 1024) * 1.25)  # Min 0.25 vCPU

                            # Memory: P99 + 10% marge
                            memory_p99 = max((p['Average'] for p in memory_datapoints), default=0)
                            recommended_memory_gb = max(0.5, (memory_p99 / 1024) * 1.10)  # Min 0.5 GB

                            # Arrondir aux configs Fargate valides
                            # vCPU: 0.25, 0.5, 1, 2, 4, 8, 16
                            # Memory: d√©pend vCPU
                            fargate_vcpu_configs = [0.25, 0.5, 1, 2, 4, 8, 16]
                            recommended_vcpu = min(fargate_vcpu_configs, key=lambda x: abs(x - recommended_vcpu) if x >= recommended_vcpu else float('inf'))

                            # Memory: arrondir au GB sup√©rieur
                            recommended_memory_gb = math.ceil(recommended_memory_gb)

                            # Calcule √©conomie
                            current_cost = (vcpu * 0.04048 * 730) + (memory_gb * 0.004445 * 730)
                            optimized_cost = (recommended_vcpu * 0.04048 * 730) + (recommended_memory_gb * 0.004445 * 730)
                            monthly_savings = current_cost - optimized_cost
                            savings_percent = (monthly_savings / current_cost * 100) if current_cost > 0 else 0

                            # Filtre: √©conomie > 50%
                            if savings_percent < 50:
                                continue

                            # Niveau de confiance
                            if age_days >= 180:
                                confidence = "critical"
                            elif age_days >= 90:
                                confidence = "high"
                            else:
                                confidence = "medium"

                            # M√©tadonn√©es
                            metadata = {
                                "task_arn": task_arn,
                                "task_definition": task_definition_arn.split('/')[-1],
                                "cluster_name": cluster_arn.split('/')[-1],
                                "current_vcpu": vcpu,
                                "current_memory_gb": round(memory_gb, 2),
                                "cpu_utilization_percent": round(cpu_utilization_percent, 2),
                                "memory_utilization_percent": round(memory_utilization_percent, 2),
                                "recommended_vcpu": recommended_vcpu,
                                "recommended_memory_gb": recommended_memory_gb,
                                "current_monthly_cost": round(current_cost, 2),
                                "optimized_monthly_cost": round(optimized_cost, 2),
                                "monthly_savings": round(monthly_savings, 2),
                                "savings_percent": round(savings_percent, 2),
                                "age_days": age_days,
                                "confidence": confidence
                            }

                            orphan = {
                                "resource_id": task_arn,
                                "resource_name": task_definition_arn.split('/')[-1],
                                "resource_type": "fargate_task",
                                "region": region,
                                "orphan_type": "over_provisioned",
                                "estimated_monthly_cost": round(monthly_savings, 2),  # √âconomie potentielle
                                "metadata": metadata,
                                "detection_timestamp": datetime.now(timezone.utc).isoformat()
                            }

                            orphans.append(orphan)

                            logger.info(
                                f"Over-provisioned Fargate task: {task_definition_arn.split('/')[-1]} "
                                f"(CPU {cpu_utilization_percent:.1f}%, Memory {memory_utilization_percent:.1f}%, "
                                f"${monthly_savings:.2f}/mois savings)"
                            )

                    except Exception as e:
                        logger.error(f"Error analyzing task {task.get('taskArn')}: {e}")
                        continue

            except ClientError as e:
                error_code = e.response.get('Error', {}).get('Code', '')
                logger.error(f"Error listing tasks for cluster {cluster_arn}: {error_code}")
                continue

        logger.info(f"Found {len(orphans)} over-provisioned Fargate tasks in {region}")
        return orphans

    except Exception as e:
        logger.error(f"Error scanning Fargate over-provisioned tasks in {region}: {e}")
        raise
```

---

## üß™ Test Unitaire

```python
import pytest
from moto import mock_ecs, mock_cloudwatch
import boto3
from datetime import datetime, timezone
import math

@mock_ecs
@mock_cloudwatch
async def test_scan_fargate_over_provisioned():
    """Test de d√©tection des Fargate tasks over-provisioned."""

    region = 'us-east-1'

    # Setup
    ecs = boto3.client('ecs', region_name=region)
    cloudwatch = boto3.client('cloudwatch', region_name=region)

    # Cr√©er cluster
    cluster_resp = ecs.create_cluster(clusterName='test-cluster')
    cluster_arn = cluster_resp['cluster']['clusterArn']

    # Enregistrer task definition over-provisioned
    ecs.register_task_definition(
        family='api-backend',
        requiresCompatibilities=['FARGATE'],
        networkMode='awsvpc',
        cpu='2048',  # 2 vCPU
        memory='4096',  # 4 GB
        containerDefinitions=[
            {
                'name': 'api',
                'image': 'nginx:latest',
                'memory': 4096
            }
        ]
    )

    # Note: moto limitations pour CloudWatch metrics
    # Dans un environnement r√©el, on mockerait CPUUtilization <10%

    # Ex√©cution
    orphans = await scan_fargate_over_provisioned(
        region=region,
        cpu_threshold_percent=10.0,
        memory_threshold_percent=50.0,
        lookback_days=30,
        min_age_days=30
    )

    # V√©rifications
    # Note: Test simplifi√© car moto ne supporte pas compl√®tement ECS Container Insights

    # 1. V√©rifier structure orphans
    for orphan in orphans:
        assert orphan['orphan_type'] == 'over_provisioned'
        assert orphan['metadata']['cpu_utilization_percent'] < 10 or orphan['metadata']['memory_utilization_percent'] < 50
        assert orphan['metadata']['savings_percent'] >= 50
        assert orphan['estimated_monthly_cost'] > 0  # √âconomie potentielle

    # 2. V√©rifier right-sizing recommendations
    for orphan in orphans:
        assert orphan['metadata']['recommended_vcpu'] <= orphan['metadata']['current_vcpu']
        assert orphan['metadata']['recommended_memory_gb'] <= orphan['metadata']['current_memory_gb']

    print(f"‚úÖ Test passed: {len(orphans)} over-provisioned tasks detected")
```

---

## ‚úÖ Recommandations

### 1. Right-Sizing Process

**√âtape 1: Audit CloudWatch (30 jours)**
```python
# Analyser CPU/Memory utilization P99
cpu_p99 = get_cloudwatch_p99('CpuUtilized', task_arn, days=30)
memory_p99 = get_cloudwatch_p99('MemoryUtilized', task_arn, days=30)

# Recommandation: P99 + marge
recommended_vcpu = cpu_p99 * 1.25  # +25% marge
recommended_memory = memory_p99 * 1.10  # +10% marge
```

**√âtape 2: Test en Staging**
- D√©ployer nouvelle config en staging
- Valider performance (response time, error rate)
- Load test pour valider headroom

**√âtape 3: D√©ploiement Progressif Prod**
- Canary deployment: 10% ‚Üí 50% ‚Üí 100%
- Monitoring CloudWatch alerts
- Rollback si d√©gradation

### 2. Fargate CPU/Memory Configurations Valides

| vCPU | Memory Options (GB) | Use Case |
|------|---------------------|----------|
| **0.25** | 0.5, 1, 2 | Micro services, cron jobs |
| **0.5** | 1, 2, 3, 4 | Small APIs, workers |
| **1** | 2, 3, 4, 5, 6, 7, 8 | **Standard APIs** ‚úÖ |
| **2** | 4-16 GB | Medium workloads |
| **4** | 8-30 GB | Large workloads |
| **8** | 16-60 GB | Very large |
| **16** | 32-120 GB | Extreme |

üí° **R√®gle 80/20**: 80% des workloads fonctionnent avec **0.5-1 vCPU + 1-2 GB**

### 3. Monitoring Continu

```python
# CloudWatch alarm: CPU >80% (sous-provisionn√©)
cloudwatch.put_metric_alarm(
    AlarmName='fargate-task-cpu-high',
    MetricName='CPUUtilization',
    Threshold=80,
    ComparisonOperator='GreaterThanThreshold'
)

# CloudWatch alarm: CPU <10% (over-provisionn√©)
cloudwatch.put_metric_alarm(
    AlarmName='fargate-task-cpu-low',
    MetricName='CPUUtilization',
    Threshold=10,
    ComparisonOperator='LessThanThreshold'
)
```

### 4. Automation (Right-Sizing Lambda)

```python
# Lambda triggered monthly
# Auto-detect over-provisioned tasks ‚Üí Slack notification
for task in fargate_tasks:
    if task['cpu_utilization'] < 10:
        # Recommandation right-sizing
        send_slack_alert(
            f"Task {task['name']} over-provisioned (CPU {task['cpu_util']}%)\n"
            f"Current: {task['vcpu']} vCPU, {task['memory']} GB = ${task['cost']}/mois\n"
            f"Recommended: {task['recommended_vcpu']} vCPU, {task['recommended_memory']} GB = ${task['optimized_cost']}/mois\n"
            f"Savings: ${task['savings']}/mois = ${task['savings']*12}/an"
        )
```

---
