# ðŸ“¦ CloudWaste - Couverture 100% AWS Fargate Tasks

CloudWaste dÃ©tecte maintenant **100% des scÃ©narios de gaspillage** pour AWS Fargate (Serverless Containers) !

## ðŸŽ¯ ScÃ©narios Couverts (10/10 = 100%)

### Phase 1 - DÃ©tection Simple (5 scÃ©narios - MÃ©tadonnÃ©es + ECS/CloudWatch APIs)
1. âœ… **fargate_stopped_tasks** - Tasks ArrÃªtÃ©es Jamais SupprimÃ©es (STOPPED > 30 Jours)
2. âœ… **fargate_idle_tasks** - Tasks Running Mais Sans Traffic (0 NetworkIn/Out > 7 Jours)
3. âœ… **fargate_over_provisioned** - CPU/Memory Over-Provisioned (<10% Utilization > 30 Jours)
4. âœ… **fargate_inactive_services** - Services ECS Ã  0 Desired Count (Inactifs > 90 Jours)
5. âœ… **fargate_no_spot** - Pas de Fargate Spot (100% On-Demand â†’ SurcoÃ»t 70%)

### Phase 2 - Optimisation AvancÃ©e (5 scÃ©narios - CloudWatch + Cost Optimization)
6. âœ… **fargate_excessive_logs** - CloudWatch Logs Retention Excessive (>90 Jours)
7. âœ… **fargate_ec2_opportunity** - Wrong Compute Type (Workloads 24/7 Mieux sur EC2)
8. âœ… **fargate_standalone_orphaned** - Tasks Standalone Jamais NettoyÃ©es (RunTask Sans Service)
9. âœ… **fargate_bad_autoscaling** - Auto Scaling Mal ConfigurÃ© (Target <30% ou >70%)
10. âœ… **fargate_outdated_platform** - Platform Version ObsolÃ¨te (< LATEST-1 â†’ SÃ©curitÃ© + Bugs)

---

## ðŸ“‹ Introduction

**AWS Fargate** est un moteur de calcul serverless pour containers qui Ã©limine la gestion de l'infrastructure EC2. Fargate fonctionne avec:
- **Amazon ECS** (Elastic Container Service) - Orchestration AWS native
- **Amazon EKS** (Elastic Kubernetes Service) - Kubernetes managÃ©

MalgrÃ© son approche serverless, Fargate reprÃ©sente une **source majeure de gaspillage cloud**:

- **CoÃ»t Ã©levÃ© vs EC2**: 30-50% plus cher que EC2 Spot pour workloads 24/7
- **Over-provisioning facile**: Tasks avec CPU/Memory mal dimensionnÃ©s â†’ surcoÃ»t 200-300%
- **Fargate Spot sous-utilisÃ©**: 70% d'Ã©conomies ignorÃ©es (Spot vs On-Demand)
- **Services inactifs oubliÃ©s**: Services ECS desired=0 mais load balancers actifs â†’ $20-50/mois gaspillÃ©s
- **Logs retention excessive**: CloudWatch Logs indefinite â†’ $0.50/GB/mois Ã— accumulation

### Pourquoi Fargate est critique ?

| ProblÃ¨me | Impact Annuel (Organisation 200 Tasks, Avg 1 vCPU + 2 GB) |
|----------|-----------------------------------------------------------|
| Tasks idle (10%) | 20 tasks Ã— $35.86/mois = **$7,000/an** ðŸ”´ |
| Over-provisioned (40%) | 80 tasks Ã— right-size 70% = **$28,000/an** ðŸ”´ |
| No Fargate Spot (50%) | 100 tasks Ã— 70% savings = **$29,400/an** ðŸ”´ |
| Services inactifs (5%) | 10 services Ã— $20 ALB = **$1,200/an** ðŸŸ¡ |
| STOPPED tasks (pollution) | Cleanup namespace | ðŸŸ¢ |
| Excessive logs (20%) | 40 tasks Ã— 5 GB Ã— $0.50 Ã— 12 = **$1,200/an** ðŸŸ¡ |
| Wrong compute (15%) | 30 tasks â†’ EC2 30% savings = **$6,300/an** ðŸ”´ |
| Standalone orphaned (5%) | 10 tasks Ã— $35/mois = **$1,800/an** ðŸŸ¡ |
| Bad autoscaling (20%) | 40 tasks Ã— over-scaled 30% = **$5,000/an** ðŸŸ¢ |
| Outdated platform | Security risk (no direct cost) | ðŸŸ¢ |
| **TOTAL** | **~$80,000/an** ðŸ’° |

---

## ðŸ’° Pricing AWS Fargate

### Fargate On-Demand Pricing (us-east-1)

| Ressource | CoÃ»t par heure | CoÃ»t mensuel (730h) | Use Case |
|-----------|----------------|---------------------|----------|
| **1 vCPU** | **$0.04048** | **$29.55** | Baseline compute |
| **1 GB Memory** | **$0.004445** | **$3.24** | Baseline memory |

### Exemples de Configurations Typiques

| Config | vCPU | Memory | CoÃ»t/Heure | CoÃ»t/Mois (730h) | CoÃ»t/An |
|--------|------|--------|-----------|------------------|---------|
| **Micro** | 0.25 | 0.5 GB | $0.01234 | **$9.01** | $108 |
| **Small** | 0.5 | 1 GB | $0.02468 | **$18.02** | $216 |
| **Medium** | 1 | 2 GB | **$0.04937** | **$36.04** | $432 |
| **Large** | 2 | 4 GB | $0.09874 | **$72.08** | $865 |
| **XLarge** | 4 | 8 GB | $0.19748 | **$144.16** | $1,730 |

### Fargate Spot Pricing (-70% vs On-Demand)

| Config | On-Demand | **Fargate Spot** | Ã‰conomie/Mois | Ã‰conomie/An |
|--------|-----------|------------------|---------------|-------------|
| 1 vCPU + 2 GB | $36.04 | **$10.81** | **$25.23** | **$303** ðŸŽ‰ |
| 2 vCPU + 4 GB | $72.08 | **$21.62** | **$50.46** | **$606** ðŸŽ‰ |
| 4 vCPU + 8 GB | $144.16 | **$43.25** | **$100.91** | **$1,211** ðŸŽ‰ |

ðŸ’¡ **Fargate Spot = -70% de coÃ»t** (tasks interruptibles, ideal pour batch processing, dev/staging)

---

### Fargate vs EC2 Cost Comparison

| Workload Type | Fargate On-Demand | Fargate Spot | EC2 On-Demand | EC2 Spot | Meilleur Choix |
|---------------|-------------------|--------------|---------------|----------|----------------|
| **Short-lived (<4h)** | $0.20 | $0.06 | $0.15 + overhead | N/A | **Fargate Spot** âœ… |
| **Intermittent (4-12h)** | $0.50 | $0.15 | $0.30 + overhead | $0.10 | **Fargate Spot** âœ… |
| **24/7 Production** | $36/mois | $11/mois | $25/mois | **$8/mois** | **EC2 Spot** âœ… |
| **Batch Processing** | $0.50/batch | **$0.15/batch** | $0.30 | $0.10 | **Fargate Spot** âœ… |

ðŸ’¡ **RÃ¨gle gÃ©nÃ©rale**:
- **Fargate**: Workloads sporadiques, event-driven, auto-scaling frÃ©quent
- **EC2**: Workloads 24/7, predicable, long-running (>95% uptime)

---

### ECS vs EKS avec Fargate

| Feature | ECS (Native AWS) | EKS (Kubernetes) | DiffÃ©rence |
|---------|------------------|------------------|------------|
| **Control Plane Cost** | **Gratuit** ðŸŽ‰ | **$73/mois** ðŸ”´ | EKS = +$876/an |
| **Task Pricing** | Identique | Identique | MÃªme coÃ»t Fargate |
| **Overhead** | Minimal | K8s complexity | ECS plus simple |
| **Portability** | Locked-in AWS | Multi-cloud | K8s portable |
| **Use Case** | AWS-only, simplicitÃ© | Multi-cloud, K8s ecosystem | DÃ©pend stratÃ©gie |

ðŸ’¡ **EKS Control Plane** = $73/mois Ã— 12 = **$876/an de surcoÃ»t** vs ECS (si mono-AWS)

---

## ðŸ” ScÃ©nario 1: Tasks ArrÃªtÃ©es Jamais SupprimÃ©es (STOPPED > 30 Jours)

### ðŸ“‹ Description du ProblÃ¨me

Lorsqu'une **Fargate task** est arrÃªtÃ©e (manuellement, par scaling, ou par erreur), elle passe Ã  l'Ã©tat **STOPPED** mais n'est **PAS automatiquement supprimÃ©e** par AWS. Ces tasks STOPPED restent dans le namespace ECS indÃ©finiment, crÃ©ant:

- **Pollution du namespace**: Difficile de distinguer tasks actives vs anciennes
- **Confusion opÃ©rationnelle**: Logs/metadata de tasks obsolÃ¨tes
- **Audit complexe**: 500+ STOPPED tasks mÃ©langÃ©es aux actives
- **Pas de coÃ»t direct** (mais overhead management)

### ðŸ”´ ScÃ©narios de Gaspillage

1. **Scaling down** â†’ Tasks stopped mais jamais nettoyÃ©es (auto-scaling)
2. **Deployments** â†’ Anciens task definitions stopped (rolling updates)
3. **Tests/Debug** â†’ Tasks manuelles stopped puis oubliÃ©es
4. **Services supprimÃ©s** â†’ Tasks stopped du service persistent
5. **Erreurs** â†’ Tasks crashÃ©es en STOPPED (jamais investigated)

---

## ðŸ’° Impact Financier

### CoÃ»t Direct: $0/mois

Les tasks STOPPED ne consomment **aucune ressource compute** (pas de vCPU/Memory facturÃ©s).

### CoÃ»t Indirect: OpÃ©rationnel

```
Entreprise avec 1,000 STOPPED tasks (sur 200 services ECS):

ProblÃ¨mes:
  - Namespace pollution: aws ecs list-tasks retourne 1,200 tasks (1,000 STOPPED + 200 RUNNING)
  - Filtering required: Tous les scripts doivent filter --desired-status RUNNING
  - Audit complexity: Impossible de savoir quelles tasks sont importantes
  - Log retention: CloudWatch Logs de 1,000 tasks STOPPED conservÃ©s (si retention indefinite)

Overhead OpÃ©rationnel:
  - Temps ingÃ©nieur: 2h/semaine Ã— $100/h = $200/semaine = $800/mois
  - Scripts custom filtering: Maintenance overhead
  - Monitoring complexity: 1,000 tasks STOPPED = noise dans mÃ©triques

ðŸ’° CoÃ»t Indirect: ~$10,000/an (temps ingÃ©nieur + complexitÃ©)
```

---

## ðŸ” DÃ©tection du Gaspillage

### CritÃ¨res de DÃ©tection

1. **Task status = STOPPED**
2. **Stopped since > 30 jours** (configurble: `stopped_tasks_min_age_days`)
3. **Task NOT associated with active service** (standalone tasks)
4. **No recent investigation** (pas de CloudWatch Logs access)

### ðŸ“Š Exemple Concret

```
Task ARN:          arn:aws:ecs:us-east-1:123456789012:task/prod-cluster/abc123def456
Task Definition:   web-app:47
Cluster:           prod-cluster
Launch Type:       FARGATE
Desired Status:    STOPPED
Last Status:       STOPPED
Stopped At:        2024-04-15 14:23:00 UTC (205 days ago) ðŸ”´

Stop Reason:       "Task failed health checks" (ELB health check failure)
Stop Code:         TaskFailedToStart

Task Configuration:
  - vCPU: 1.0
  - Memory: 2 GB
  - Container: web-app:v2.3.1

Created At:        2024-04-15 14:20:00 UTC
Started At:        2024-04-15 14:21:30 UTC
Stopped At:        2024-04-15 14:23:00 UTC (ran for 90 seconds)

Associated Service: web-app-service (DELETED 2024-05-01)

Timeline:
  - April 15, 2024: Task started for deployment test
  - April 15, 2024: Health check failed â†’ STOPPED
  - May 1, 2024: Service deleted (migration to new service)
  - Today (Nov 5, 2024): Task STOPPED still exists (205 days) ðŸ”´

ðŸ”´ WASTE DETECTED: STOPPED task (205 days) never cleaned up
ðŸ’° COST: $0/direct (operational overhead)
ðŸ“‹ ACTION: DELETE task definition revision (cleanup namespace)
ðŸ’¡ ROOT CAUSE: No automatic cleanup policy for STOPPED tasks
```

---

## ðŸ ImplÃ©mentation Python

### Code de DÃ©tection

```python
async def scan_fargate_stopped_tasks(
    region: str,
    stopped_tasks_min_age_days: int = 30,
    min_age_days: int = 7
) -> List[Dict]:
    """
    DÃ©tecte les Fargate tasks STOPPED jamais supprimÃ©es.

    Analyse:
    - Task lastStatus = STOPPED
    - stoppedAt > stopped_tasks_min_age_days
    - Identifie tasks standalone (sans service parent)

    Args:
        region: RÃ©gion AWS
        stopped_tasks_min_age_days: Ã‚ge minimum STOPPED (dÃ©faut: 30 jours)
        min_age_days: Ã‚ge minimum de la task (dÃ©faut: 7 jours)

    Returns:
        Liste des tasks STOPPED avec mÃ©tadonnÃ©es
    """
    orphans = []

    ecs_client = boto3.client('ecs', region_name=region)

    try:
        # 1. Liste tous les clusters ECS
        clusters_resp = await ecs_client.list_clusters()
        cluster_arns = clusters_resp.get('clusterArns', [])

        logger.info(f"Found {len(cluster_arns)} ECS clusters in {region}")

        # 2. Pour chaque cluster, liste les tasks
        for cluster_arn in cluster_arns:
            try:
                # Liste tasks STOPPED (max 100 Ã  la fois)
                tasks_resp = await ecs_client.list_tasks(
                    cluster=cluster_arn,
                    desiredStatus='STOPPED',
                    maxResults=100
                )

                task_arns = tasks_resp.get('taskArns', [])

                if not task_arns:
                    continue

                # Describe tasks pour obtenir dÃ©tails
                tasks_desc = await ecs_client.describe_tasks(
                    cluster=cluster_arn,
                    tasks=task_arns
                )

                tasks = tasks_desc.get('tasks', [])

                # Analyse chaque task STOPPED
                for task in tasks:
                    try:
                        stopped_at = task.get('stoppedAt')
                        created_at = task.get('createdAt')
                        task_arn = task.get('taskArn')
                        task_definition = task.get('taskDefinitionArn')
                        launch_type = task.get('launchType', 'UNKNOWN')

                        # Filtrer: Fargate uniquement
                        if launch_type != 'FARGATE':
                            continue

                        # Calcule Ã¢ge de la task
                        if not stopped_at:
                            continue

                        age_days = (datetime.now(timezone.utc) - stopped_at).days

                        # Filtre: Ã¢ge minimum
                        if age_days < stopped_tasks_min_age_days:
                            continue

                        # MÃ©tadonnÃ©es
                        stop_reason = task.get('stopCode', 'UNKNOWN')
                        stop_code_reason = task.get('stoppedReason', 'Unknown')
                        group_name = task.get('group', '')
                        service_name = group_name.replace('service:', '') if 'service:' in group_name else None

                        # VÃ©rifier si service parent existe encore
                        service_exists = False
                        if service_name:
                            try:
                                service_desc = await ecs_client.describe_services(
                                    cluster=cluster_arn,
                                    services=[service_name]
                                )
                                services = service_desc.get('services', [])
                                service_exists = len(services) > 0 and services[0].get('status') == 'ACTIVE'

                            except Exception:
                                service_exists = False

                        # Niveau de confiance
                        if age_days >= 180:
                            confidence = "critical"
                        elif age_days >= 90:
                            confidence = "high"
                        else:
                            confidence = "medium"

                        # MÃ©tadonnÃ©es
                        metadata = {
                            "task_arn": task_arn,
                            "task_definition": task_definition,
                            "cluster_arn": cluster_arn,
                            "cluster_name": cluster_arn.split('/')[-1],
                            "launch_type": launch_type,
                            "stopped_at": stopped_at.isoformat(),
                            "age_days": age_days,
                            "stop_reason": stop_reason,
                            "stop_code_reason": stop_code_reason,
                            "service_name": service_name,
                            "service_exists": service_exists,
                            "confidence": confidence
                        }

                        # CoÃ»t estimÃ©: $0 direct
                        monthly_cost = 0.0

                        orphan = {
                            "resource_id": task_arn,
                            "resource_name": f"{task_definition.split('/')[-1]} (STOPPED)",
                            "resource_type": "fargate_task",
                            "region": region,
                            "orphan_type": "stopped_task",
                            "estimated_monthly_cost": round(monthly_cost, 2),
                            "metadata": metadata,
                            "detection_timestamp": datetime.now(timezone.utc).isoformat()
                        }

                        orphans.append(orphan)

                        logger.info(
                            f"STOPPED Fargate task: {task_definition.split('/')[-1]} "
                            f"(stopped {age_days} days ago)"
                        )

                    except Exception as e:
                        logger.error(f"Error analyzing task {task.get('taskArn')}: {e}")
                        continue

            except ClientError as e:
                error_code = e.response.get('Error', {}).get('Code', '')
                logger.error(f"Error listing tasks for cluster {cluster_arn}: {error_code}")
                continue

        logger.info(f"Found {len(orphans)} STOPPED Fargate tasks in {region}")
        return orphans

    except Exception as e:
        logger.error(f"Error scanning Fargate STOPPED tasks in {region}: {e}")
        raise
```

---

## ðŸ§ª Test Unitaire

```python
import pytest
from moto import mock_ecs
import boto3
from datetime import datetime, timedelta, timezone

@mock_ecs
async def test_scan_fargate_stopped_tasks():
    """Test de dÃ©tection des Fargate tasks STOPPED."""

    region = 'us-east-1'

    # Setup
    ecs = boto3.client('ecs', region_name=region)

    # CrÃ©er cluster
    cluster_resp = ecs.create_cluster(clusterName='test-cluster')
    cluster_arn = cluster_resp['cluster']['clusterArn']

    # Enregistrer task definition
    ecs.register_task_definition(
        family='web-app',
        requiresCompatibilities=['FARGATE'],
        networkMode='awsvpc',
        cpu='256',
        memory='512',
        containerDefinitions=[
            {
                'name': 'web',
                'image': 'nginx:latest',
                'memory': 512
            }
        ]
    )

    # Note: moto ne supporte pas complÃ¨tement run_task avec Fargate
    # Dans un vrai test, on crÃ©erait des tasks STOPPED

    # ExÃ©cution
    orphans = await scan_fargate_stopped_tasks(
        region=region,
        stopped_tasks_min_age_days=30,
        min_age_days=7
    )

    # VÃ©rifications
    # Note: moto limitations - dans un environnement rÃ©el:

    # 1. VÃ©rifier detection tasks STOPPED
    # stopped_tasks = [o for o in orphans if o['orphan_type'] == 'stopped_task']
    # assert len(stopped_tasks) > 0, "STOPPED tasks should be detected"

    # 2. VÃ©rifier mÃ©tadonnÃ©es
    for orphan in orphans:
        assert orphan['metadata']['launch_type'] == 'FARGATE'
        assert orphan['metadata']['age_days'] >= 30
        assert orphan['estimated_monthly_cost'] == 0  # Pas de coÃ»t direct

    print(f"âœ… Test passed: {len(orphans)} STOPPED tasks detected")
```

---

## âœ… Recommandations

1. **Automatic Cleanup Policy** (EventBridge + Lambda):
   ```python
   # Lambda triggered daily
   # Delete STOPPED tasks > 30 days
   for task in stopped_tasks:
       if task['age_days'] > 30 and not task['service_exists']:
           # Safe to delete (no parent service)
           delete_stopped_task(task_arn)
   ```

2. **Lifecycle Management**:
   - **STOPPED tasks**: Auto-delete after 30 days (configurable)
   - **Failed tasks**: Investigate within 7 days â†’ delete after 14 days
   - **Standalone tasks**: Delete immediately after completion

3. **Tagging Strategy**:
   ```json
   {
     "Environment": "production",
     "Owner": "platform-team",
     "AutoCleanup": "true",
     "RetentionDays": "30"
   }
   ```

4. **Monitoring**:
   - CloudWatch metric: Custom metric `StoppedTasksCount`
   - Alert si > 100 STOPPED tasks dans cluster

---

# âš¡ ScÃ©nario 2: Tasks Idle (Running Mais 0 Traffic RÃ©seau)

## ðŸ“‹ Description du ProblÃ¨me

Une **Fargate task idle** est une task en Ã©tat **RUNNING** mais qui ne traite **aucun traffic rÃ©seau** depuis 7+ jours. Ces tasks consomment des ressources (vCPU/Memory) **24/7** sans gÃ©nÃ©rer aucune valeur business.

### ðŸ”´ Causes Typiques

1. **Services oubliÃ©s aprÃ¨s tests** â†’ Task running mais plus utilisÃ©e
2. **Backend workers sans jobs** â†’ Queue vide depuis semaines
3. **API deprecated** â†’ Ancien endpoint plus appelÃ©
4. **Scaling mal configurÃ©** â†’ Min tasks = 1 mÃªme si 0 traffic
5. **Migration incomplÃ¨te** â†’ Ancien service running pendant migration

---

## ðŸ’° Impact Financier

### Calcul du CoÃ»t

**Formule**:
```
CoÃ»t Idle Task = (vCPU Ã— $0.04048 + Memory GB Ã— $0.004445) Ã— 730 heures/mois
```

**Exemple: Task 1 vCPU + 2 GB idle**

```
Configuration:
  - vCPU: 1.0
  - Memory: 2 GB
  - Ã‰tat: RUNNING 24/7
  - Traffic: 0 bytes IN/OUT (7 derniers jours)

CoÃ»t Mensuel:
  - vCPU: 1.0 Ã— $0.04048 Ã— 730h = $29.55/mois
  - Memory: 2 GB Ã— $0.004445 Ã— 730h = $6.49/mois
  - TOTAL: $36.04/mois = $432/an ðŸ”´

ðŸ’° GASPILLAGE: $432/an per idle task (100% waste)
```

### ðŸ“Š Exemple RÃ©el: 20 Idle Tasks

```
Entreprise: SaaS B2B avec 200 Fargate tasks total

Audit rÃ©vÃ¨le:
  - 20 tasks idle (10% du total)
  - Configuration moyenne: 1 vCPU + 2 GB
  - CoÃ»t moyen: $36/task/mois

DÃ©tails des tasks idle:
  1. legacy-api-v1 (deprecated 6 mois ago) â†’ $36/mois
  2. batch-worker-old (queue vide) â†’ $36/mois
  3. test-service-staging (oubliÃ©e) â†’ $36/mois
  ... (17 autres tasks)

CoÃ»t ACTUEL (idle tasks):
  20 tasks Ã— $36/mois = $720/mois = $8,640/an ðŸ”´

CoÃ»t OPTIMISÃ‰ (aprÃ¨s cleanup):
  0 tasks idle = $0/mois âœ…

ðŸ’° Ã‰CONOMIE: $8,640/an (delete ou scale to 0)
```

---

## ðŸ” DÃ©tection du Gaspillage

### CritÃ¨res de DÃ©tection

1. **Task status = RUNNING**
2. **Launch type = FARGATE**
3. **NetworkIn + NetworkOut = 0 bytes** (7 derniers jours via CloudWatch)
4. **Task age > 7 jours** (pas une task qui vient de dÃ©marrer)
5. **No active connections** (optional: vÃ©rifier ActiveConnectionCount si ALB/NLB)

### ðŸ“Š Exemple Concret

```
Task ARN:          arn:aws:ecs:us-east-1:123456789012:task/prod-cluster/xyz789
Task Definition:   legacy-api:23
Cluster:           prod-cluster
Service:           legacy-api-service
Launch Type:       FARGATE
Desired Status:    RUNNING
Last Status:       RUNNING
Started At:        2024-03-10 09:15:00 UTC (240 days ago)

Task Configuration:
  - vCPU: 1.0
  - Memory: 2 GB
  - Platform Version: LATEST
  - Public IP: 54.123.45.67

CloudWatch Metrics (7 derniers jours):
  - NetworkIn: 0 bytes ðŸ”´
  - NetworkOut: 0 bytes ðŸ”´
  - CPUUtilization: 0.2% (idle)
  - MemoryUtilization: 15% (minimal baseline)

Load Balancer:
  - Target Group: legacy-api-tg
  - Health Status: Healthy âœ… (responds to health checks)
  - Active Connections: 0 (7 jours)
  - Request Count: 0 requests (7 jours) ðŸ”´

Service Configuration:
  - Desired Count: 1
  - Min Healthy Percent: 100
  - Auto Scaling: DISABLED

Timeline:
  - March 10, 2024: Task started (new deployment)
  - March 15, 2024: Last API request received
  - April 1, 2024: API v2 released (migration)
  - April - Nov 2024: 0 traffic (240 days idle) ðŸ”´

CoÃ»t Mensuel (idle):
  - vCPU: 1.0 Ã— $0.04048 Ã— 730h = $29.55/mois
  - Memory: 2 GB Ã— $0.004445 Ã— 730h = $6.49/mois
  - Load Balancer: ALB $16/mois (idle aussi)
  - TOTAL: $52.04/mois = $625/an ðŸ”´

ðŸ”´ WASTE DETECTED: Task idle (0 traffic for 240 days)
ðŸ’° COST: $52.04/mois = $625/an GASPILLÃ‰S
ðŸ“‹ ACTION: Scale service to 0 OR delete service + task
ðŸ’¡ ROOT CAUSE: API v2 migration complete but v1 service not decommissioned
```

---

## ðŸ ImplÃ©mentation Python

### Code de DÃ©tection

```python
async def scan_fargate_idle_tasks(
    region: str,
    lookback_days: int = 7,
    min_age_days: int = 7
) -> List[Dict]:
    """
    DÃ©tecte les Fargate tasks idle (RUNNING mais 0 traffic rÃ©seau).

    Analyse:
    - Task lastStatus = RUNNING
    - NetworkIn + NetworkOut = 0 bytes (lookback_days)
    - Task age > min_age_days

    Args:
        region: RÃ©gion AWS
        lookback_days: PÃ©riode CloudWatch (dÃ©faut: 7 jours)
        min_age_days: Ã‚ge minimum task (dÃ©faut: 7 jours)

    Returns:
        Liste des tasks idle avec coÃ»ts
    """
    orphans = []

    ecs_client = boto3.client('ecs', region_name=region)
    cloudwatch = boto3.client('cloudwatch', region_name=region)

    try:
        # 1. Liste clusters
        clusters_resp = await ecs_client.list_clusters()
        cluster_arns = clusters_resp.get('clusterArns', [])

        logger.info(f"Found {len(cluster_arns)} ECS clusters in {region}")

        # 2. Pour chaque cluster, liste tasks RUNNING
        for cluster_arn in cluster_arns:
            try:
                # Liste tasks RUNNING
                tasks_resp = await ecs_client.list_tasks(
                    cluster=cluster_arn,
                    desiredStatus='RUNNING',
                    maxResults=100
                )

                task_arns = tasks_resp.get('taskArns', [])

                if not task_arns:
                    continue

                # Describe tasks
                tasks_desc = await ecs_client.describe_tasks(
                    cluster=cluster_arn,
                    tasks=task_arns
                )

                tasks = tasks_desc.get('tasks', [])

                # Analyse chaque task RUNNING
                for task in tasks:
                    try:
                        started_at = task.get('startedAt')
                        task_arn = task.get('taskArn')
                        task_definition_arn = task.get('taskDefinitionArn')
                        launch_type = task.get('launchType', 'UNKNOWN')

                        # Filtrer: Fargate uniquement
                        if launch_type != 'FARGATE':
                            continue

                        # Calcule Ã¢ge de la task
                        if not started_at:
                            continue

                        age_days = (datetime.now(timezone.utc) - started_at).days

                        # Filtre: Ã¢ge minimum
                        if age_days < min_age_days:
                            continue

                        # RÃ©cupÃ¨re task definition pour CPU/Memory
                        task_def_resp = await ecs_client.describe_task_definition(
                            taskDefinition=task_definition_arn
                        )
                        task_def = task_def_resp['taskDefinition']

                        cpu = int(task_def.get('cpu', '256'))  # CPU units (256 = 0.25 vCPU)
                        memory = int(task_def.get('memory', '512'))  # Memory MB

                        # Convertir CPU units â†’ vCPU
                        vcpu = cpu / 1024.0
                        memory_gb = memory / 1024.0

                        # CloudWatch metrics: NetworkIn + NetworkOut
                        end_time = datetime.now(timezone.utc)
                        start_time = end_time - timedelta(days=lookback_days)

                        # NetworkIn
                        network_in_metrics = await cloudwatch.get_metric_statistics(
                            Namespace='ECS/ContainerInsights',
                            MetricName='NetworkRxBytes',
                            Dimensions=[
                                {'Name': 'ClusterName', 'Value': cluster_arn.split('/')[-1]},
                                {'Name': 'TaskId', 'Value': task_arn.split('/')[-1]}
                            ],
                            StartTime=start_time,
                            EndTime=end_time,
                            Period=86400,  # 1 jour
                            Statistics=['Sum']
                        )

                        # NetworkOut
                        network_out_metrics = await cloudwatch.get_metric_statistics(
                            Namespace='ECS/ContainerInsights',
                            MetricName='NetworkTxBytes',
                            Dimensions=[
                                {'Name': 'ClusterName', 'Value': cluster_arn.split('/')[-1]},
                                {'Name': 'TaskId', 'Value': task_arn.split('/')[-1]}
                            ],
                            StartTime=start_time,
                            EndTime=end_time,
                            Period=86400,  # 1 jour
                            Statistics=['Sum']
                        )

                        total_network_in = sum(
                            point['Sum'] for point in network_in_metrics.get('Datapoints', [])
                        )
                        total_network_out = sum(
                            point['Sum'] for point in network_out_metrics.get('Datapoints', [])
                        )

                        total_network = total_network_in + total_network_out

                        # ðŸ”´ DÃ‰TECTION: 0 bytes network traffic
                        if total_network == 0:

                            # Calcule coÃ»t mensuel
                            vcpu_cost = vcpu * 0.04048 * 730
                            memory_cost = memory_gb * 0.004445 * 730
                            monthly_cost = vcpu_cost + memory_cost

                            # Niveau de confiance
                            if age_days >= 90:
                                confidence = "critical"
                            elif age_days >= 30:
                                confidence = "high"
                            else:
                                confidence = "medium"

                            # MÃ©tadonnÃ©es
                            metadata = {
                                "task_arn": task_arn,
                                "task_definition": task_definition_arn.split('/')[-1],
                                "cluster_name": cluster_arn.split('/')[-1],
                                "vcpu": vcpu,
                                "memory_gb": round(memory_gb, 2),
                                "age_days": age_days,
                                "network_in_bytes_7d": int(total_network_in),
                                "network_out_bytes_7d": int(total_network_out),
                                "total_network_bytes": int(total_network),
                                "confidence": confidence
                            }

                            orphan = {
                                "resource_id": task_arn,
                                "resource_name": task_definition_arn.split('/')[-1],
                                "resource_type": "fargate_task",
                                "region": region,
                                "orphan_type": "idle_task",
                                "estimated_monthly_cost": round(monthly_cost, 2),
                                "metadata": metadata,
                                "detection_timestamp": datetime.now(timezone.utc).isoformat()
                            }

                            orphans.append(orphan)

                            logger.info(
                                f"Idle Fargate task: {task_definition_arn.split('/')[-1]} "
                                f"(0 network traffic, ${monthly_cost:.2f}/mois)"
                            )

                    except Exception as e:
                        logger.error(f"Error analyzing task {task.get('taskArn')}: {e}")
                        continue

            except ClientError as e:
                error_code = e.response.get('Error', {}).get('Code', '')
                logger.error(f"Error listing tasks for cluster {cluster_arn}: {error_code}")
                continue

        logger.info(f"Found {len(orphans)} idle Fargate tasks in {region}")
        return orphans

    except Exception as e:
        logger.error(f"Error scanning Fargate idle tasks in {region}: {e}")
        raise
```

---

## ðŸ§ª Test Unitaire

```python
import pytest
from moto import mock_ecs, mock_cloudwatch
import boto3
from datetime import datetime, timezone

@mock_ecs
@mock_cloudwatch
async def test_scan_fargate_idle_tasks():
    """Test de dÃ©tection des Fargate tasks idle."""

    region = 'us-east-1'

    # Setup
    ecs = boto3.client('ecs', region_name=region)
    cloudwatch = boto3.client('cloudwatch', region_name=region)

    # CrÃ©er cluster
    cluster_resp = ecs.create_cluster(clusterName='test-cluster')
    cluster_arn = cluster_resp['cluster']['clusterArn']

    # Enregistrer task definition
    ecs.register_task_definition(
        family='web-app',
        requiresCompatibilities=['FARGATE'],
        networkMode='awsvpc',
        cpu='1024',  # 1 vCPU
        memory='2048',  # 2 GB
        containerDefinitions=[
            {
                'name': 'web',
                'image': 'nginx:latest',
                'memory': 2048
            }
        ]
    )

    # Note: moto limitations pour CloudWatch metrics
    # Dans un environnement rÃ©el, on mockerait NetworkIn/Out metrics

    # ExÃ©cution
    orphans = await scan_fargate_idle_tasks(
        region=region,
        lookback_days=7,
        min_age_days=7
    )

    # VÃ©rifications
    # Note: Test simplifiÃ© car moto ne supporte pas complÃ¨tement ECS Container Insights

    # 1. VÃ©rifier structure orphans
    for orphan in orphans:
        assert orphan['orphan_type'] == 'idle_task'
        assert orphan['metadata']['total_network_bytes'] == 0
        assert orphan['estimated_monthly_cost'] > 0  # CoÃ»t vCPU + Memory

    # 2. VÃ©rifier calcul coÃ»t (1 vCPU + 2 GB)
    if orphans:
        # 1 vCPU = 1024 CPU units, 2 GB = 2048 MB
        expected_cost = (1.0 * 0.04048 * 730) + (2.0 * 0.004445 * 730)
        assert abs(orphans[0]['estimated_monthly_cost'] - expected_cost) < 0.01

    print(f"âœ… Test passed: {len(orphans)} idle tasks detected")
```

---

## âœ… Recommandations

1. **Auto-scaling Ã  0**:
   ```python
   # Configure service min tasks = 0 (si traffic sporadique)
   ecs.update_service(
       cluster='prod-cluster',
       service='legacy-api',
       desiredCount=0  # Scale to 0
   )
   ```

2. **Monitoring Alerts**:
   - CloudWatch alarm: NetworkIn + NetworkOut = 0 pendant 7 jours â†’ Alert
   - Lambda weekly scan: Identifier tasks idle â†’ Slack notification

3. **Tagging pour Review**:
   ```json
   {
     "Environment": "production",
     "Owner": "backend-team",
     "LastReviewDate": "2024-11-01",
     "AutoScaleToZero": "true"
   }
   ```

4. **Grace Period**:
   - 7 jours idle â†’ Warning
   - 30 jours idle â†’ Scale to 0 automatic
   - 90 jours idle â†’ Delete service

---
# ðŸ“‰ ScÃ©nario 3: CPU/Memory Over-Provisioned (<10% Utilization)

## ðŸ“‹ Description du ProblÃ¨me

Une **Fargate task over-provisioned** est une task avec des ressources CPU/Memory **largement surdimensionnÃ©es** par rapport Ã  son utilisation rÃ©elle. SymptÃ´mes:

- **CPU Utilization < 10%** (moyenne sur 30 jours)
- **Memory Utilization < 50%** (moyenne sur 30 jours)
- **CoÃ»t gaspillÃ©** = (Provisioned - Used) Ã— Prix

AWS Fargate facture uniquement les ressources **provisionnÃ©es** (pas utilisÃ©es). Une task configurÃ©e avec **4 vCPU + 8 GB** mais utilisant rÃ©ellement **0.5 vCPU + 2 GB** gaspille **87.5% de son coÃ»t**.

### ðŸ”´ Causes Typiques

1. **Copy-paste config** â†’ Copier config d'un service haute performance vers service lÃ©ger
2. **Provisioning "par sÃ©curitÃ©"** â†’ Allouer 4 vCPU "au cas oÃ¹" alors que 0.5 vCPU suffisent
3. **Pas de right-sizing** â†’ Jamais revu la config depuis le lancement (2+ ans ago)
4. **Workload change** â†’ Traffic divisÃ© par 10 mais config identique
5. **Dev/Staging over-provisioned** â†’ MÃªme config que prod mais 10Ã— moins de traffic

---

## ðŸ’° Impact Financier

### Calcul du CoÃ»t

**Formule Gaspillage**:
```
CoÃ»t GaspillÃ© = (vCPU Provisioned - vCPU Used) Ã— $0.04048 Ã— 730h
              + (Memory Provisioned - Memory Used) Ã— $0.004445 Ã— 730h
```

### ðŸ“Š Exemple 1: Task 4 vCPU + 8 GB â†’ Right-Size 0.5 vCPU + 1 GB

```
Configuration ACTUELLE (Over-Provisioned):
  - vCPU: 4.0
  - Memory: 8 GB

Utilization RÃ‰ELLE (CloudWatch 30 jours):
  - CPU: 8% average (= 0.32 vCPU effective)
  - Memory: 12% average (= 0.96 GB effective)

CoÃ»t ACTUEL:
  - vCPU: 4.0 Ã— $0.04048 Ã— 730h = $118.20/mois
  - Memory: 8 GB Ã— $0.004445 Ã— 730h = $25.94/mois
  - TOTAL: $144.14/mois = $1,730/an ðŸ”´

Configuration OPTIMISÃ‰E (Right-Sized):
  - vCPU: 0.5 (avec 25% marge)
  - Memory: 1 GB (avec 10% marge)

CoÃ»t OPTIMISÃ‰:
  - vCPU: 0.5 Ã— $0.04048 Ã— 730h = $14.78/mois
  - Memory: 1 GB Ã— $0.004445 Ã— 730h = $3.24/mois
  - TOTAL: $18.02/mois = $216/an âœ…

ðŸ’° Ã‰CONOMIE: $144.14 - $18.02 = $126.12/mois = $1,514/an per task (87.5% rÃ©duction!)
```

### ðŸ“Š Exemple 2: 80 Tasks Over-Provisioned (Organisation Typique)

```
Entreprise: SaaS avec 200 Fargate tasks total

Audit CloudWatch (30 jours):
  - 120 tasks: Utilization OK (CPU >30%, Memory >50%)
  - 80 tasks: Over-provisioned (CPU <10%, Memory <50%) ðŸ”´

DÃ©tails des 80 tasks over-provisioned:
  - Config moyenne: 2 vCPU + 4 GB
  - Utilization moyenne: CPU 7%, Memory 20%
  - Right-size optimal: 0.5 vCPU + 1 GB

CoÃ»t ACTUEL (80 tasks over-provisioned):
  Config: 2 vCPU + 4 GB
  CoÃ»t: (2 Ã— $0.04048 + 4 Ã— $0.004445) Ã— 730 = $72.08/task/mois
  Total: 80 tasks Ã— $72.08 = $5,766/mois = $69,192/an ðŸ”´

CoÃ»t OPTIMISÃ‰ (aprÃ¨s right-sizing):
  Config: 0.5 vCPU + 1 GB
  CoÃ»t: (0.5 Ã— $0.04048 + 1 Ã— $0.004445) Ã— 730 = $18.02/task/mois
  Total: 80 tasks Ã— $18.02 = $1,442/mois = $17,304/an âœ…

ðŸ’° Ã‰CONOMIE: $5,766 - $1,442 = $4,324/mois = $51,888/an (75% rÃ©duction!)
ðŸ’¡ ROI: Right-sizing 80 tasks = 2 jours de travail â†’ $51,888/an saved â†’ ROI 1:10,000+
```

---

## ðŸ” DÃ©tection du Gaspillage

### CritÃ¨res de DÃ©tection

1. **Task status = RUNNING**
2. **Launch type = FARGATE**
3. **CPU Utilization < 10%** (moyenne 30 jours CloudWatch)
4. **Memory Utilization < 50%** (moyenne 30 jours CloudWatch)
5. **Task age > 30 jours** (pas une task qui vient de dÃ©marrer)
6. **Right-sizing potential > 50%** (Ã©conomie â‰¥ 50% possible)

### ðŸ“Š Exemple Concret

```
Task ARN:          arn:aws:ecs:us-east-1:123456789012:task/prod-cluster/def456
Task Definition:   api-backend:67
Cluster:           prod-cluster
Service:           api-backend-service
Launch Type:       FARGATE
Desired Status:    RUNNING
Last Status:       RUNNING
Started At:        2023-01-15 10:30:00 UTC (660 days ago)

Task Configuration (ACTUELLE):
  - vCPU: 2.0
  - Memory: 4 GB
  - Platform Version: 1.4.0
  - Cost: $72.08/mois

CloudWatch Metrics (30 derniers jours):
  - CPUUtilization:
    - Average: 5.2% ðŸ”´
    - Max: 18% (peak traffic)
    - P99: 12%
    - Effective vCPU used: 0.104 vCPU (5.2% Ã— 2.0)

  - MemoryUtilization:
    - Average: 32% ðŸ”´
    - Max: 48% (peak)
    - P99: 42%
    - Effective Memory used: 1.28 GB (32% Ã— 4 GB)

Service Traffic Pattern:
  - Requests/day: ~50,000 (stable)
  - Peak requests/hour: 3,000
  - Response time P95: 45ms (trÃ¨s rapide = under-utilized)

Right-Sizing Analysis:
  - CPU Required (P99 + 25% marge): 0.12 Ã— 1.25 = 0.15 vCPU
    â†’ Fargate config: 0.25 vCPU (minimum) âœ…

  - Memory Required (P99 + 10% marge): 1.68 GB Ã— 1.10 = 1.85 GB
    â†’ Fargate config: 2 GB âœ…

Configuration OPTIMALE:
  - vCPU: 0.25 (vs 2.0 actuel = -87.5%)
  - Memory: 2 GB (vs 4 GB actuel = -50%)

CoÃ»t ACTUEL:
  - vCPU: 2.0 Ã— $0.04048 Ã— 730 = $59.10/mois
  - Memory: 4 GB Ã— $0.004445 Ã— 730 = $12.98/mois
  - TOTAL: $72.08/mois = $865/an ðŸ”´

CoÃ»t OPTIMISÃ‰:
  - vCPU: 0.25 Ã— $0.04048 Ã— 730 = $7.39/mois
  - Memory: 2 GB Ã— $0.004445 Ã— 730 = $6.49/mois
  - TOTAL: $13.88/mois = $167/an âœ…

ðŸ’° Ã‰CONOMIE: $72.08 - $13.88 = $58.20/mois = $698/an per task (81% rÃ©duction!)

Timeline:
  - Jan 2023: Task launched with 2 vCPU + 4 GB (initial config)
  - Mar 2023: Traffic stable ~50K req/day (CPU <10%)
  - 2023-2024: Jamais de right-sizing review ðŸ”´
  - Today (Nov 2024): 660 days over-provisioned

Total Wasted (660 days):
  $58.20/mois Ã— 22 mois = $1,280 ðŸ”´

ðŸ”´ WASTE DETECTED: Over-provisioned (CPU 5%, Memory 32% for 660 days)
ðŸ’° COST: $58.20/mois = $698/an GASPILLÃ‰S
ðŸ“‹ ACTION: Right-size to 0.25 vCPU + 2 GB (immediate 81% savings)
ðŸ’¡ ROOT CAUSE: Initial over-provisioning "par sÃ©curitÃ©" jamais revu

Performance Validation:
  âœ… Response time OK aprÃ¨s right-sizing (tested in staging)
  âœ… CPU headroom 25% (0.15 used vs 0.25 provisioned)
  âœ… Memory headroom 10% (1.85 GB used vs 2 GB provisioned)
  âœ… Zero impact on SLA
```

---

## ðŸ ImplÃ©mentation Python

### Code de DÃ©tection

```python
async def scan_fargate_over_provisioned(
    region: str,
    cpu_threshold_percent: float = 10.0,
    memory_threshold_percent: float = 50.0,
    lookback_days: int = 30,
    min_age_days: int = 30
) -> List[Dict]:
    """
    DÃ©tecte les Fargate tasks over-provisioned (CPU/Memory sous-utilisÃ©s).

    Analyse:
    - Task lastStatus = RUNNING
    - CPUUtilization < cpu_threshold_percent (30 jours)
    - MemoryUtilization < memory_threshold_percent (30 jours)
    - Calcule right-sizing recommendations

    Args:
        region: RÃ©gion AWS
        cpu_threshold_percent: Seuil CPU (dÃ©faut: 10%)
        memory_threshold_percent: Seuil Memory (dÃ©faut: 50%)
        lookback_days: PÃ©riode CloudWatch (dÃ©faut: 30 jours)
        min_age_days: Ã‚ge minimum task (dÃ©faut: 30 jours)

    Returns:
        Liste des tasks over-provisioned avec Ã©conomies potentielles
    """
    orphans = []

    ecs_client = boto3.client('ecs', region_name=region)
    cloudwatch = boto3.client('cloudwatch', region_name=region)

    try:
        # 1. Liste clusters
        clusters_resp = await ecs_client.list_clusters()
        cluster_arns = clusters_resp.get('clusterArns', [])

        logger.info(f"Found {len(cluster_arns)} ECS clusters in {region}")

        # 2. Pour chaque cluster, liste tasks RUNNING
        for cluster_arn in cluster_arns:
            try:
                # Liste tasks RUNNING
                tasks_resp = await ecs_client.list_tasks(
                    cluster=cluster_arn,
                    desiredStatus='RUNNING',
                    maxResults=100
                )

                task_arns = tasks_resp.get('taskArns', [])

                if not task_arns:
                    continue

                # Describe tasks
                tasks_desc = await ecs_client.describe_tasks(
                    cluster=cluster_arn,
                    tasks=task_arns
                )

                tasks = tasks_desc.get('tasks', [])

                # Analyse chaque task RUNNING
                for task in tasks:
                    try:
                        started_at = task.get('startedAt')
                        task_arn = task.get('taskArn')
                        task_definition_arn = task.get('taskDefinitionArn')
                        launch_type = task.get('launchType', 'UNKNOWN')

                        # Filtrer: Fargate uniquement
                        if launch_type != 'FARGATE':
                            continue

                        # Calcule Ã¢ge de la task
                        if not started_at:
                            continue

                        age_days = (datetime.now(timezone.utc) - started_at).days

                        # Filtre: Ã¢ge minimum
                        if age_days < min_age_days:
                            continue

                        # RÃ©cupÃ¨re task definition pour CPU/Memory
                        task_def_resp = await ecs_client.describe_task_definition(
                            taskDefinition=task_definition_arn
                        )
                        task_def = task_def_resp['taskDefinition']

                        cpu = int(task_def.get('cpu', '256'))  # CPU units
                        memory = int(task_def.get('memory', '512'))  # Memory MB

                        # Convertir
                        vcpu = cpu / 1024.0
                        memory_gb = memory / 1024.0

                        # CloudWatch metrics: CPU + Memory Utilization
                        end_time = datetime.now(timezone.utc)
                        start_time = end_time - timedelta(days=lookback_days)

                        # CPU Utilization
                        cpu_metrics = await cloudwatch.get_metric_statistics(
                            Namespace='ECS/ContainerInsights',
                            MetricName='CpuUtilized',
                            Dimensions=[
                                {'Name': 'ClusterName', 'Value': cluster_arn.split('/')[-1]},
                                {'Name': 'TaskId', 'Value': task_arn.split('/')[-1]}
                            ],
                            StartTime=start_time,
                            EndTime=end_time,
                            Period=3600,  # 1 heure
                            Statistics=['Average']
                        )

                        # Memory Utilization
                        memory_metrics = await cloudwatch.get_metric_statistics(
                            Namespace='ECS/ContainerInsights',
                            MetricName='MemoryUtilized',
                            Dimensions=[
                                {'Name': 'ClusterName', 'Value': cluster_arn.split('/')[-1]},
                                {'Name': 'TaskId', 'Value': task_arn.split('/')[-1]}
                            ],
                            StartTime=start_time,
                            EndTime=end_time,
                            Period=3600,  # 1 heure
                            Statistics=['Average']
                        )

                        cpu_datapoints = cpu_metrics.get('Datapoints', [])
                        memory_datapoints = memory_metrics.get('Datapoints', [])

                        if not cpu_datapoints or not memory_datapoints:
                            continue  # Pas de metrics disponibles

                        # Calcule utilization moyenne
                        avg_cpu_utilized = sum(p['Average'] for p in cpu_datapoints) / len(cpu_datapoints)
                        avg_memory_utilized = sum(p['Average'] for p in memory_datapoints) / len(memory_datapoints)

                        # Convertir en %
                        cpu_utilization_percent = (avg_cpu_utilized / (vcpu * 1024)) * 100
                        memory_utilization_percent = (avg_memory_utilized / (memory_gb * 1024)) * 100

                        # ðŸ”´ DÃ‰TECTION: CPU <10% OU Memory <50%
                        if cpu_utilization_percent < cpu_threshold_percent or memory_utilization_percent < memory_threshold_percent:

                            # Right-sizing recommendations
                            # CPU: P99 + 25% marge
                            cpu_p99 = max((p['Average'] for p in cpu_datapoints), default=0)
                            recommended_vcpu = max(0.25, (cpu_p99 / 1024) * 1.25)  # Min 0.25 vCPU

                            # Memory: P99 + 10% marge
                            memory_p99 = max((p['Average'] for p in memory_datapoints), default=0)
                            recommended_memory_gb = max(0.5, (memory_p99 / 1024) * 1.10)  # Min 0.5 GB

                            # Arrondir aux configs Fargate valides
                            # vCPU: 0.25, 0.5, 1, 2, 4, 8, 16
                            # Memory: dÃ©pend vCPU
                            fargate_vcpu_configs = [0.25, 0.5, 1, 2, 4, 8, 16]
                            recommended_vcpu = min(fargate_vcpu_configs, key=lambda x: abs(x - recommended_vcpu) if x >= recommended_vcpu else float('inf'))

                            # Memory: arrondir au GB supÃ©rieur
                            recommended_memory_gb = math.ceil(recommended_memory_gb)

                            # Calcule Ã©conomie
                            current_cost = (vcpu * 0.04048 * 730) + (memory_gb * 0.004445 * 730)
                            optimized_cost = (recommended_vcpu * 0.04048 * 730) + (recommended_memory_gb * 0.004445 * 730)
                            monthly_savings = current_cost - optimized_cost
                            savings_percent = (monthly_savings / current_cost * 100) if current_cost > 0 else 0

                            # Filtre: Ã©conomie > 50%
                            if savings_percent < 50:
                                continue

                            # Niveau de confiance
                            if age_days >= 180:
                                confidence = "critical"
                            elif age_days >= 90:
                                confidence = "high"
                            else:
                                confidence = "medium"

                            # MÃ©tadonnÃ©es
                            metadata = {
                                "task_arn": task_arn,
                                "task_definition": task_definition_arn.split('/')[-1],
                                "cluster_name": cluster_arn.split('/')[-1],
                                "current_vcpu": vcpu,
                                "current_memory_gb": round(memory_gb, 2),
                                "cpu_utilization_percent": round(cpu_utilization_percent, 2),
                                "memory_utilization_percent": round(memory_utilization_percent, 2),
                                "recommended_vcpu": recommended_vcpu,
                                "recommended_memory_gb": recommended_memory_gb,
                                "current_monthly_cost": round(current_cost, 2),
                                "optimized_monthly_cost": round(optimized_cost, 2),
                                "monthly_savings": round(monthly_savings, 2),
                                "savings_percent": round(savings_percent, 2),
                                "age_days": age_days,
                                "confidence": confidence
                            }

                            orphan = {
                                "resource_id": task_arn,
                                "resource_name": task_definition_arn.split('/')[-1],
                                "resource_type": "fargate_task",
                                "region": region,
                                "orphan_type": "over_provisioned",
                                "estimated_monthly_cost": round(monthly_savings, 2),  # Ã‰conomie potentielle
                                "metadata": metadata,
                                "detection_timestamp": datetime.now(timezone.utc).isoformat()
                            }

                            orphans.append(orphan)

                            logger.info(
                                f"Over-provisioned Fargate task: {task_definition_arn.split('/')[-1]} "
                                f"(CPU {cpu_utilization_percent:.1f}%, Memory {memory_utilization_percent:.1f}%, "
                                f"${monthly_savings:.2f}/mois savings)"
                            )

                    except Exception as e:
                        logger.error(f"Error analyzing task {task.get('taskArn')}: {e}")
                        continue

            except ClientError as e:
                error_code = e.response.get('Error', {}).get('Code', '')
                logger.error(f"Error listing tasks for cluster {cluster_arn}: {error_code}")
                continue

        logger.info(f"Found {len(orphans)} over-provisioned Fargate tasks in {region}")
        return orphans

    except Exception as e:
        logger.error(f"Error scanning Fargate over-provisioned tasks in {region}: {e}")
        raise
```

---

## ðŸ§ª Test Unitaire

```python
import pytest
from moto import mock_ecs, mock_cloudwatch
import boto3
from datetime import datetime, timezone
import math

@mock_ecs
@mock_cloudwatch
async def test_scan_fargate_over_provisioned():
    """Test de dÃ©tection des Fargate tasks over-provisioned."""

    region = 'us-east-1'

    # Setup
    ecs = boto3.client('ecs', region_name=region)
    cloudwatch = boto3.client('cloudwatch', region_name=region)

    # CrÃ©er cluster
    cluster_resp = ecs.create_cluster(clusterName='test-cluster')
    cluster_arn = cluster_resp['cluster']['clusterArn']

    # Enregistrer task definition over-provisioned
    ecs.register_task_definition(
        family='api-backend',
        requiresCompatibilities=['FARGATE'],
        networkMode='awsvpc',
        cpu='2048',  # 2 vCPU
        memory='4096',  # 4 GB
        containerDefinitions=[
            {
                'name': 'api',
                'image': 'nginx:latest',
                'memory': 4096
            }
        ]
    )

    # Note: moto limitations pour CloudWatch metrics
    # Dans un environnement rÃ©el, on mockerait CPUUtilization <10%

    # ExÃ©cution
    orphans = await scan_fargate_over_provisioned(
        region=region,
        cpu_threshold_percent=10.0,
        memory_threshold_percent=50.0,
        lookback_days=30,
        min_age_days=30
    )

    # VÃ©rifications
    # Note: Test simplifiÃ© car moto ne supporte pas complÃ¨tement ECS Container Insights

    # 1. VÃ©rifier structure orphans
    for orphan in orphans:
        assert orphan['orphan_type'] == 'over_provisioned'
        assert orphan['metadata']['cpu_utilization_percent'] < 10 or orphan['metadata']['memory_utilization_percent'] < 50
        assert orphan['metadata']['savings_percent'] >= 50
        assert orphan['estimated_monthly_cost'] > 0  # Ã‰conomie potentielle

    # 2. VÃ©rifier right-sizing recommendations
    for orphan in orphans:
        assert orphan['metadata']['recommended_vcpu'] <= orphan['metadata']['current_vcpu']
        assert orphan['metadata']['recommended_memory_gb'] <= orphan['metadata']['current_memory_gb']

    print(f"âœ… Test passed: {len(orphans)} over-provisioned tasks detected")
```

---

## âœ… Recommandations

### 1. Right-Sizing Process

**Ã‰tape 1: Audit CloudWatch (30 jours)**
```python
# Analyser CPU/Memory utilization P99
cpu_p99 = get_cloudwatch_p99('CpuUtilized', task_arn, days=30)
memory_p99 = get_cloudwatch_p99('MemoryUtilized', task_arn, days=30)

# Recommandation: P99 + marge
recommended_vcpu = cpu_p99 * 1.25  # +25% marge
recommended_memory = memory_p99 * 1.10  # +10% marge
```

**Ã‰tape 2: Test en Staging**
- DÃ©ployer nouvelle config en staging
- Valider performance (response time, error rate)
- Load test pour valider headroom

**Ã‰tape 3: DÃ©ploiement Progressif Prod**
- Canary deployment: 10% â†’ 50% â†’ 100%
- Monitoring CloudWatch alerts
- Rollback si dÃ©gradation

### 2. Fargate CPU/Memory Configurations Valides

| vCPU | Memory Options (GB) | Use Case |
|------|---------------------|----------|
| **0.25** | 0.5, 1, 2 | Micro services, cron jobs |
| **0.5** | 1, 2, 3, 4 | Small APIs, workers |
| **1** | 2, 3, 4, 5, 6, 7, 8 | **Standard APIs** âœ… |
| **2** | 4-16 GB | Medium workloads |
| **4** | 8-30 GB | Large workloads |
| **8** | 16-60 GB | Very large |
| **16** | 32-120 GB | Extreme |

ðŸ’¡ **RÃ¨gle 80/20**: 80% des workloads fonctionnent avec **0.5-1 vCPU + 1-2 GB**

### 3. Monitoring Continu

```python
# CloudWatch alarm: CPU >80% (sous-provisionnÃ©)
cloudwatch.put_metric_alarm(
    AlarmName='fargate-task-cpu-high',
    MetricName='CPUUtilization',
    Threshold=80,
    ComparisonOperator='GreaterThanThreshold'
)

# CloudWatch alarm: CPU <10% (over-provisionnÃ©)
cloudwatch.put_metric_alarm(
    AlarmName='fargate-task-cpu-low',
    MetricName='CPUUtilization',
    Threshold=10,
    ComparisonOperator='LessThanThreshold'
)
```

### 4. Automation (Right-Sizing Lambda)

```python
# Lambda triggered monthly
# Auto-detect over-provisioned tasks â†’ Slack notification
for task in fargate_tasks:
    if task['cpu_utilization'] < 10:
        # Recommandation right-sizing
        send_slack_alert(
            f"Task {task['name']} over-provisioned (CPU {task['cpu_util']}%)\n"
            f"Current: {task['vcpu']} vCPU, {task['memory']} GB = ${task['cost']}/mois\n"
            f"Recommended: {task['recommended_vcpu']} vCPU, {task['recommended_memory']} GB = ${task['optimized_cost']}/mois\n"
            f"Savings: ${task['savings']}/mois = ${task['savings']*12}/an"
        )
```

---
