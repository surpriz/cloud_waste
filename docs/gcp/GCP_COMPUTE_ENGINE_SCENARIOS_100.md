# CloudWaste - Couverture 100% GCP Compute Engine Instances

**Resource Type:** `Compute : Compute Engine Instances`
**Provider:** Google Cloud Platform (GCP)
**API:** `compute.googleapis.com` (Compute Engine API v1)
**√âquivalents:** AWS EC2 Instances, Azure Virtual Machines
**Total Scenarios:** 10 (100% coverage)

---

## üìã Table des Mati√®res

- [Vue d'Ensemble](#vue-densemble)
- [Mod√®le de Pricing GCP](#mod√®le-de-pricing-gcp)
- [Phase 1 - D√©tection Simple (7 sc√©narios)](#phase-1---d√©tection-simple-7-sc√©narios)
  - [1. Instances Arr√™t√©es >30 Jours](#1-compute_instance_stopped---instances-arr√™t√©es-30-jours)
  - [2. Instances Inactives (CPU <5%)](#2-compute_instance_idle---instances-inactives-cpu-5)
  - [3. Instances Sur-Provisionn√©es (CPU <30%)](#3-compute_instance_overprovisioned---instances-sur-provisionn√©es-cpu-30)
  - [4. Anciennes G√©n√©rations de Machines](#4-compute_instance_old_generation---anciennes-g√©n√©rations-de-machines)
  - [5. Absence d'Usage Spot/Preemptible](#5-compute_instance_no_spot---absence-dusage-spotpreemptible)
  - [6. Instances Non Tagu√©es](#6-compute_instance_untagged---instances-non-tagu√©es)
  - [7. Instances Dev/Test 24/7](#7-compute_instance_devtest_247---instances-devtest-247)
- [Phase 2 - D√©tection Avanc√©e (3 sc√©narios)](#phase-2---d√©tection-avanc√©e-3-sc√©narios)
  - [8. M√©moire Sur-Provisionn√©e (<40% usage)](#8-compute_instance_memory_waste---m√©moire-sur-provisionn√©e-40-usage)
  - [9. Opportunit√©s de Right-Sizing](#9-compute_instance_rightsizing---opportunit√©s-de-right-sizing)
  - [10. Instances Burstable Sous-Utilis√©es](#10-compute_instance_burstable_waste---instances-burstable-sous-utilis√©es)
- [Protocole de Test](#protocole-de-test)
- [R√©f√©rences](#r√©f√©rences)

---

## Vue d'Ensemble

### Contexte GCP Compute Engine

Google Cloud Platform facture les **Compute Engine Instances** √† la seconde (minimum 1 minute) avec des **Sustained Use Discounts (SUD)** automatiques :

- **Sustained Use Discounts (SUD)** : -30% automatique apr√®s 25% du mois d'utilisation
- **Committed Use Discounts (CUD)** : -57% pour 1 an, -70% pour 3 ans (engagement)
- **Spot VMs** : -60% √† -91% (anciennes preemptible) - interruptibles
- **Machine Types** : n1 (ancienne g√©n√©ration), n2/n2d (moderne), e2 (burstable), c2/c2d (compute-optimized)

### Waste Typique

1. **Instances arr√™t√©es** : Paiement des disques attach√©s ($0.04-0.17/GB/mois)
2. **Idle instances** : CPU <5% - 95% de gaspillage
3. **Over-provisioning** : CPU <30% - opportunit√©s de downgrade
4. **Anciennes g√©n√©rations** : n1 ‚Üí n2 = -20% √† -30% de co√ªt
5. **Non-usage Spot** : 60-91% d'√©conomies potentielles

---

## Mod√®le de Pricing GCP

### Exemples de Co√ªts Mensuels (us-central1)

| Machine Type | vCPUs | RAM (GB) | Prix Standard | Prix Spot | √âconomie Spot |
|-------------|-------|---------|---------------|-----------|---------------|
| **e2-micro** | 0.25 | 1 GB | $7.11/mois | $2.84/mois | -60% |
| **e2-small** | 0.5 | 2 GB | $14.23/mois | $5.69/mois | -60% |
| **n1-standard-1** | 1 | 3.75 GB | $24.27/mois | $7.30/mois | -70% |
| **n2-standard-2** | 2 | 8 GB | $71.17/mois | $17.08/mois | -76% |
| **n2-standard-4** | 4 | 16 GB | $142.34/mois | $34.16/mois | -76% |
| **n2-standard-8** | 8 | 32 GB | $284.68/mois | $68.32/mois | -76% |
| **c2-standard-4** | 4 | 16 GB | $163.73/mois | $39.30/mois | -76% |
| **c2-standard-8** | 8 | 32 GB | $327.46/mois | $78.59/mois | -76% |

**Notes :**
- Pricing incluant Sustained Use Discounts (SUD) automatique
- Spot pricing variable selon disponibilit√© (60-91% discount)
- n2/n2d 20-30% moins cher que n1 √† performance √©quivalente
- Disques persistants factur√©s m√™me quand instance arr√™t√©e

---

## Phase 1 - D√©tection Simple (7 sc√©narios)

### 1. `compute_instance_stopped` - Instances Arr√™t√©es >30 Jours

#### D√©tection

**Logique :**
```python
# 1. Lister toutes les instances via Compute Engine API
instances = compute_client.instances().aggregatedList(project=project_id).execute()

# 2. Filtrer instances avec status = 'TERMINATED'
for zone, instances_scoped in instances.get('items', {}).items():
    for instance in instances_scoped.get('instances', []):
        if instance['status'] == 'TERMINATED':
            # 3. Calculer √¢ge depuis derni√®re modification
            last_stop = parse_timestamp(instance.get('lastStopTimestamp'))
            age_days = (now - last_stop).days

            # 4. D√©tection si √¢ge > seuil configurable (d√©faut: 30 jours)
            if age_days >= min_age_days:
                # Instance arr√™t√©e = waste d√©tect√©
```

**Crit√®res :**
- `status == 'TERMINATED'`
- `age >= min_age_days` (d√©faut: 30 jours)

**API Calls :**
```python
# Google Cloud Compute Engine API v1
compute_client.instances().aggregatedList(
    project='my-project',
    filter='status=TERMINATED'
).execute()
```

#### Calcul de Co√ªt

**Formule :**

Instances arr√™t√©es ne paient **QUE les disques attach√©s** (pas de compute) :

```python
# Co√ªt mensuel = somme des disques persistants attach√©s
monthly_cost = 0

for disk in instance['disks']:
    disk_size_gb = disk['diskSizeGb']
    disk_type = disk['type']  # pd-standard, pd-ssd, pd-balanced

    # Prix par GB/mois selon type
    disk_pricing = {
        'pd-standard': 0.040,  # $0.040/GB/mois (HDD)
        'pd-balanced': 0.100,  # $0.100/GB/mois (SSD √©quilibr√©)
        'pd-ssd': 0.170,       # $0.170/GB/mois (SSD performance)
    }

    monthly_cost += disk_size_gb * disk_pricing.get(disk_type, 0.040)

# Co√ªt gaspill√© cumul√©
already_wasted = monthly_cost * (age_days / 30.0)
```

**Exemple :**

Instance arr√™t√©e avec 100 GB pd-standard + 50 GB pd-ssd depuis 60 jours :
```python
monthly_cost = (100 * $0.040) + (50 * $0.170) = $4 + $8.50 = $12.50/mois
already_wasted = $12.50 * (60/30) = $25.00
```

#### Param√®tres Configurables

| Param√®tre | Type | D√©faut | Description |
|-----------|------|--------|-------------|
| `min_age_days` | int | 30 | √Çge minimum en jours avant d√©tection |
| `exclude_labels` | dict | `{}` | Labels pour exclure instances (ex: `{'environment': 'backup'}`) |

#### M√©tadonn√©es Exemple

```json
{
  "resource_id": "instance-1234567890123456789",
  "resource_name": "dev-api-server",
  "resource_type": "compute_instance_stopped",
  "zone": "us-central1-a",
  "machine_type": "n1-standard-2",
  "status": "TERMINATED",
  "last_stop_timestamp": "2024-09-15T10:30:00Z",
  "age_days": 48,
  "disks": [
    {
      "name": "dev-api-boot",
      "size_gb": 100,
      "type": "pd-standard"
    },
    {
      "name": "dev-api-data",
      "size_gb": 50,
      "type": "pd-ssd"
    }
  ],
  "estimated_monthly_cost": 12.50,
  "already_wasted": 20.00,
  "confidence": "high",
  "detection_date": "2024-11-02T14:30:00Z"
}
```

#### Fichier d'Impl√©mentation

**Backend :** `/backend/app/providers/gcp.py` (√† impl√©menter)

---

### 2. `compute_instance_idle` - Instances Inactives (CPU <5%)

#### D√©tection

**Logique :**
```python
# 1. Lister toutes les instances RUNNING
instances = compute_client.instances().aggregatedList(
    project=project_id,
    filter='status=RUNNING'
).execute()

# 2. Pour chaque instance, r√©cup√©rer m√©triques Cloud Monitoring
from google.cloud import monitoring_v3

monitoring_client = monitoring_v3.MetricServiceClient()

for instance in instances:
    # 3. Query CPU utilization (14 derniers jours)
    interval = monitoring_v3.TimeInterval({
        "end_time": {"seconds": int(time.time())},
        "start_time": {"seconds": int(time.time()) - 14*24*3600},
    })

    results = monitoring_client.list_time_series(
        request={
            "name": f"projects/{project_id}",
            "filter": f'metric.type="compute.googleapis.com/instance/cpu/utilization" AND resource.instance_id="{instance.id}"',
            "interval": interval,
        }
    )

    # 4. Calculer moyenne CPU
    cpu_values = [point.value.double_value for series in results for point in series.points]
    avg_cpu = sum(cpu_values) / len(cpu_values) * 100  # Convertir en %

    # 5. D√©tection si CPU < seuil (d√©faut: 5%)
    if avg_cpu < cpu_threshold:
        # Instance idle = waste d√©tect√©
```

**Crit√®res :**
- `status == 'RUNNING'`
- `avg_cpu_14d < cpu_threshold` (d√©faut: 5%)
- Minimum 50 data points (√©viter faux positifs)

**API Calls :**
```python
# Compute Engine API
compute_client.instances().aggregatedList(project, filter='status=RUNNING')

# Cloud Monitoring API
monitoring_client.list_time_series(
    name=f"projects/{project_id}",
    filter='metric.type="compute.googleapis.com/instance/cpu/utilization"',
    interval={"start_time": ..., "end_time": ...}
)
```

#### Calcul de Co√ªt

**Formule :**

Instances idle paient **100% du co√ªt compute** alors que CPU <5% :

```python
# R√©cup√©rer pricing via Cloud Billing API ou hard-coded
machine_type = instance['machineType'].split('/')[-1]  # "n1-standard-2"

# Pricing mensuel par machine type (us-central1, avec SUD)
machine_pricing = {
    'n1-standard-1': 24.27,
    'n1-standard-2': 48.54,
    'n2-standard-2': 71.17,
    'n2-standard-4': 142.34,
    'e2-small': 14.23,
}

monthly_cost = machine_pricing.get(machine_type, 0)

# Waste = 95% du co√ªt si CPU <5% (garder 5% pour co√ªt minimal)
waste_percentage = (100 - avg_cpu) / 100.0
monthly_waste = monthly_cost * waste_percentage

# Co√ªt d√©j√† gaspill√© depuis cr√©ation
creation_date = parse_timestamp(instance['creationTimestamp'])
age_months = (now - creation_date).days / 30.0
already_wasted = monthly_waste * age_months
```

**Exemple :**

Instance n2-standard-4 avec CPU √† 3% depuis 90 jours :
```python
monthly_cost = $142.34
waste_percentage = (100 - 3) / 100 = 0.97
monthly_waste = $142.34 * 0.97 = $138.07/mois
already_wasted = $138.07 * (90/30) = $414.21
```

#### Param√®tres Configurables

| Param√®tre | Type | D√©faut | Description |
|-----------|------|--------|-------------|
| `cpu_threshold` | float | 5.0 | CPU % maximum pour √™tre consid√©r√© idle |
| `lookback_days` | int | 14 | P√©riode d'analyse des m√©triques |
| `min_datapoints` | int | 50 | Nombre minimum de points de donn√©es |
| `exclude_labels` | dict | `{}` | Labels pour exclure instances |

#### M√©tadonn√©es Exemple

```json
{
  "resource_id": "instance-9876543210987654321",
  "resource_name": "staging-web-server",
  "resource_type": "compute_instance_idle",
  "zone": "us-central1-b",
  "machine_type": "n2-standard-4",
  "status": "RUNNING",
  "creation_timestamp": "2024-08-05T08:00:00Z",
  "age_days": 89,
  "cpu_metrics": {
    "avg_cpu_14d": 3.2,
    "max_cpu_14d": 8.5,
    "min_cpu_14d": 0.8,
    "datapoints": 672
  },
  "estimated_monthly_cost": 142.34,
  "estimated_monthly_waste": 138.07,
  "already_wasted": 414.21,
  "confidence": "high",
  "recommendation": "Downgrade to n2-standard-2 or e2-small",
  "detection_date": "2024-11-02T14:30:00Z"
}
```

#### Fichier d'Impl√©mentation

**Backend :** `/backend/app/providers/gcp.py` (√† impl√©menter)

---

### 3. `compute_instance_overprovisioned` - Instances Sur-Provisionn√©es (CPU <30%)

#### D√©tection

**Logique :**

Similaire √† `compute_instance_idle` mais avec seuil plus √©lev√© (30%) pour d√©tecter over-provisioning :

```python
# 1. Instances RUNNING avec CPU <30% sur 14 jours
instances = get_running_instances()

for instance in instances:
    # 2. R√©cup√©rer m√©triques CPU via Cloud Monitoring
    avg_cpu = get_avg_cpu(instance, lookback_days=14)

    # 3. D√©tection si 5% < CPU < 30%
    if cpu_min_threshold < avg_cpu < cpu_max_threshold:
        # 4. Calculer machine type recommand√©e (downgrade)
        current_type = instance['machineType'].split('/')[-1]
        recommended_type = calculate_recommended_size(current_type, avg_cpu)

        # Over-provisioned = waste d√©tect√©
```

**Crit√®res :**
- `status == 'RUNNING'`
- `5% < avg_cpu_14d < 30%`
- Possibilit√© de downgrade machine type

**API Calls :** Identiques √† `compute_instance_idle`

#### Calcul de Co√ªt

**Formule :**

Calcul de l'√©conomie potentielle en downgradant :

```python
# Co√ªt actuel
current_machine = 'n2-standard-8'
current_cost = 284.68  # $/mois

# Machine recommand√©e (bas√© sur avg_cpu)
# Si CPU = 20% ‚Üí recommandation = n2-standard-4 (50% des vCPUs)
recommended_machine = 'n2-standard-4'
recommended_cost = 142.34  # $/mois

# Waste = diff√©rence entre actuel et recommand√©
monthly_waste = current_cost - recommended_cost  # $142.34/mois

# Co√ªt d√©j√† gaspill√© depuis cr√©ation
age_months = (now - creation_date).days / 30.0
already_wasted = monthly_waste * age_months
```

**Exemple :**

Instance n2-standard-8 avec CPU √† 22% depuis 180 jours :
```python
current_cost = $284.68
recommended_cost = $142.34  # n2-standard-4
monthly_waste = $142.34
already_wasted = $142.34 * (180/30) = $852.04
```

#### Param√®tres Configurables

| Param√®tre | Type | D√©faut | Description |
|-----------|------|--------|-------------|
| `cpu_min_threshold` | float | 5.0 | CPU % minimum (√©viter overlap avec idle) |
| `cpu_max_threshold` | float | 30.0 | CPU % maximum pour over-provisioning |
| `lookback_days` | int | 14 | P√©riode d'analyse |
| `downgrade_ratio` | float | 0.5 | Ratio de downgrade (0.5 = moiti√© des vCPUs) |

#### M√©tadonn√©es Exemple

```json
{
  "resource_id": "instance-1122334455667788990",
  "resource_name": "prod-batch-processor",
  "resource_type": "compute_instance_overprovisioned",
  "zone": "europe-west1-b",
  "machine_type": "n2-standard-8",
  "status": "RUNNING",
  "cpu_metrics": {
    "avg_cpu_14d": 22.4,
    "max_cpu_14d": 45.2,
    "min_cpu_14d": 5.1
  },
  "current_cost_monthly": 284.68,
  "recommended_machine_type": "n2-standard-4",
  "recommended_cost_monthly": 142.34,
  "estimated_monthly_waste": 142.34,
  "already_wasted": 852.04,
  "confidence": "medium",
  "recommendation": "Downgrade from 8 vCPUs to 4 vCPUs",
  "detection_date": "2024-11-02T14:30:00Z"
}
```

#### Fichier d'Impl√©mentation

**Backend :** `/backend/app/providers/gcp.py` (√† impl√©menter)

---

### 4. `compute_instance_old_generation` - Anciennes G√©n√©rations de Machines

#### D√©tection

**Logique :**

D√©tecter instances utilisant anciennes g√©n√©rations de machine types (n1) au lieu de modernes (n2/n2d) :

```python
# 1. Lister toutes les instances RUNNING
instances = compute_client.instances().aggregatedList(
    project=project_id,
    filter='status=RUNNING'
).execute()

# 2. Pour chaque instance, extraire machine type
for instance in instances:
    machine_type = instance['machineType'].split('/')[-1]  # "n1-standard-4"

    # 3. D√©tecter g√©n√©ration ancienne
    if machine_type.startswith('n1-'):
        # 4. Calculer machine type √©quivalente moderne
        n2_equivalent = machine_type.replace('n1-', 'n2-')

        # 5. Calculer √©conomie potentielle (n2 = -20% √† -30% vs n1)
        n1_cost = get_machine_cost(machine_type)
        n2_cost = get_machine_cost(n2_equivalent)

        if n2_cost < n1_cost:
            # Old generation = waste d√©tect√©
```

**Crit√®res :**
- `status == 'RUNNING'`
- `machine_type.startswith('n1-')`
- √âquivalent n2/n2d moins cher existe

**API Calls :**
```python
# Compute Engine API
compute_client.instances().aggregatedList(project, filter='status=RUNNING')

# Machine Types API (pour pricing)
compute_client.machineTypes().get(
    project=project_id,
    zone='us-central1-a',
    machineType='n1-standard-4'
).execute()
```

#### Calcul de Co√ªt

**Formule :**

√âconomie potentielle en migrant n1 ‚Üí n2/n2d :

```python
# Mapping n1 ‚Üí n2 pricing (us-central1, avec SUD)
n1_pricing = {
    'n1-standard-1': 24.27,
    'n1-standard-2': 48.54,
    'n1-standard-4': 97.08,
    'n1-standard-8': 194.16,
}

n2_pricing = {
    'n2-standard-2': 71.17,   # n2-standard-1 n'existe pas
    'n2-standard-4': 142.34,
    'n2-standard-8': 284.68,
}

# Note: n2 a 2x moins de vCPUs minimum (n2-standard-2 vs n1-standard-1)
# Comparaison √©quivalente: n1-standard-2 ($48.54) ‚Üí n2-standard-2 ($71.17)
# MAIS n2 a +46% performance ‚Üí co√ªt/performance r√©duit de -20%

# Pour n1-standard-4 ‚Üí n2-standard-4
n1_cost = 97.08
n2_cost = 142.34

# N2 a +40% performance, donc co√ªt effectif ajust√©:
n2_cost_adjusted = n2_cost / 1.40 = 101.67

# Waste = diff√©rence (si migration vers n2d au lieu de n2, √©conomie de -30%)
# Utiliser n2d pour √©conomies maximales:
n2d_cost = n2_cost * 0.87  # n2d = -13% vs n2
monthly_waste = n1_cost - n2d_cost

# Co√ªt d√©j√† gaspill√© depuis cr√©ation
age_months = (now - creation_date).days / 30.0
already_wasted = monthly_waste * age_months
```

**Exemple :**

Instance n1-standard-4 depuis 120 jours :
```python
n1_cost = $97.08/mois
n2d_cost = $142.34 * 0.87 = $123.84/mois (ajust√© pour performance)

# Co√ªt/performance: n1 moins bon, recommandation n2d-standard-4
# Si on consid√®re co√ªt brut: √©conomie via migration n1‚Üín2d pour perf
# Exemple simplifi√©: migration vers n2-standard-2 (moiti√© vCPUs mais +40% perf)
recommended_cost = $71.17
monthly_waste = $97.08 - $71.17 = $25.91
already_wasted = $25.91 * (120/30) = $103.64
```

**Note :** Calcul complexe car n2 a minimum 2 vCPUs. Recommandation r√©elle d√©pend du workload.

#### Param√®tres Configurables

| Param√®tre | Type | D√©faut | Description |
|-----------|------|--------|-------------|
| `old_generations` | list | `['n1']` | G√©n√©rations consid√©r√©es anciennes |
| `preferred_generation` | str | `'n2d'` | G√©n√©ration recommand√©e (n2, n2d, c2, etc.) |
| `min_savings_threshold` | float | 10.0 | √âconomie minimum en $/mois pour alerte |

#### M√©tadonn√©es Exemple

```json
{
  "resource_id": "instance-5566778899001122334",
  "resource_name": "legacy-app-server",
  "resource_type": "compute_instance_old_generation",
  "zone": "us-central1-a",
  "machine_type": "n1-standard-4",
  "status": "RUNNING",
  "creation_timestamp": "2024-07-05T10:00:00Z",
  "age_days": 120,
  "current_cost_monthly": 97.08,
  "recommended_machine_type": "n2-standard-2",
  "recommended_cost_monthly": 71.17,
  "estimated_monthly_waste": 25.91,
  "already_wasted": 103.64,
  "confidence": "medium",
  "recommendation": "Migrate to n2-standard-2 (similar performance, -27% cost)",
  "migration_notes": "n2 instances have +40% performance per vCPU vs n1",
  "detection_date": "2024-11-02T14:30:00Z"
}
```

#### Fichier d'Impl√©mentation

**Backend :** `/backend/app/providers/gcp.py` (√† impl√©menter)

---

### 5. `compute_instance_no_spot` - Absence d'Usage Spot/Preemptible

#### D√©tection

**Logique :**

D√©tecter instances standard (on-demand) qui pourraient utiliser **Spot VMs** (-60% √† -91%) :

```python
# 1. Lister toutes les instances RUNNING
instances = compute_client.instances().aggregatedList(
    project=project_id,
    filter='status=RUNNING'
).execute()

# 2. Pour chaque instance, v√©rifier si Spot/Preemptible
for instance in instances:
    scheduling = instance.get('scheduling', {})
    is_preemptible = scheduling.get('preemptible', False)

    # 3. V√©rifier labels pour identifier workload type
    labels = instance.get('labels', {})
    workload_type = labels.get('workload', 'unknown')

    # 4. D√©tection si instance standard ET workload tol√©rant interruptions
    if not is_preemptible and workload_type in ['batch', 'dev', 'test', 'staging']:
        # 5. Calculer √©conomie potentielle avec Spot
        machine_type = instance['machineType'].split('/')[-1]
        standard_cost = get_machine_cost(machine_type, spot=False)
        spot_cost = get_machine_cost(machine_type, spot=True)

        savings = standard_cost - spot_cost

        if savings >= min_savings_threshold:
            # No Spot usage = waste d√©tect√©
```

**Crit√®res :**
- `status == 'RUNNING'`
- `scheduling.preemptible == False`
- `labels.workload in ['batch', 'dev', 'test', 'staging']`
- √âconomie Spot > seuil (d√©faut: $20/mois)

**API Calls :**
```python
# Compute Engine API
compute_client.instances().aggregatedList(project, filter='status=RUNNING')

# Instance details (pour scheduling + labels)
compute_client.instances().get(
    project=project_id,
    zone='us-central1-a',
    instance='my-instance'
).execute()
```

#### Calcul de Co√ªt

**Formule :**

√âconomie potentielle en convertissant vers Spot :

```python
# Pricing standard vs Spot (us-central1)
machine_type = 'n2-standard-4'

standard_cost = 142.34  # $/mois (avec SUD)
spot_cost = 34.16       # $/mois (-76%)

# Waste = diff√©rence standard - spot
monthly_waste = standard_cost - spot_cost  # $108.18/mois

# Co√ªt d√©j√† gaspill√© depuis cr√©ation
age_months = (now - creation_date).days / 30.0
already_wasted = monthly_waste * age_months
```

**Exemple :**

Instance n2-standard-4 standard (batch workload) depuis 60 jours :
```python
standard_cost = $142.34
spot_cost = $34.16
monthly_waste = $108.18
already_wasted = $108.18 * (60/30) = $216.36
```

#### Param√®tres Configurables

| Param√®tre | Type | D√©faut | Description |
|-----------|------|--------|-------------|
| `spot_eligible_labels` | list | `['batch', 'dev', 'test', 'staging']` | Workload types √©ligibles Spot |
| `min_savings_threshold` | float | 20.0 | √âconomie minimum en $/mois |
| `exclude_production` | bool | `True` | Exclure instances avec label `env=production` |

#### M√©tadonn√©es Exemple

```json
{
  "resource_id": "instance-9988776655443322110",
  "resource_name": "batch-processing-worker",
  "resource_type": "compute_instance_no_spot",
  "zone": "us-central1-c",
  "machine_type": "n2-standard-4",
  "status": "RUNNING",
  "scheduling": {
    "preemptible": false,
    "onHostMaintenance": "MIGRATE"
  },
  "labels": {
    "workload": "batch",
    "environment": "staging"
  },
  "creation_timestamp": "2024-09-05T12:00:00Z",
  "age_days": 58,
  "current_cost_monthly": 142.34,
  "spot_cost_monthly": 34.16,
  "estimated_monthly_waste": 108.18,
  "already_wasted": 216.36,
  "spot_discount_percentage": 76,
  "confidence": "high",
  "recommendation": "Convert to Spot VM for batch workloads (-76% cost)",
  "detection_date": "2024-11-02T14:30:00Z"
}
```

#### Fichier d'Impl√©mentation

**Backend :** `/backend/app/providers/gcp.py` (√† impl√©menter)

---

### 6. `compute_instance_untagged` - Instances Non Tagu√©es

#### D√©tection

**Logique :**

D√©tecter instances sans **labels GCP** requis pour gouvernance :

```python
# 1. Lister toutes les instances
instances = compute_client.instances().aggregatedList(
    project=project_id
).execute()

# 2. D√©finir labels requis (configurables)
required_labels = ['environment', 'owner', 'cost-center', 'project']

# 3. Pour chaque instance, v√©rifier labels
for instance in instances:
    labels = instance.get('labels', {})

    # 4. Identifier labels manquants
    missing_labels = [label for label in required_labels if label not in labels]

    # 5. D√©tection si labels manquants
    if missing_labels:
        # Untagged = governance waste
```

**Crit√®res :**
- Labels manquants parmi la liste requise
- Optionnel: valeurs de labels invalides

**API Calls :**
```python
# Compute Engine API
compute_client.instances().aggregatedList(project).execute()
```

#### Calcul de Co√ªt

**Formule :**

Co√ªt de gouvernance (estim√©) :

```python
# Instances non tagu√©es = perte de visibilit√© + risque co√ªt
# Co√ªt estim√© = temps management + over-provisioning cach√©

# Estimations:
# - 5% de co√ªt additionnel par manque de visibilit√©
# - Risque de duplication/non-nettoyage

machine_type = instance['machineType'].split('/')[-1]
instance_monthly_cost = get_machine_cost(machine_type)

# Governance waste = 5% du co√ªt instance (estimation)
governance_waste_percentage = 0.05
monthly_waste = instance_monthly_cost * governance_waste_percentage

# Waste cumul√© depuis cr√©ation
age_months = (now - creation_date).days / 30.0
already_wasted = monthly_waste * age_months
```

**Exemple :**

Instance n2-standard-8 sans labels depuis 90 jours :
```python
instance_monthly_cost = $284.68
monthly_waste = $284.68 * 0.05 = $14.23
already_wasted = $14.23 * (90/30) = $42.69
```

**Note :** Co√ªt gouvernance est estim√©. Impact r√©el = meilleure visibilit√© co√ªts + pr√©vention waste.

#### Param√®tres Configurables

| Param√®tre | Type | D√©faut | Description |
|-----------|------|--------|-------------|
| `required_labels` | list | `['environment', 'owner', 'cost-center']` | Labels requis |
| `governance_waste_pct` | float | 0.05 | % co√ªt attribu√© au waste gouvernance |
| `enforce_values` | dict | `{}` | Valeurs autoris√©es par label (ex: `{'environment': ['dev', 'staging', 'prod']}`) |

#### M√©tadonn√©es Exemple

```json
{
  "resource_id": "instance-1231231231231231231",
  "resource_name": "unnamed-instance-47",
  "resource_type": "compute_instance_untagged",
  "zone": "asia-southeast1-a",
  "machine_type": "n2-standard-8",
  "status": "RUNNING",
  "labels": {},
  "missing_labels": ["environment", "owner", "cost-center", "project"],
  "creation_timestamp": "2024-08-05T06:00:00Z",
  "age_days": 89,
  "instance_monthly_cost": 284.68,
  "estimated_monthly_waste": 14.23,
  "already_wasted": 42.69,
  "confidence": "medium",
  "recommendation": "Add required labels for cost allocation and governance",
  "detection_date": "2024-11-02T14:30:00Z"
}
```

#### Fichier d'Impl√©mentation

**Backend :** `/backend/app/providers/gcp.py` (√† impl√©menter)

---

### 7. `compute_instance_devtest_247` - Instances Dev/Test 24/7

#### D√©tection

**Logique :**

D√©tecter instances **dev/test** tournant 24/7 (√©conomies via arr√™ts nocturnes/weekends) :

```python
# 1. Lister toutes les instances RUNNING
instances = compute_client.instances().aggregatedList(
    project=project_id,
    filter='status=RUNNING'
).execute()

# 2. Pour chaque instance, v√©rifier labels environment
for instance in instances:
    labels = instance.get('labels', {})
    environment = labels.get('environment', '').lower()

    # 3. D√©tection si environment = dev/test/staging
    if environment in ['dev', 'test', 'staging', 'development']:
        # 4. V√©rifier si instance tourne 24/7 (uptime >7 jours continus)
        creation_timestamp = parse_timestamp(instance['creationTimestamp'])
        last_start = instance.get('lastStartTimestamp', creation_timestamp)
        uptime_days = (now - parse_timestamp(last_start)).days

        if uptime_days >= min_uptime_days:
            # 5. Calculer √©conomie potentielle (arr√™t 12h/jour + weekends)
            # Business hours: 8h-20h (12h/jour), Lun-Ven (5/7 jours)
            # Uptime optimal: 12h * 5j = 60h/semaine vs 168h actuel
            # √âconomie: (168-60)/168 = 64%

            machine_type = instance['machineType'].split('/')[-1]
            monthly_cost = get_machine_cost(machine_type)

            # Waste = 64% du co√ªt (instance arr√™t√©e 64% du temps)
            monthly_waste = monthly_cost * 0.64

            # Dev/Test 24/7 = waste d√©tect√©
```

**Crit√®res :**
- `status == 'RUNNING'`
- `labels.environment in ['dev', 'test', 'staging']`
- `uptime_days >= min_uptime_days` (d√©faut: 7 jours)

**API Calls :**
```python
# Compute Engine API
compute_client.instances().aggregatedList(project, filter='status=RUNNING')
```

#### Calcul de Co√ªt

**Formule :**

√âconomie potentielle avec arr√™ts planifi√©s :

```python
# Sc√©nario: Instance dev tournant 24/7
# Optimal: 8h-20h Lun-Ven (60h/semaine)
# Actuel: 24/7 (168h/semaine)

machine_type = 'n2-standard-4'
monthly_cost = 142.34  # $/mois (24/7)

# Calcul co√ªt optimal (60h vs 168h par semaine)
hours_optimal = 60  # 12h/jour * 5 jours
hours_actual = 168  # 24h * 7 jours

optimal_cost = monthly_cost * (hours_optimal / hours_actual)  # $50.83/mois
monthly_waste = monthly_cost - optimal_cost  # $91.51/mois

# Co√ªt d√©j√† gaspill√© depuis cr√©ation
age_months = (now - creation_date).days / 30.0
already_wasted = monthly_waste * age_months
```

**Exemple :**

Instance n2-standard-4 dev depuis 120 jours :
```python
monthly_cost = $142.34
optimal_cost = $50.83  # (60/168 = 35.7% uptime)
monthly_waste = $91.51
already_wasted = $91.51 * (120/30) = $366.04
```

#### Param√®tres Configurables

| Param√®tre | Type | D√©faut | Description |
|-----------|------|--------|-------------|
| `devtest_labels` | list | `['dev', 'test', 'staging', 'development']` | Labels indiquant environnement non-prod |
| `min_uptime_days` | int | 7 | Uptime minimum pour d√©tection |
| `business_hours_per_day` | int | 12 | Heures optimales par jour (8h-20h) |
| `business_days_per_week` | int | 5 | Jours optimaux par semaine (Lun-Ven) |

#### M√©tadonn√©es Exemple

```json
{
  "resource_id": "instance-4564564564564564564",
  "resource_name": "dev-frontend-server",
  "resource_type": "compute_instance_devtest_247",
  "zone": "europe-west1-b",
  "machine_type": "n2-standard-4",
  "status": "RUNNING",
  "labels": {
    "environment": "dev",
    "team": "frontend"
  },
  "creation_timestamp": "2024-07-05T09:00:00Z",
  "last_start_timestamp": "2024-07-05T09:00:00Z",
  "uptime_days": 120,
  "current_uptime_hours_weekly": 168,
  "optimal_uptime_hours_weekly": 60,
  "current_cost_monthly": 142.34,
  "optimal_cost_monthly": 50.83,
  "estimated_monthly_waste": 91.51,
  "already_wasted": 366.04,
  "waste_percentage": 64,
  "confidence": "high",
  "recommendation": "Implement automated start/stop schedule (8am-8pm Mon-Fri) for 64% cost savings",
  "detection_date": "2024-11-02T14:30:00Z"
}
```

#### Fichier d'Impl√©mentation

**Backend :** `/backend/app/providers/gcp.py` (√† impl√©menter)

---

## Phase 2 - D√©tection Avanc√©e (3 sc√©narios)

### 8. `compute_instance_memory_waste` - M√©moire Sur-Provisionn√©e (<40% usage)

#### D√©tection

**Logique :**

Utiliser **Cloud Monitoring** pour analyser usage m√©moire r√©el :

```python
# 1. Lister toutes les instances RUNNING
instances = compute_client.instances().aggregatedList(
    project=project_id,
    filter='status=RUNNING'
).execute()

# 2. Pour chaque instance, r√©cup√©rer m√©triques m√©moire
from google.cloud import monitoring_v3

monitoring_client = monitoring_v3.MetricServiceClient()

for instance in instances:
    # 3. Query memory utilization (14 derniers jours)
    # Note: N√©cessite Cloud Monitoring Agent install√© sur instance
    interval = monitoring_v3.TimeInterval({
        "end_time": {"seconds": int(time.time())},
        "start_time": {"seconds": int(time.time()) - 14*24*3600},
    })

    results = monitoring_client.list_time_series(
        request={
            "name": f"projects/{project_id}",
            "filter": f'metric.type="agent.googleapis.com/memory/percent_used" AND resource.instance_id="{instance.id}"',
            "interval": interval,
        }
    )

    # 4. Calculer moyenne m√©moire utilis√©e
    memory_values = [point.value.double_value for series in results for point in series.points]

    if not memory_values:
        # Agent non install√©, skip
        continue

    avg_memory = sum(memory_values) / len(memory_values)  # En %

    # 5. D√©tection si m√©moire <40% utilis√©e
    if avg_memory < memory_threshold:
        # 6. Calculer machine type avec moins de RAM
        current_type = instance['machineType'].split('/')[-1]
        recommended_type = calculate_memory_rightsizing(current_type, avg_memory)

        # Memory waste = d√©tect√©
```

**Crit√®res :**
- `status == 'RUNNING'`
- Cloud Monitoring Agent install√© (metrics disponibles)
- `avg_memory_used_14d < 40%`
- Possibilit√© downgrade RAM (ex: n2-standard ‚Üí n2-highmem inutile)

**API Calls :**
```python
# Compute Engine API
compute_client.instances().aggregatedList(project, filter='status=RUNNING')

# Cloud Monitoring API (memory metrics)
monitoring_client.list_time_series(
    name=f"projects/{project_id}",
    filter='metric.type="agent.googleapis.com/memory/percent_used"',
    interval={"start_time": ..., "end_time": ...}
)
```

#### Calcul de Co√ªt

**Formule :**

GCP facture RAM s√©par√©ment des vCPUs :

```python
# GCP Pricing (us-central1, avec SUD):
# vCPU: $0.031611/hour
# RAM: $0.004237/GB/hour

# Exemple: n2-standard-8 (8 vCPUs, 32 GB RAM)
vcpu_cost = 8 * 0.031611 * 730 = $184.61/mois
ram_cost = 32 * 0.004237 * 730 = $99.07/mois
total_cost = $283.68/mois

# Si RAM utilis√©e = 30%, recommandation: n2-highcpu-8 (8 vCPUs, 8 GB RAM)
new_vcpu_cost = 8 * 0.031611 * 730 = $184.61/mois (identique)
new_ram_cost = 8 * 0.004237 * 730 = $24.77/mois
new_total_cost = $209.38/mois

# Waste = diff√©rence RAM
monthly_waste = ram_cost - new_ram_cost  # $74.30/mois

# Co√ªt d√©j√† gaspill√©
age_months = (now - creation_date).days / 30.0
already_wasted = monthly_waste * age_months
```

**Exemple :**

Instance n2-standard-8 (32 GB) avec RAM √† 28% depuis 90 jours :
```python
current_ram_cost = $99.07/mois
recommended_ram_cost = $24.77/mois (8 GB au lieu de 32 GB)
monthly_waste = $74.30
already_wasted = $74.30 * (90/30) = $222.90
```

#### Param√®tres Configurables

| Param√®tre | Type | D√©faut | Description |
|-----------|------|--------|-------------|
| `memory_threshold` | float | 40.0 | M√©moire % maximum pour over-provisioning |
| `lookback_days` | int | 14 | P√©riode d'analyse |
| `min_datapoints` | int | 50 | Points minimum requis |
| `require_monitoring_agent` | bool | `True` | Exiger agent install√© (sinon skip) |

#### M√©tadonn√©es Exemple

```json
{
  "resource_id": "instance-7897897897897897897",
  "resource_name": "app-server-highram",
  "resource_type": "compute_instance_memory_waste",
  "zone": "us-central1-a",
  "machine_type": "n2-standard-8",
  "status": "RUNNING",
  "memory_specs": {
    "total_gb": 32,
    "avg_used_gb": 8.96,
    "avg_used_percent": 28.0,
    "max_used_percent": 42.1
  },
  "current_cost_monthly": 283.68,
  "current_ram_cost_monthly": 99.07,
  "recommended_machine_type": "n2-highcpu-8",
  "recommended_ram_gb": 8,
  "recommended_cost_monthly": 209.38,
  "estimated_monthly_waste": 74.30,
  "already_wasted": 222.90,
  "confidence": "high",
  "recommendation": "Downgrade from 32GB to 8GB RAM (n2-highcpu-8)",
  "monitoring_agent_installed": true,
  "detection_date": "2024-11-02T14:30:00Z"
}
```

#### Fichier d'Impl√©mentation

**Backend :** `/backend/app/providers/gcp.py` (√† impl√©menter)

---

### 9. `compute_instance_rightsizing` - Opportunit√©s de Right-Sizing

#### D√©tection

**Logique :**

Analyse holistique CPU + RAM + Disk I/O pour recommandation pr√©cise :

```python
# 1. Instances RUNNING uniquement
instances = get_running_instances()

for instance in instances:
    # 2. R√©cup√©rer toutes les m√©triques (14 jours)
    metrics = {
        'cpu': get_avg_cpu(instance, lookback_days=14),
        'memory': get_avg_memory(instance, lookback_days=14),
        'disk_read_ops': get_avg_disk_read_ops(instance, lookback_days=14),
        'disk_write_ops': get_avg_disk_write_ops(instance, lookback_days=14),
        'network_in': get_avg_network_in(instance, lookback_days=14),
        'network_out': get_avg_network_out(instance, lookback_days=14),
    }

    # 3. Algorithme de right-sizing
    current_type = instance['machineType'].split('/')[-1]
    current_specs = get_machine_specs(current_type)  # vCPUs, RAM

    # 4. Calculer ressources optimales bas√©es sur m√©triques
    optimal_vcpus = calculate_optimal_vcpus(metrics['cpu'], current_specs['vcpus'])
    optimal_ram_gb = calculate_optimal_ram(metrics['memory'], current_specs['ram_gb'])

    # 5. Trouver machine type correspondante
    recommended_type = find_closest_machine_type(optimal_vcpus, optimal_ram_gb)

    # 6. D√©tection si machine recommand√©e != actuelle ET √©conomie >10%
    current_cost = get_machine_cost(current_type)
    recommended_cost = get_machine_cost(recommended_type)

    savings_percentage = (current_cost - recommended_cost) / current_cost * 100

    if recommended_type != current_type and savings_percentage >= min_savings_pct:
        # Right-sizing opportunity = d√©tect√©
```

**Crit√®res :**
- M√©triques compl√®tes disponibles (CPU, RAM, Disk, Network)
- √âconomie potentielle >10%
- Recommandation bas√©e sur usage r√©el

**API Calls :**
```python
# Compute Engine API
compute_client.instances().aggregatedList(project, filter='status=RUNNING')

# Cloud Monitoring API (multiple metrics)
monitoring_client.list_time_series(
    name=f"projects/{project_id}",
    filter='metric.type="compute.googleapis.com/instance/cpu/utilization"'
)

monitoring_client.list_time_series(
    name=f"projects/{project_id}",
    filter='metric.type="agent.googleapis.com/memory/percent_used"'
)

# Disk I/O metrics, Network metrics, etc.
```

#### Calcul de Co√ªt

**Formule :**

Calcul pr√©cis bas√© sur analyse multi-m√©triques :

```python
# Exemple: Instance actuelle n2-standard-8 (8 vCPUs, 32 GB)
current_cost = 283.68  # $/mois

# M√©triques observ√©es:
# - CPU: 18% avg
# - Memory: 35% avg (11.2 GB / 32 GB)
# - Disk I/O: Low
# - Network: Moderate

# Recommandation algorithme:
# - vCPUs requis: 18% * 8 = 1.44 vCPUs ‚Üí arrondi √† 2 vCPUs
# - RAM requis: 11.2 GB * 1.3 (safety margin) = 14.56 GB ‚Üí arrondi √† 16 GB
# - Machine recommand√©e: n2-standard-4 (4 vCPUs, 16 GB) - over spec for safety

recommended_type = 'n2-standard-4'
recommended_cost = 142.34  # $/mois

# Waste
monthly_waste = current_cost - recommended_cost  # $141.34/mois
savings_percentage = (monthly_waste / current_cost) * 100  # 49.8%

# Co√ªt d√©j√† gaspill√©
age_months = (now - creation_date).days / 30.0
already_wasted = monthly_waste * age_months
```

**Exemple :**

Instance n2-standard-8 depuis 180 jours :
```python
monthly_waste = $141.34
already_wasted = $141.34 * (180/30) = $848.04
```

#### Param√®tres Configurables

| Param√®tre | Type | D√©faut | Description |
|-----------|------|--------|-------------|
| `min_savings_pct` | float | 10.0 | √âconomie minimum % pour recommandation |
| `safety_margin_cpu` | float | 1.5 | Marge s√©curit√© vCPU (1.5x usage observ√©) |
| `safety_margin_ram` | float | 1.3 | Marge s√©curit√© RAM (1.3x usage observ√©) |
| `lookback_days` | int | 14 | P√©riode analyse m√©triques |

#### M√©tadonn√©es Exemple

```json
{
  "resource_id": "instance-1471471471471471471",
  "resource_name": "api-backend-overspec",
  "resource_type": "compute_instance_rightsizing",
  "zone": "us-east1-b",
  "machine_type": "n2-standard-8",
  "status": "RUNNING",
  "current_specs": {
    "vcpus": 8,
    "ram_gb": 32
  },
  "metrics_analysis": {
    "avg_cpu_percent": 18.2,
    "avg_memory_percent": 35.0,
    "avg_memory_used_gb": 11.2,
    "avg_disk_read_iops": 120,
    "avg_disk_write_iops": 80,
    "avg_network_in_mbps": 5.4,
    "avg_network_out_mbps": 8.2
  },
  "optimal_specs": {
    "vcpus": 2,
    "ram_gb": 15
  },
  "recommended_machine_type": "n2-standard-4",
  "recommended_specs": {
    "vcpus": 4,
    "ram_gb": 16
  },
  "current_cost_monthly": 283.68,
  "recommended_cost_monthly": 142.34,
  "estimated_monthly_waste": 141.34,
  "already_wasted": 848.04,
  "savings_percentage": 49.8,
  "confidence": "high",
  "recommendation": "Right-size from n2-standard-8 to n2-standard-4 for 50% cost savings",
  "detection_date": "2024-11-02T14:30:00Z"
}
```

#### Fichier d'Impl√©mentation

**Backend :** `/backend/app/providers/gcp.py` (√† impl√©menter)

---

### 10. `compute_instance_burstable_waste` - Instances Burstable Sous-Utilis√©es

#### D√©tection

**Logique :**

D√©tecter instances **e2** (burstable) qui n'utilisent pas les bursts ‚Üí downgrade vers f1/g1 :

```python
# 1. Lister instances e2 (burstable) RUNNING
instances = compute_client.instances().aggregatedList(
    project=project_id,
    filter='status=RUNNING'
).execute()

e2_instances = [i for i in instances if i['machineType'].split('/')[-1].startswith('e2-')]

# 2. Pour chaque instance e2, analyser CPU burst usage
for instance in e2_instances:
    # 3. R√©cup√©rer CPU utilization (14 jours)
    cpu_values = get_cpu_timeseries(instance, lookback_days=14)

    # 4. Identifier bursts (CPU >20% pour e2-micro/small)
    # e2 instances ont baseline CPU: e2-micro=12.5%, e2-small=25%
    machine_type = instance['machineType'].split('/')[-1]

    baseline_cpu = {
        'e2-micro': 12.5,
        'e2-small': 25.0,
        'e2-medium': 50.0,
    }

    baseline = baseline_cpu.get(machine_type, 50.0)

    # 5. Calculer % temps au-dessus baseline (= burst usage)
    burst_percentage = sum(1 for cpu in cpu_values if cpu > baseline) / len(cpu_values) * 100

    # 6. D√©tection si burst <5% (jamais utilis√©)
    if burst_percentage < max_burst_pct:
        # 7. Recommandation: downgrade vers f1-micro/g1-small (shared-core)
        # e2-micro ($7.11/mois) ‚Üí f1-micro ($3.88/mois) = -45%

        recommended_type = 'f1-micro' if machine_type == 'e2-micro' else 'g1-small'

        # Burstable waste = d√©tect√©
```

**Crit√®res :**
- `machine_type.startswith('e2-')`
- `status == 'RUNNING'`
- Burst usage <5% du temps (jamais d√©passe baseline)

**API Calls :**
```python
# Compute Engine API
compute_client.instances().aggregatedList(project, filter='status=RUNNING')

# Cloud Monitoring API (CPU utilization)
monitoring_client.list_time_series(
    name=f"projects/{project_id}",
    filter='metric.type="compute.googleapis.com/instance/cpu/utilization"',
    interval={"start_time": ..., "end_time": ...}
)
```

#### Calcul de Co√ªt

**Formule :**

√âconomie en downgradant e2 ‚Üí f1/g1 :

```python
# Pricing (us-central1, avec SUD)
e2_pricing = {
    'e2-micro': 7.11,   # $/mois
    'e2-small': 14.23,
    'e2-medium': 28.45,
}

f1g1_pricing = {
    'f1-micro': 3.88,   # $/mois (shared-core)
    'g1-small': 13.23,  # $/mois (shared-core, 1.7 GB)
}

# Exemple: e2-micro ‚Üí f1-micro
current_cost = 7.11
recommended_cost = 3.88
monthly_waste = 3.23  # -45%

# Co√ªt d√©j√† gaspill√©
age_months = (now - creation_date).days / 30.0
already_wasted = monthly_waste * age_months
```

**Exemple :**

Instance e2-micro (burst jamais utilis√©) depuis 120 jours :
```python
current_cost = $7.11
recommended_cost = $3.88
monthly_waste = $3.23
already_wasted = $3.23 * (120/30) = $12.92
```

#### Param√®tres Configurables

| Param√®tre | Type | D√©faut | Description |
|-----------|------|--------|-------------|
| `max_burst_pct` | float | 5.0 | % temps maximum au-dessus baseline pour d√©tection |
| `lookback_days` | int | 14 | P√©riode d'analyse |
| `e2_baseline_cpu` | dict | `{'e2-micro': 12.5, 'e2-small': 25.0}` | CPU baseline par type |

#### M√©tadonn√©es Exemple

```json
{
  "resource_id": "instance-9639639639639639639",
  "resource_name": "low-traffic-web",
  "resource_type": "compute_instance_burstable_waste",
  "zone": "us-west1-a",
  "machine_type": "e2-micro",
  "status": "RUNNING",
  "cpu_analysis": {
    "baseline_cpu_percent": 12.5,
    "avg_cpu_percent": 6.2,
    "max_cpu_percent": 15.8,
    "time_above_baseline_percent": 2.3,
    "burst_usage_percent": 2.3
  },
  "current_cost_monthly": 7.11,
  "recommended_machine_type": "f1-micro",
  "recommended_cost_monthly": 3.88,
  "estimated_monthly_waste": 3.23,
  "already_wasted": 12.92,
  "savings_percentage": 45.4,
  "confidence": "high",
  "recommendation": "Downgrade to f1-micro (shared-core) - burst capability unused",
  "detection_date": "2024-11-02T14:30:00Z"
}
```

#### Fichier d'Impl√©mentation

**Backend :** `/backend/app/providers/gcp.py` (√† impl√©menter)

---

## Protocole de Test

### Pr√©requis

#### 1. Compte GCP et Projet Test

```bash
# Cr√©er projet GCP d√©di√© testing
gcloud projects create cloudwaste-test-$(date +%s) \
  --name="CloudWaste Testing" \
  --labels=environment=test

# D√©finir projet actif
export PROJECT_ID="cloudwaste-test-XXXXXXXXXX"
gcloud config set project $PROJECT_ID

# Activer APIs requises
gcloud services enable compute.googleapis.com
gcloud services enable monitoring.googleapis.com
```

#### 2. Service Account Setup

```bash
# Cr√©er Service Account
gcloud iam service-accounts create cloudwaste-scanner \
  --display-name="CloudWaste Scanner" \
  --description="Read-only scanner for waste detection"

# Attacher r√¥les read-only
gcloud projects add-iam-policy-binding $PROJECT_ID \
  --member="serviceAccount:cloudwaste-scanner@${PROJECT_ID}.iam.gserviceaccount.com" \
  --role="roles/compute.viewer"

gcloud projects add-iam-policy-binding $PROJECT_ID \
  --member="serviceAccount:cloudwaste-scanner@${PROJECT_ID}.iam.gserviceaccount.com" \
  --role="roles/monitoring.viewer"

# G√©n√©rer cl√© JSON
gcloud iam service-accounts keys create cloudwaste-key.json \
  --iam-account=cloudwaste-scanner@${PROJECT_ID}.iam.gserviceaccount.com

# D√©finir credentials
export GOOGLE_APPLICATION_CREDENTIALS="$(pwd)/cloudwaste-key.json"
```

#### 3. Installer Cloud Monitoring Agent

**Important :** Requis pour m√©triques m√©moire (sc√©narios 8-10)

```bash
# Template installation agent (√† ex√©cuter sur instances)
curl -sSO https://dl.google.com/cloudagents/add-google-cloud-ops-agent-repo.sh
sudo bash add-google-cloud-ops-agent-repo.sh --also-install
```

---

### Tests Unitaires - Cr√©er Instances de Test

#### Sc√©nario 1: Instance Arr√™t√©e >30 Jours

```bash
# Cr√©er instance avec disques
gcloud compute instances create test-stopped-instance \
  --zone=us-central1-a \
  --machine-type=n1-standard-2 \
  --boot-disk-size=100GB \
  --boot-disk-type=pd-standard \
  --create-disk=size=50GB,type=pd-ssd

# Arr√™ter instance
gcloud compute instances stop test-stopped-instance --zone=us-central1-a

# Modifier lastStopTimestamp (simuler 30+ jours) - via API ou attendre
# Note: Pour tests, utiliser instance r√©ellement arr√™t√©e depuis >30 jours
```

**Validation attendue :**
```json
{
  "resource_type": "compute_instance_stopped",
  "resource_name": "test-stopped-instance",
  "status": "TERMINATED",
  "age_days": ">=30",
  "estimated_monthly_cost": "~12.50",
  "confidence": "high"
}
```

---

#### Sc√©nario 2: Instance Idle (CPU <5%)

```bash
# Cr√©er instance n2-standard-2
gcloud compute instances create test-idle-instance \
  --zone=us-central1-a \
  --machine-type=n2-standard-2 \
  --image-family=debian-11 \
  --image-project=debian-cloud \
  --labels=environment=test

# SSH et installer monitoring agent
gcloud compute ssh test-idle-instance --zone=us-central1-a

# Sur instance:
curl -sSO https://dl.google.com/cloudagents/add-google-cloud-ops-agent-repo.sh
sudo bash add-google-cloud-ops-agent-repo.sh --also-install

# Laisser tourner idle (aucune charge) pendant 14 jours
```

**Validation attendue :**
```json
{
  "resource_type": "compute_instance_idle",
  "avg_cpu_14d": "<5%",
  "estimated_monthly_waste": "~67.61",
  "recommendation": "Downgrade to e2-small"
}
```

---

#### Sc√©nario 3: Instance Over-Provisioned (CPU <30%)

```bash
# Cr√©er instance n2-standard-8 (large)
gcloud compute instances create test-overprovisioned \
  --zone=us-central1-a \
  --machine-type=n2-standard-8 \
  --image-family=debian-11 \
  --image-project=debian-cloud

# SSH et g√©n√©rer charge CPU √† 20%
gcloud compute ssh test-overprovisioned --zone=us-central1-a

# Sur instance: stress CPU √† 20% constant
sudo apt-get update && sudo apt-get install -y stress-ng
stress-ng --cpu 1 --cpu-load 20 --timeout 0 &

# Laisser tourner 14 jours
```

**Validation attendue :**
```json
{
  "resource_type": "compute_instance_overprovisioned",
  "avg_cpu_14d": "~20%",
  "recommended_machine_type": "n2-standard-4",
  "estimated_monthly_waste": "~142.34"
}
```

---

#### Sc√©nario 4: Ancienne G√©n√©ration (n1)

```bash
# Cr√©er instance n1-standard-4
gcloud compute instances create test-old-generation \
  --zone=us-central1-a \
  --machine-type=n1-standard-4 \
  --image-family=debian-11 \
  --image-project=debian-cloud
```

**Validation attendue :**
```json
{
  "resource_type": "compute_instance_old_generation",
  "machine_type": "n1-standard-4",
  "recommended_machine_type": "n2-standard-2",
  "estimated_monthly_waste": "~25.91"
}
```

---

#### Sc√©nario 5: No Spot Usage

```bash
# Cr√©er instance standard avec label batch
gcloud compute instances create test-no-spot \
  --zone=us-central1-a \
  --machine-type=n2-standard-4 \
  --image-family=debian-11 \
  --image-project=debian-cloud \
  --labels=workload=batch,environment=staging
```

**Validation attendue :**
```json
{
  "resource_type": "compute_instance_no_spot",
  "scheduling": {"preemptible": false},
  "labels": {"workload": "batch"},
  "spot_discount_percentage": 76,
  "estimated_monthly_waste": "~108.18"
}
```

---

#### Sc√©nario 6: Instances Non Tagu√©es

```bash
# Cr√©er instance SANS labels
gcloud compute instances create test-untagged \
  --zone=us-central1-a \
  --machine-type=n2-standard-8 \
  --image-family=debian-11 \
  --image-project=debian-cloud
```

**Validation attendue :**
```json
{
  "resource_type": "compute_instance_untagged",
  "labels": {},
  "missing_labels": ["environment", "owner", "cost-center"],
  "estimated_monthly_waste": "~14.23"
}
```

---

#### Sc√©nario 7: Dev/Test 24/7

```bash
# Cr√©er instance dev
gcloud compute instances create test-devtest-247 \
  --zone=europe-west1-b \
  --machine-type=n2-standard-4 \
  --image-family=debian-11 \
  --image-project=debian-cloud \
  --labels=environment=dev,team=backend

# Laisser tourner 7+ jours sans arr√™t
```

**Validation attendue :**
```json
{
  "resource_type": "compute_instance_devtest_247",
  "labels": {"environment": "dev"},
  "uptime_days": ">=7",
  "waste_percentage": 64,
  "estimated_monthly_waste": "~91.51"
}
```

---

#### Sc√©nario 8: M√©moire Sur-Provisionn√©e

```bash
# Cr√©er instance n2-standard-8 (32 GB RAM)
gcloud compute instances create test-memory-waste \
  --zone=us-central1-a \
  --machine-type=n2-standard-8 \
  --image-family=debian-11 \
  --image-project=debian-cloud

# SSH, installer agent, laisser RAM idle (<40% usage)
gcloud compute ssh test-memory-waste --zone=us-central1-a

# Sur instance: installer monitoring agent
curl -sSO https://dl.google.com/cloudagents/add-google-cloud-ops-agent-repo.sh
sudo bash add-google-cloud-ops-agent-repo.sh --also-install

# Laisser tourner 14 jours avec faible usage m√©moire
```

**Validation attendue :**
```json
{
  "resource_type": "compute_instance_memory_waste",
  "avg_memory_percent": "<40%",
  "recommended_machine_type": "n2-highcpu-8",
  "estimated_monthly_waste": "~74.30"
}
```

---

#### Sc√©nario 9: Right-Sizing

```bash
# Cr√©er instance large (n2-standard-8) sous-utilis√©e
gcloud compute instances create test-rightsizing \
  --zone=us-east1-b \
  --machine-type=n2-standard-8 \
  --image-family=debian-11 \
  --image-project=debian-cloud

# SSH, installer agent, stress CPU √† 18% + RAM √† 35%
gcloud compute ssh test-rightsizing --zone=us-east1-b

# Sur instance:
curl -sSO https://dl.google.com/cloudagents/add-google-cloud-ops-agent-repo.sh
sudo bash add-google-cloud-ops-agent-repo.sh --also-install

sudo apt-get update && sudo apt-get install -y stress-ng
stress-ng --cpu 1 --cpu-load 18 --vm 1 --vm-bytes 11G --timeout 0 &

# Laisser tourner 14 jours
```

**Validation attendue :**
```json
{
  "resource_type": "compute_instance_rightsizing",
  "avg_cpu_percent": "~18%",
  "avg_memory_percent": "~35%",
  "recommended_machine_type": "n2-standard-4",
  "savings_percentage": "~50%",
  "estimated_monthly_waste": "~141.34"
}
```

---

#### Sc√©nario 10: Burstable Waste

```bash
# Cr√©er instance e2-micro
gcloud compute instances create test-burstable-waste \
  --zone=us-west1-a \
  --machine-type=e2-micro \
  --image-family=debian-11 \
  --image-project=debian-cloud

# SSH, installer agent, laisser CPU <12.5% (baseline)
gcloud compute ssh test-burstable-waste --zone=us-west1-a

# Sur instance:
curl -sSO https://dl.google.com/cloudagents/add-google-cloud-ops-agent-repo.sh
sudo bash add-google-cloud-ops-agent-repo.sh --also-install

# Laisser tourner 14 jours sans burst
```

**Validation attendue :**
```json
{
  "resource_type": "compute_instance_burstable_waste",
  "machine_type": "e2-micro",
  "burst_usage_percent": "<5%",
  "recommended_machine_type": "f1-micro",
  "estimated_monthly_waste": "~3.23"
}
```

---

### Validation Globale

#### Script Test Complet

```python
#!/usr/bin/env python3
"""
Script de validation complet pour GCP Compute Engine Instances
"""

from google.cloud import compute_v1
from google.cloud import monitoring_v3
import os

PROJECT_ID = os.environ['PROJECT_ID']

def test_all_scenarios():
    compute_client = compute_v1.InstancesClient()

    # 1. Lister toutes les instances
    request = compute_v1.AggregatedListInstancesRequest(
        project=PROJECT_ID
    )

    agg_list = compute_client.aggregated_list(request=request)

    instances = []
    for zone, response in agg_list:
        if response.instances:
            instances.extend(response.instances)

    print(f"‚úÖ Found {len(instances)} instances")

    # 2. V√©rifier d√©tection pour chaque sc√©nario
    scenarios_detected = {
        'stopped': 0,
        'idle': 0,
        'overprovisioned': 0,
        'old_generation': 0,
        'no_spot': 0,
        'untagged': 0,
        'devtest_247': 0,
        'memory_waste': 0,
        'rightsizing': 0,
        'burstable_waste': 0,
    }

    for instance in instances:
        name = instance.name

        # Logique de d√©tection (simplifi√©)
        if instance.status == 'TERMINATED':
            scenarios_detected['stopped'] += 1
            print(f"‚úÖ Detected scenario 1 (stopped): {name}")

        if instance.machine_type.endswith('n1-standard-4'):
            scenarios_detected['old_generation'] += 1
            print(f"‚úÖ Detected scenario 4 (old generation): {name}")

        # ... (impl√©menter logique pour autres sc√©narios)

    # 3. Rapport final
    print("\nüìä Detection Summary:")
    for scenario, count in scenarios_detected.items():
        print(f"  - {scenario}: {count} instances")

    total_detected = sum(scenarios_detected.values())
    print(f"\n‚úÖ Total waste detected: {total_detected} instances")

if __name__ == '__main__':
    test_all_scenarios()
```

#### Ex√©cution

```bash
# Exporter PROJECT_ID
export PROJECT_ID="cloudwaste-test-XXXXXXXXXX"

# Ex√©cuter validation
python3 test_gcp_compute_instances.py
```

**R√©sultat attendu :**
```
‚úÖ Found 10 instances
‚úÖ Detected scenario 1 (stopped): test-stopped-instance
‚úÖ Detected scenario 2 (idle): test-idle-instance
‚úÖ Detected scenario 3 (overprovisioned): test-overprovisioned
‚úÖ Detected scenario 4 (old generation): test-old-generation
‚úÖ Detected scenario 5 (no spot): test-no-spot
‚úÖ Detected scenario 6 (untagged): test-untagged
‚úÖ Detected scenario 7 (devtest 24/7): test-devtest-247
‚úÖ Detected scenario 8 (memory waste): test-memory-waste
‚úÖ Detected scenario 9 (rightsizing): test-rightsizing
‚úÖ Detected scenario 10 (burstable waste): test-burstable-waste

üìä Detection Summary:
  - stopped: 1 instances
  - idle: 1 instances
  - overprovisioned: 1 instances
  - old_generation: 1 instances
  - no_spot: 1 instances
  - untagged: 1 instances
  - devtest_247: 1 instances
  - memory_waste: 1 instances
  - rightsizing: 1 instances
  - burstable_waste: 1 instances

‚úÖ Total waste detected: 10 instances
```

---

### Cleanup

```bash
# Supprimer toutes les instances de test
gcloud compute instances delete test-stopped-instance --zone=us-central1-a --quiet
gcloud compute instances delete test-idle-instance --zone=us-central1-a --quiet
gcloud compute instances delete test-overprovisioned --zone=us-central1-a --quiet
gcloud compute instances delete test-old-generation --zone=us-central1-a --quiet
gcloud compute instances delete test-no-spot --zone=us-central1-a --quiet
gcloud compute instances delete test-untagged --zone=us-central1-a --quiet
gcloud compute instances delete test-devtest-247 --zone=europe-west1-b --quiet
gcloud compute instances delete test-memory-waste --zone=us-central1-a --quiet
gcloud compute instances delete test-rightsizing --zone=us-east1-b --quiet
gcloud compute instances delete test-burstable-waste --zone=us-west1-a --quiet

# Supprimer Service Account
gcloud iam service-accounts delete cloudwaste-scanner@${PROJECT_ID}.iam.gserviceaccount.com --quiet

# Supprimer projet test (optionnel)
gcloud projects delete $PROJECT_ID --quiet
```

---

## R√©f√©rences

### Documentation GCP

- [Compute Engine Instances API](https://cloud.google.com/compute/docs/reference/rest/v1/instances)
- [Cloud Monitoring API](https://cloud.google.com/monitoring/api/v3)
- [Machine Types Pricing](https://cloud.google.com/compute/vm-instance-pricing)
- [Spot VMs Documentation](https://cloud.google.com/compute/docs/instances/spot)
- [Sustained Use Discounts](https://cloud.google.com/compute/docs/sustained-use-discounts)
- [Committed Use Discounts](https://cloud.google.com/compute/docs/instances/signing-up-committed-use-discounts)

### CloudWaste Documentation

- [GCP.md](./GCP.md) - Listing complet 27 ressources GCP
- [GCP.csv](./GCP.csv) - Tableau Excel ressources GCP
- [README.md](./README.md) - Guide utilisation documentation GCP

### √âquivalences AWS/Azure

- **AWS EC2 Instances** ‚Üí GCP Compute Engine Instances
- **Azure Virtual Machines** ‚Üí GCP Compute Engine Instances
- **AWS CloudWatch** ‚Üí GCP Cloud Monitoring
- **Azure Monitor** ‚Üí GCP Cloud Monitoring
- **AWS Spot Instances** ‚Üí GCP Spot VMs
- **Azure Spot VMs** ‚Üí GCP Spot VMs

---

**Derni√®re mise √† jour :** 2 novembre 2025
**Status :** ‚úÖ Sp√©cification compl√®te - Pr√™t pour impl√©mentation
**Version :** 1.0
**Auteur :** CloudWaste Team
