# GCP Cloud Filestore - 100% des Sc√©narios de Gaspillage

**Version:** 1.0
**Date:** 2025-01-03
**Ressource GCP:** `Storage: Filestore`
**Impact estim√©:** $10,000 - $60,000/an par organisation
**Cat√©gorie:** Network-attached storage (NAS) haute performance

---

## Table des Mati√®res

1. [Vue d'Ensemble](#vue-densemble)
2. [Architecture et Mod√®le de Pricing](#architecture-et-mod√®le-de-pricing)
3. [Phase 1 : Sc√©narios de D√©tection Simples](#phase-1--sc√©narios-de-d√©tection-simples)
   - [Sc√©nario 1 : Filestore Instances Sous-Utilis√©es](#sc√©nario-1--filestore-instances-sous-utilis√©es)
   - [Sc√©nario 2 : Wrong Tier (Enterprise pour Dev/Test)](#sc√©nario-2--wrong-tier-enterprise-pour-devtest)
   - [Sc√©nario 3 : Filestore Instances Idle (0 Connections)](#sc√©nario-3--filestore-instances-idle-0-connections)
   - [Sc√©nario 4 : Overprovisioned Capacity](#sc√©nario-4--overprovisioned-capacity)
   - [Sc√©nario 5 : Filestore Instances Untagged](#sc√©nario-5--filestore-instances-untagged)
   - [Sc√©nario 6 : No Backup Policy](#sc√©nario-6--no-backup-policy)
   - [Sc√©nario 7 : Legacy Tier (Basic HDD vs Zonal)](#sc√©nario-7--legacy-tier-basic-hdd-vs-zonal)
4. [Phase 2 : Sc√©narios d'Analyse Avanc√©e](#phase-2--sc√©narios-danalyse-avanc√©e)
   - [Sc√©nario 8 : Multi-Share Consolidation Opportunity](#sc√©nario-8--multi-share-consolidation-opportunity)
   - [Sc√©nario 9 : Snapshot Waste (Old Snapshots)](#sc√©nario-9--snapshot-waste-old-snapshots)
   - [Sc√©nario 10 : Wrong NFS Protocol (NFSv3 vs v4.1)](#sc√©nario-10--wrong-nfs-protocol-nfsv3-vs-v41)
5. [Protocole de Test Complet](#protocole-de-test-complet)
6. [R√©f√©rences et Ressources](#r√©f√©rences-et-ressources)

---

## Vue d'Ensemble

### Qu'est-ce que Cloud Filestore ?

**Cloud Filestore** est le service de stockage de fichiers enti√®rement manag√© de Google Cloud Platform. Il fournit des partages de fichiers r√©seau (NFS) haute performance pour les applications qui n√©cessitent un syst√®me de fichiers traditionnel.

**Caract√©ristiques principales :**
- **Protocole NFS** standard (v3 et v4.1)
- **Performance scalable** : jusqu'√† 100,000 IOPS et 2 GB/s de throughput
- **5 tiers de service** : Zonal, Basic HDD, Basic SSD, High Scale SSD, Enterprise
- **Capacit√©s** : de 1 TB √† 100 TB (selon le tier)
- **Backups automatiques** : schedules configurables
- **Multi-share** : jusqu'√† 10 shares par instance (Enterprise)
- **Montage concurrent** : milliers de clients simultan√©s

### Cas d'Usage Principaux

1. **Content Management Systems** - WordPress, Drupal, Joomla
2. **Media Processing** - Render farms, video transcoding
3. **Genomics Workloads** - Analyse de donn√©es biologiques
4. **Enterprise Applications** - ERP, CRM legacy n√©cessitant NFS
5. **Development Environments** - Shared code repositories
6. **Home Directories** - User home directories pour GKE/GCE

### Pourquoi Cloud Filestore est-il Critique pour la D√©tection de Gaspillage ?

Cloud Filestore pr√©sente des risques de gaspillage significatifs pour **3 raisons majeures** :

#### 1. **Facturation sur Capacit√© Provisionn√©e (NON Utilis√©e)**

**Contrairement √† Cloud Storage** (qui facture uniquement les donn√©es stock√©es), **Filestore facture la capacit√© provisionn√©e**, que vous l'utilisiez ou non.

**Exemple concret :**
```python
# Filestore 10 TB provisionn√©, 2 TB r√©ellement utilis√©
provisioned_capacity_tb = 10
actual_usage_tb = 2
tier_price_per_gb = 0.20  # Basic HDD

# Co√ªt mensuel
monthly_cost = provisioned_capacity_tb * 1024 * tier_price_per_gb
# = 10 * 1024 * $0.20 = $2,048/mois

# Co√ªt optimal (provision 3 TB avec 20% buffer)
optimal_cost = 3 * 1024 * 0.20  # $614.40/mois

# Gaspillage annuel
annual_waste = (monthly_cost - optimal_cost) * 12  # $17,203/an
```

**Cons√©quence :** Une instance provisionn√©e √† 20% d'utilisation gaspille **80% de son budget**.

#### 2. **Diff√©rences de Prix Entre Tiers Extr√™mes**

Les 5 tiers de Filestore ont des prix variant de **1:3.3** (Zonal vs Enterprise).

**Tableau comparatif :**
```
Tier               | Prix/GB/Mois | Instance 5 TB/Mois | Performance
------------------|--------------|--------------------|--------------
Zonal             | $0.18        | $921.60           | Basic
Basic HDD         | $0.20        | $1,024.00         | Standard
Basic SSD         | $0.30        | $1,536.00         | Fast
High Scale SSD    | $0.30        | $1,536.00         | Very Fast
Enterprise        | $0.60        | $3,072.00         | Multi-share
```

**Gaspillage typique :**
- Utiliser Enterprise pour environnement de d√©veloppement (233% plus cher que Zonal)
- Utiliser Basic SSD pour cold data (67% plus cher que Basic HDD)

#### 3. **Instances Idle et Oubli√©es**

Les instances Filestore sont souvent cr√©√©es pour des projets temporaires et oubli√©es :
- POCs/tests abandonn√©s
- Environnements de dev/staging non supprim√©s
- Migration d'applications termin√©e (donn√©es d√©j√† copi√©es ailleurs)

**Impact :**
- Une instance 5 TB Enterprise idle = **$36,864/an gaspill√©s**
- Co√ªt silencieux car aucune alerte automatique

### M√©triques Cl√©s pour la D√©tection

Cloud Filestore expose plusieurs m√©triques via **Cloud Monitoring API** :

| M√©trique | Type | Utilit√© |
|----------|------|---------|
| `file.googleapis.com/nfs/server/used_bytes_percent` | Gauge | Taux d'utilisation (0-100%) |
| `file.googleapis.com/nfs/server/used_bytes` | Gauge | Bytes utilis√©s |
| `file.googleapis.com/nfs/server/free_bytes` | Gauge | Bytes disponibles |
| `file.googleapis.com/nfs/server/read_ops_count` | Counter | Nombre d'op√©rations de lecture |
| `file.googleapis.com/nfs/server/write_ops_count` | Counter | Nombre d'op√©rations d'√©criture |
| `file.googleapis.com/nfs/server/connections` | Gauge | Nombre de connexions actives |
| `file.googleapis.com/nfs/server/procedure_count` | Counter | Appels NFS par type |

**D√©tection de gaspillage typique :**
```python
# Instance sous-utilis√©e
if used_bytes_percent < 30:
    waste_category = "UNDERUTILIZED"

# Instance idle
if connections == 0 and (read_ops + write_ops) == 0:
    waste_category = "IDLE"

# Instance overprovisionn√©e
if used_bytes_percent < 10:
    waste_category = "OVERPROVISIONED"
```

### Scope de Couverture : 100% des Sc√©narios

Ce document couvre **10 sc√©narios** repr√©sentant **100% des patterns de gaspillage** observ√©s en production :

**Phase 1 - D√©tection Simple (7 sc√©narios) :**
1. Instances sous-utilis√©es (<30% capacity)
2. Wrong tier (Enterprise pour dev/test)
3. Instances idle (0 connections + 0 I/O)
4. Overprovisioned capacity (<10% utilis√©)
5. Instances untagged (non cat√©goris√©es)
6. No backup policy (risque + co√ªt)
7. Legacy tier (Basic HDD vs Zonal moderne)

**Phase 2 - Analyse Avanc√©e (3 sc√©narios) :**
8. Multi-share consolidation (Enterprise sous-utilis√©)
9. Snapshot waste (snapshots anciens jamais utilis√©s)
10. Wrong NFS protocol (v3 vs v4.1 performance)

**Impact total estim√© :** $10,000 - $60,000/an par organisation

---

## Architecture et Mod√®le de Pricing

### Architecture Cloud Filestore

Cloud Filestore propose **5 tiers** avec des caract√©ristiques distinctes :

#### 1. **Zonal Tier** (Lanc√© 2023, recommand√© pour la plupart des workloads)

**Caract√©ristiques :**
- **Capacit√© :** 1 TB - 10 TB
- **Prix :** $0.18/GB/mois
- **Performance :** 100 MB/s par TB (read), 100 MB/s par TB (write)
- **IOPS :** 5,000 par TB
- **Disponibilit√© :** 1 zone (99.9% SLA)
- **Backups :** Support√©s
- **Multi-share :** Non (1 share par instance)

**Cas d'usage :**
- Applications standard n√©cessitant NFS
- Dev/test/staging environments
- Workloads tol√©rant une panne de zone courte

**Pricing exemple :**
```python
# Instance 5 TB Zonal
capacity_tb = 5
price_per_gb = 0.18

monthly_cost = capacity_tb * 1024 * price_per_gb  # $921.60/mois
annual_cost = monthly_cost * 12  # $11,059.20/an
```

#### 2. **Basic HDD Tier** (Original tier, moins recommand√© maintenant)

**Caract√©ristiques :**
- **Capacit√© :** 1 TB - 10 TB
- **Prix :** $0.20/GB/mois
- **Performance :** 100 MB/s par TB (read), 100 MB/s par TB (write)
- **IOPS :** 5,000 par TB
- **Disponibilit√© :** 1 zone (99.9% SLA)
- **Backups :** Support√©s
- **Multi-share :** Non

**Note :** Zonal tier (plus r√©cent) est 10% moins cher avec m√™mes performances. **Migration recommand√©e.**

#### 3. **Basic SSD Tier**

**Caract√©ristiques :**
- **Capacit√© :** 2.5 TB - 10 TB (min varie par r√©gion)
- **Prix :** $0.30/GB/mois
- **Performance :** 180 MB/s par TB (read), 120 MB/s par TB (write)
- **IOPS :** 8,000 par TB
- **Disponibilit√© :** 1 zone (99.9% SLA)
- **Backups :** Support√©s
- **Multi-share :** Non

**Cas d'usage :**
- Workloads n√©cessitant IOPS √©lev√©s
- Bases de donn√©es NFS
- Media processing workloads

**Performance comparison :**
```python
# Instance 5 TB Basic HDD vs Basic SSD
capacity_tb = 5

# Basic HDD
hdd_throughput_mb = capacity_tb * 100  # 500 MB/s
hdd_iops = capacity_tb * 5000  # 25,000 IOPS
hdd_cost = capacity_tb * 1024 * 0.20  # $1,024/mois

# Basic SSD
ssd_throughput_mb = capacity_tb * 180  # 900 MB/s (80% faster)
ssd_iops = capacity_tb * 8000  # 40,000 IOPS (60% faster)
ssd_cost = capacity_tb * 1024 * 0.30  # $1,536/mois (50% plus cher)
```

#### 4. **High Scale SSD Tier**

**Caract√©ristiques :**
- **Capacit√© :** 10 TB - 100 TB
- **Prix :** $0.30/GB/mois
- **Performance :** 1,200 MB/s fixe (max), IOPS scaling
- **IOPS :** 100,000 max
- **Disponibilit√© :** 1 zone (99.9% SLA)
- **Backups :** Support√©s
- **Multi-share :** Non

**Cas d'usage :**
- Workloads tr√®s large scale
- Render farms
- Genomics pipelines

**Note :** Prix identique √† Basic SSD mais capacit√© min 10 TB. Performance scale jusqu'√† 100 TB.

#### 5. **Enterprise Tier** (Premium, multi-share)

**Caract√©ristiques :**
- **Capacit√© :** 1 TB - 10 TB
- **Prix :** $0.60/GB/mois (200% plus cher que Zonal)
- **Performance :** 100 MB/s par TB (read), 100 MB/s par TB (write)
- **IOPS :** 5,000 par TB
- **Disponibilit√© :** Multi-zone (99.99% SLA - 10x meilleur)
- **Backups :** Support√©s
- **Multi-share :** Jusqu'√† 10 shares par instance

**Cas d'usage :**
- Applications critiques n√©cessitant haute disponibilit√©
- Multi-tenancy (plusieurs applications sur 1 instance)
- Consolidation de plusieurs shares

**Pricing exemple :**
```python
# Instance 5 TB Enterprise avec 3 shares
capacity_tb = 5
price_per_gb = 0.60
num_shares = 3

# Co√ªt total
monthly_cost = capacity_tb * 1024 * price_per_gb  # $3,072/mois

# Co√ªt par share (si consolidation)
cost_per_share = monthly_cost / num_shares  # $1,024/mois par share

# Comparaison : 3 instances Zonal s√©par√©es
zonal_cost = (capacity_tb / num_shares) * 1024 * 0.18 * num_shares
# = 1.67 TB * 1024 * 0.18 * 3 = $920.58/mois

# Enterprise est 233% plus cher dans ce cas
```

### Mod√®le de Pricing D√©taill√©

#### Pricing de Base (Capacit√© Provisionn√©e)

**R√®gle fondamentale :** Filestore facture **100% de la capacit√© provisionn√©e**, pas la capacit√© utilis√©e.

```python
def calculate_filestore_monthly_cost(
    capacity_tb: float,
    tier: str
) -> float:
    """
    Calcule le co√ªt mensuel Filestore bas√© sur capacit√© provisionn√©e.

    Args:
        capacity_tb: Capacit√© provisionn√©e en TB
        tier: 'zonal', 'basic_hdd', 'basic_ssd', 'high_scale_ssd', 'enterprise'

    Returns:
        Co√ªt mensuel en USD
    """
    tier_pricing = {
        'zonal': 0.18,
        'basic_hdd': 0.20,
        'basic_ssd': 0.30,
        'high_scale_ssd': 0.30,
        'enterprise': 0.60
    }

    price_per_gb = tier_pricing[tier]
    capacity_gb = capacity_tb * 1024

    monthly_cost = capacity_gb * price_per_gb
    return monthly_cost


# Exemple : 5 TB Zonal avec 2 TB utilis√©s
provisioned_tb = 5
used_tb = 2
tier = 'zonal'

monthly_cost = calculate_filestore_monthly_cost(provisioned_tb, tier)
# = $921.60/mois (factur√© sur 5 TB, pas 2 TB)

utilization_percent = (used_tb / provisioned_tb) * 100  # 40%
```

#### Pricing des Backups/Snapshots

Les backups Filestore sont factur√©s s√©par√©ment :

**Prix :** $0.10/GB/mois (identique pour tous les tiers)

```python
def calculate_filestore_backup_cost(
    used_capacity_tb: float,
    num_backups: int = 7  # ex: 7 daily backups
) -> float:
    """
    Calcule le co√ªt mensuel des backups Filestore.

    Note: Backups sont factur√©s sur capacit√© UTILIS√âE, pas provisionn√©e.
    """
    backup_price_per_gb = 0.10

    # Chaque backup contient les donn√©es utilis√©es
    total_backup_capacity_gb = used_capacity_tb * 1024 * num_backups

    monthly_backup_cost = total_backup_capacity_gb * backup_price_per_gb
    return monthly_backup_cost


# Exemple : Instance 10 TB avec 6 TB utilis√©s, 7 backups daily
used_tb = 6
num_backups = 7

backup_cost = calculate_filestore_backup_cost(used_tb, num_backups)
# = 6 * 1024 * 7 * $0.10 = $4,300.80/mois
```

**Important :** Le co√ªt des backups peut **d√©passer le co√ªt de l'instance** avec des policies de r√©tention agressives.

#### Co√ªts de Transfert R√©seau (Egress)

Le trafic r√©seau sortant est factur√© selon la grille standard GCP :

| Destination | Prix/GB |
|-------------|---------|
| M√™me zone GCP | Gratuit |
| M√™me r√©gion (inter-zone) | Gratuit |
| Autre r√©gion GCP (m√™me continent) | $0.01 |
| Inter-continental | $0.08 - $0.15 |
| Internet | $0.12 - $0.23 |

**Note :** Trafic Filestore ‚Üí GCE/GKE dans la m√™me zone = **0$**.

#### Formule de Co√ªt Total

```python
def calculate_total_filestore_cost(
    provisioned_capacity_tb: float,
    used_capacity_tb: float,
    tier: str,
    num_backups: int = 7,
    egress_gb_per_month: float = 0
) -> dict:
    """
    Calcule le co√ªt total mensuel Filestore.

    Returns:
        Dict avec breakdown des co√ªts
    """
    # Co√ªt de l'instance (capacit√© provisionn√©e)
    tier_pricing = {
        'zonal': 0.18,
        'basic_hdd': 0.20,
        'basic_ssd': 0.30,
        'high_scale_ssd': 0.30,
        'enterprise': 0.60
    }

    instance_cost = provisioned_capacity_tb * 1024 * tier_pricing[tier]

    # Co√ªt des backups (capacit√© utilis√©e)
    backup_cost = used_capacity_tb * 1024 * num_backups * 0.10

    # Co√ªt d'egress (simplifi√© : $0.12/GB average)
    egress_cost = egress_gb_per_month * 0.12

    total_cost = instance_cost + backup_cost + egress_cost

    return {
        'instance_cost': instance_cost,
        'backup_cost': backup_cost,
        'egress_cost': egress_cost,
        'total_monthly_cost': total_cost,
        'total_annual_cost': total_cost * 12
    }


# Exemple r√©aliste
costs = calculate_total_filestore_cost(
    provisioned_capacity_tb=10,
    used_capacity_tb=6,
    tier='basic_hdd',
    num_backups=7,
    egress_gb_per_month=500
)

print(costs)
# {
#     'instance_cost': 2048.0,      # $2,048/mois
#     'backup_cost': 4300.8,        # $4,301/mois (plus cher que l'instance!)
#     'egress_cost': 60.0,          # $60/mois
#     'total_monthly_cost': 6408.8, # $6,409/mois
#     'total_annual_cost': 76905.6  # $76,906/an
# }
```

**Observation critique :** Les backups peuvent repr√©senter **67% du co√ªt total** dans cet exemple.

### Comparaison de Performance par Tier

| Tier | Capacity Range | Read MB/s | Write MB/s | IOPS | Prix/GB | SLA |
|------|---------------|-----------|------------|------|---------|-----|
| Zonal | 1-10 TB | 100/TB | 100/TB | 5K/TB | $0.18 | 99.9% |
| Basic HDD | 1-10 TB | 100/TB | 100/TB | 5K/TB | $0.20 | 99.9% |
| Basic SSD | 2.5-10 TB | 180/TB | 120/TB | 8K/TB | $0.30 | 99.9% |
| High Scale SSD | 10-100 TB | 1200 max | 1200 max | 100K max | $0.30 | 99.9% |
| Enterprise | 1-10 TB | 100/TB | 100/TB | 5K/TB | $0.60 | 99.99% |

**Exemple performance scaling :**
```python
# Instance 5 TB sur diff√©rents tiers
capacity_tb = 5

tiers = {
    'zonal': {
        'read_mb_s': 100 * capacity_tb,      # 500 MB/s
        'write_mb_s': 100 * capacity_tb,     # 500 MB/s
        'iops': 5000 * capacity_tb,          # 25,000 IOPS
        'monthly_cost': capacity_tb * 1024 * 0.18  # $921.60
    },
    'basic_ssd': {
        'read_mb_s': 180 * capacity_tb,      # 900 MB/s (+80%)
        'write_mb_s': 120 * capacity_tb,     # 600 MB/s (+20%)
        'iops': 8000 * capacity_tb,          # 40,000 IOPS (+60%)
        'monthly_cost': capacity_tb * 1024 * 0.30  # $1,536 (+67% cost)
    },
    'enterprise': {
        'read_mb_s': 100 * capacity_tb,      # 500 MB/s (identique √† Zonal)
        'write_mb_s': 100 * capacity_tb,     # 500 MB/s (identique √† Zonal)
        'iops': 5000 * capacity_tb,          # 25,000 IOPS (identique √† Zonal)
        'monthly_cost': capacity_tb * 1024 * 0.60,  # $3,072 (+233% cost)
        'multi_share': True,
        'sla': 0.9999
    }
}
```

**Conclusion :** Enterprise est 233% plus cher que Zonal **pour la m√™me performance**. Le surco√ªt est justifi√© uniquement par :
- Multi-zone HA (SLA 99.99% vs 99.9%)
- Support de multi-share (10 shares par instance)

### R√®gles de Dimensionnement

**Capacit√©s minimales par tier :**
```python
min_capacity_tb = {
    'zonal': 1.0,
    'basic_hdd': 1.0,
    'basic_ssd': 2.5,  # Varie par r√©gion (1 TB dans certaines)
    'high_scale_ssd': 10.0,
    'enterprise': 1.0
}
```

**Incr√©ments de capacit√© :**
- Tous les tiers : par incr√©ments de **256 GB** (0.25 TB)

**Limites par projet :**
- **100 instances** Filestore par projet (soft limit, peut √™tre augment√©)

### Migrations Entre Tiers

**Migrations support√©es (sans downtime) :**
- Basic HDD ‚Üí Zonal ‚úÖ
- Basic HDD ‚Üí Basic SSD ‚úÖ
- Basic SSD ‚Üí High Scale SSD ‚úÖ (si capacity ‚â• 10 TB)
- Zonal ‚Üí Enterprise ‚úÖ
- Basic HDD ‚Üí Enterprise ‚úÖ

**Migrations NON support√©es :**
- Tier sup√©rieur ‚Üí Tier inf√©rieur ‚ùå (ex: Enterprise ‚Üí Zonal)
- High Scale SSD ‚Üí Basic SSD ‚ùå

**Proc√©dure de migration :**
```bash
gcloud filestore instances update INSTANCE_NAME \
    --zone=ZONE \
    --tier=TIER \
    --project=PROJECT_ID
```

**Downtime :** 0 secondes (migration transparente)

---

## Phase 1 : Sc√©narios de D√©tection Simples

### Sc√©nario 1 : Filestore Instances Sous-Utilis√©es

**Description :**
Instances Filestore avec un taux d'utilisation de capacit√© **< 30%** pendant une p√©riode prolong√©e (‚â• 14 jours). Ces instances gaspillent de l'argent car Filestore facture sur la capacit√© **provisionn√©e**, pas utilis√©e.

**Pourquoi c'est un probl√®me :**
- Filestore co√ªte $0.18-$0.60/GB/mois **m√™me si l'espace est vide**
- Une instance 10 TB utilis√©e √† 20% (2 TB) gaspille **$14,000/an** (tier Zonal)
- Downsizing permet √©conomie imm√©diate (migration sans downtime)

**Seuils de D√©tection :**
```python
UNDERUTILIZATION_THRESHOLDS = {
    'critical': 0.10,   # <10% utilis√© pendant 30 jours
    'high': 0.20,       # <20% utilis√© pendant 21 jours
    'medium': 0.30,     # <30% utilis√© pendant 14 jours
    'low': 0.40         # <40% utilis√© pendant 7 jours
}
```

**M√©trique Utilis√©e :**
- `file.googleapis.com/nfs/server/used_bytes_percent` (Gauge)

**Code de D√©tection Python :**

```python
from google.cloud import filestore_v1
from google.cloud import monitoring_v3
from datetime import datetime, timedelta
from typing import List, Dict
import logging

logger = logging.getLogger(__name__)


def detect_filestore_underutilized(
    project_id: str,
    utilization_threshold: float = 0.30,
    lookback_days: int = 14
) -> List[Dict]:
    """
    D√©tecte les instances Filestore sous-utilis√©es (<30% capacity).

    Args:
        project_id: GCP project ID
        utilization_threshold: Seuil d'utilisation (0.30 = 30%)
        lookback_days: P√©riode d'observation (14 jours par d√©faut)

    Returns:
        Liste d'instances sous-utilis√©es avec d√©tails et co√ªt gaspill√©
    """
    filestore_client = filestore_v1.CloudFilestoreManagerClient()
    monitoring_client = monitoring_v3.MetricServiceClient()

    underutilized_instances = []

    # Liste toutes les instances Filestore
    parent = f"projects/{project_id}/locations/-"

    try:
        instances = filestore_client.list_instances(parent=parent)
    except Exception as e:
        logger.error(f"Erreur lors de la r√©cup√©ration des instances: {e}")
        return []

    for instance in instances:
        instance_name = instance.name.split('/')[-1]
        zone = instance.name.split('/')[3]

        # R√©cup√®re les m√©triques d'utilisation
        utilization_metrics = get_filestore_utilization_metrics(
            project_id=project_id,
            instance_name=instance_name,
            zone=zone,
            lookback_days=lookback_days
        )

        if not utilization_metrics:
            logger.warning(f"Aucune m√©trique pour {instance_name}")
            continue

        avg_utilization = utilization_metrics['avg_utilization_percent'] / 100

        # V√©rifie si sous-utilis√©
        if avg_utilization < utilization_threshold:
            # Calcule le gaspillage
            waste_analysis = calculate_filestore_waste(
                instance=instance,
                avg_utilization=avg_utilization
            )

            # D√©termine confidence level
            confidence = determine_confidence_level(
                avg_utilization=avg_utilization,
                lookback_days=lookback_days
            )

            underutilized_instances.append({
                'instance_name': instance_name,
                'zone': zone,
                'tier': instance.tier.name,
                'provisioned_capacity_gb': instance.file_shares[0].capacity_gb,
                'used_capacity_gb': waste_analysis['used_capacity_gb'],
                'utilization_percent': avg_utilization * 100,
                'monthly_cost_current': waste_analysis['current_monthly_cost'],
                'monthly_cost_optimal': waste_analysis['optimal_monthly_cost'],
                'monthly_waste': waste_analysis['monthly_waste'],
                'annual_waste': waste_analysis['annual_waste'],
                'recommended_capacity_gb': waste_analysis['recommended_capacity_gb'],
                'confidence': confidence,
                'lookback_days': lookback_days,
                'labels': dict(instance.labels) if instance.labels else {}
            })

    # Trie par waste annuel d√©croissant
    underutilized_instances.sort(key=lambda x: x['annual_waste'], reverse=True)

    return underutilized_instances


def get_filestore_utilization_metrics(
    project_id: str,
    instance_name: str,
    zone: str,
    lookback_days: int
) -> Dict:
    """
    R√©cup√®re les m√©triques d'utilisation via Cloud Monitoring API.
    """
    monitoring_client = monitoring_v3.MetricServiceClient()

    project_name = f"projects/{project_id}"

    # P√©riode
    end_time = datetime.utcnow()
    start_time = end_time - timedelta(days=lookback_days)

    interval = monitoring_v3.TimeInterval({
        "end_time": {"seconds": int(end_time.timestamp())},
        "start_time": {"seconds": int(start_time.timestamp())},
    })

    # Query pour used_bytes_percent
    filter_str = (
        f'resource.type = "filestore_instance" '
        f'AND resource.labels.instance_name = "{instance_name}" '
        f'AND resource.labels.zone = "{zone}" '
        f'AND metric.type = "file.googleapis.com/nfs/server/used_bytes_percent"'
    )

    aggregation = monitoring_v3.Aggregation({
        "alignment_period": {"seconds": 3600},  # 1 heure
        "per_series_aligner": monitoring_v3.Aggregation.Aligner.ALIGN_MEAN,
    })

    try:
        results = monitoring_client.list_time_series(
            request={
                "name": project_name,
                "filter": filter_str,
                "interval": interval,
                "aggregation": aggregation,
            }
        )

        utilization_values = []
        for result in results:
            for point in result.points:
                utilization_values.append(point.value.double_value)

        if not utilization_values:
            return None

        avg_utilization = sum(utilization_values) / len(utilization_values)
        max_utilization = max(utilization_values)
        min_utilization = min(utilization_values)

        return {
            'avg_utilization_percent': avg_utilization,
            'max_utilization_percent': max_utilization,
            'min_utilization_percent': min_utilization,
            'num_samples': len(utilization_values)
        }

    except Exception as e:
        logger.error(f"Erreur monitoring metrics: {e}")
        return None


def calculate_filestore_waste(
    instance: filestore_v1.Instance,
    avg_utilization: float
) -> Dict:
    """
    Calcule le gaspillage financier d'une instance sous-utilis√©e.
    """
    # Prix par tier ($/GB/mois)
    tier_pricing = {
        'STANDARD': 0.20,        # Basic HDD (legacy name)
        'PREMIUM': 0.30,         # Basic SSD (legacy name)
        'BASIC_HDD': 0.20,
        'BASIC_SSD': 0.30,
        'HIGH_SCALE_SSD': 0.30,
        'ENTERPRISE': 0.60,
        'ZONAL': 0.18
    }

    tier = instance.tier.name
    price_per_gb = tier_pricing.get(tier, 0.20)

    # Capacit√© actuelle
    provisioned_capacity_gb = instance.file_shares[0].capacity_gb
    used_capacity_gb = provisioned_capacity_gb * avg_utilization

    # Capacit√© optimale (add 30% buffer au-dessus de l'utilisation actuelle)
    recommended_capacity_gb = int(used_capacity_gb * 1.30)

    # Arrondi au multiple de 256 GB sup√©rieur
    recommended_capacity_gb = ((recommended_capacity_gb + 255) // 256) * 256

    # Min capacity selon tier
    min_capacity_gb = {
        'ZONAL': 1024,
        'BASIC_HDD': 1024,
        'BASIC_SSD': 2560,
        'HIGH_SCALE_SSD': 10240,
        'ENTERPRISE': 1024
    }

    recommended_capacity_gb = max(
        recommended_capacity_gb,
        min_capacity_gb.get(tier, 1024)
    )

    # Co√ªts
    current_monthly_cost = provisioned_capacity_gb * price_per_gb
    optimal_monthly_cost = recommended_capacity_gb * price_per_gb
    monthly_waste = current_monthly_cost - optimal_monthly_cost
    annual_waste = monthly_waste * 12

    return {
        'used_capacity_gb': int(used_capacity_gb),
        'recommended_capacity_gb': recommended_capacity_gb,
        'current_monthly_cost': round(current_monthly_cost, 2),
        'optimal_monthly_cost': round(optimal_monthly_cost, 2),
        'monthly_waste': round(monthly_waste, 2),
        'annual_waste': round(annual_waste, 2)
    }


def determine_confidence_level(
    avg_utilization: float,
    lookback_days: int
) -> str:
    """
    D√©termine le niveau de confiance de la recommandation.
    """
    if avg_utilization < 0.10 and lookback_days >= 30:
        return 'CRITICAL'
    elif avg_utilization < 0.20 and lookback_days >= 21:
        return 'HIGH'
    elif avg_utilization < 0.30 and lookback_days >= 14:
        return 'MEDIUM'
    else:
        return 'LOW'


# Exemple d'utilisation
if __name__ == "__main__":
    underutilized = detect_filestore_underutilized(
        project_id="my-gcp-project",
        utilization_threshold=0.30,
        lookback_days=14
    )

    print(f"Trouv√© {len(underutilized)} instances sous-utilis√©es")

    for instance in underutilized:
        print(f"\nInstance: {instance['instance_name']}")
        print(f"  Tier: {instance['tier']}")
        print(f"  Capacit√© provisionn√©e: {instance['provisioned_capacity_gb']} GB")
        print(f"  Capacit√© utilis√©e: {instance['used_capacity_gb']} GB ({instance['utilization_percent']:.1f}%)")
        print(f"  Recommandation: {instance['recommended_capacity_gb']} GB")
        print(f"  Gaspillage: ${instance['monthly_waste']:.2f}/mois (${instance['annual_waste']:.2f}/an)")
        print(f"  Confiance: {instance['confidence']}")
```

**Exemples de D√©tection :**

**Exemple 1 : Instance 10 TB utilis√©e √† 15%**
```python
# Instance details
instance_name = "prod-filestore-old"
tier = "BASIC_HDD"
provisioned_capacity_gb = 10240  # 10 TB
used_capacity_gb = 1536  # 1.5 TB (15%)
utilization = 0.15

# Calcul du waste
price_per_gb = 0.20
current_monthly_cost = 10240 * 0.20  # $2,048/mois
optimal_capacity_gb = int(1536 * 1.30)  # 1,997 GB + 30% buffer
optimal_capacity_gb = 2048  # Arrondi √† 2 TB (256 GB increments)
optimal_monthly_cost = 2048 * 0.20  # $409.60/mois

monthly_waste = 2048 - 409.60  # $1,638.40/mois
annual_waste = monthly_waste * 12  # $19,660.80/an

# Recommandation
print(f"WASTE D√âTECT√â:")
print(f"  Instance {instance_name} ({tier})")
print(f"  Capacit√© provisionn√©e: 10 TB")
print(f"  Capacit√© utilis√©e: 1.5 TB (15%)")
print(f"  Recommandation: Downsize √† 2 TB")
print(f"  √âconomie potentielle: $19,661/an")
print(f"  Confiance: CRITICAL (15% < 30%)")
```

**Exemple 2 : Instance Enterprise 5 TB utilis√©e √† 25%**
```python
# Instance details
instance_name = "dev-filestore-enterprise"
tier = "ENTERPRISE"
provisioned_capacity_gb = 5120  # 5 TB
used_capacity_gb = 1280  # 1.25 TB (25%)

# Calcul
price_per_gb = 0.60
current_monthly_cost = 5120 * 0.60  # $3,072/mois
optimal_capacity_gb = 1664  # 1.25 TB * 1.30 = 1.625 TB ‚Üí 1.75 TB arrondi
optimal_monthly_cost = 1792 * 0.60  # $1,075.20/mois

monthly_waste = 3072 - 1075.20  # $1,996.80/mois
annual_waste = monthly_waste * 12  # $23,961.60/an

print(f"Instance {instance_name} gaspille $23,962/an")
print(f"Recommandation: Downsize 5 TB ‚Üí 1.75 TB")
```

**Formule de Co√ªt Optimal :**

```python
def calculate_optimal_capacity(
    used_capacity_gb: int,
    growth_buffer: float = 0.30,  # 30% buffer par d√©faut
    tier: str = 'ZONAL'
) -> int:
    """
    Calcule la capacit√© optimale avec buffer de croissance.

    Args:
        used_capacity_gb: Capacit√© actuellement utilis√©e
        growth_buffer: Buffer de croissance (0.30 = 30%)
        tier: Tier Filestore

    Returns:
        Capacit√© optimale en GB (arrondie √† 256 GB pr√®s)
    """
    # Capacit√© cible avec buffer
    target_capacity_gb = int(used_capacity_gb * (1 + growth_buffer))

    # Arrondi au multiple de 256 GB sup√©rieur
    optimal_capacity_gb = ((target_capacity_gb + 255) // 256) * 256

    # Min capacity par tier
    min_capacity = {
        'ZONAL': 1024,
        'BASIC_HDD': 1024,
        'BASIC_SSD': 2560,
        'HIGH_SCALE_SSD': 10240,
        'ENTERPRISE': 1024
    }

    optimal_capacity_gb = max(optimal_capacity_gb, min_capacity.get(tier, 1024))

    return optimal_capacity_gb


# Exemples
print(calculate_optimal_capacity(500, tier='ZONAL'))     # 1024 GB (min capacity)
print(calculate_optimal_capacity(1500, tier='ZONAL'))    # 2048 GB
print(calculate_optimal_capacity(8000, tier='BASIC_SSD'))  # 10240 GB (arrondi)
```

**Test d'Int√©gration Bash :**

```bash
#!/bin/bash
# test_filestore_underutilized.sh

PROJECT_ID="my-gcp-project"
ZONE="us-central1-a"
INSTANCE_NAME="test-underutilized-filestore"

echo "=== Test Sc√©nario 1: Filestore Underutilized ==="

# 1. Cr√©er une instance de test 2 TB
echo "Cr√©ation instance Filestore 2 TB (Zonal)..."
gcloud filestore instances create $INSTANCE_NAME \
    --zone=$ZONE \
    --tier=ZONAL \
    --file-share=name="test_share",capacity=2TB \
    --network=name="default" \
    --project=$PROJECT_ID

# 2. Attendre 30 secondes
sleep 30

# 3. Monter le share et √©crire seulement 300 GB (15% utilization)
echo "Simulation: Utilisation √† 15%..."
# (Dans un vrai test, on monterait via NFS et √©crirait des donn√©es)

# 4. Attendre 1 heure pour collecter m√©triques
echo "Attente de collecte de m√©triques (60 min)..."
sleep 3600

# 5. Ex√©cuter le detector
echo "Ex√©cution du detector..."
python3 - <<EOF
from detect_waste import detect_filestore_underutilized

results = detect_filestore_underutilized(
    project_id="$PROJECT_ID",
    utilization_threshold=0.30,
    lookback_days=1  # Test court
)

for r in results:
    if r['instance_name'] == '$INSTANCE_NAME':
        print(f"‚úì Instance d√©tect√©e: {r['instance_name']}")
        print(f"  Utilization: {r['utilization_percent']:.1f}%")
        print(f"  Waste: \${r['annual_waste']:.2f}/an")

        assert r['utilization_percent'] < 30, "Utilization should be <30%"
        assert r['annual_waste'] > 0, "Annual waste should be positive"
        print("‚úì Test PASSED")
        exit(0)

print("‚úó Instance not detected")
exit(1)
EOF

# 6. Cleanup
echo "Suppression de l'instance de test..."
gcloud filestore instances delete $INSTANCE_NAME \
    --zone=$ZONE \
    --project=$PROJECT_ID \
    --quiet

echo "=== Test termin√© ==="
```

**Recommandations Utilisateur :**

```python
def generate_filestore_underutilized_recommendation(
    instance: Dict
) -> str:
    """G√©n√®re une recommandation lisible pour l'utilisateur."""

    utilization = instance['utilization_percent']
    current_gb = instance['provisioned_capacity_gb']
    recommended_gb = instance['recommended_capacity_gb']
    annual_waste = instance['annual_waste']

    recommendation = f"""
üî¥ Filestore Sous-Utilis√© D√©tect√©

Instance: {instance['instance_name']}
Tier: {instance['tier']}
Zone: {instance['zone']}

üìä Utilisation:
  ‚Ä¢ Capacit√© provisionn√©e: {current_gb} GB ({current_gb/1024:.1f} TB)
  ‚Ä¢ Capacit√© utilis√©e: {instance['used_capacity_gb']} GB ({utilization:.1f}%)
  ‚Ä¢ Capacit√© gaspill√©e: {current_gb - instance['used_capacity_gb']} GB

üí∞ Co√ªt:
  ‚Ä¢ Co√ªt actuel: ${instance['monthly_cost_current']:.2f}/mois
  ‚Ä¢ Co√ªt optimal: ${instance['monthly_cost_optimal']:.2f}/mois
  ‚Ä¢ Gaspillage: ${instance['monthly_waste']:.2f}/mois (${annual_waste:.2f}/an)

‚úÖ Recommandation:
  ‚Ä¢ Downsize: {current_gb} GB ‚Üí {recommended_gb} GB
  ‚Ä¢ √âconomie: ${annual_waste:.2f}/an (80% de r√©duction)
  ‚Ä¢ Downtime: 0 secondes (migration transparente)

üîß Action:
```bash
gcloud filestore instances update {instance['instance_name']} \\
    --zone={instance['zone']} \\
    --file-share=capacity={recommended_gb//1024}TB \\
    --project=YOUR_PROJECT_ID
```

‚ö†Ô∏è Note: Assurez-vous que la nouvelle capacit√© ({recommended_gb} GB) permet
20-30% de croissance future.
"""

    return recommendation
```

---

### Sc√©nario 2 : Wrong Tier (Enterprise pour Dev/Test)

**Description :**
Instances Filestore utilisant le tier **Enterprise** ($0.60/GB/mois) pour des environnements de d√©veloppement, staging, ou test qui ne n√©cessitent pas la haute disponibilit√© multi-zone. Enterprise co√ªte **233% plus cher** que Zonal pour la m√™me performance.

**Pourquoi c'est un probl√®me :**
- Enterprise est justifi√© uniquement pour :
  - Applications critiques n√©cessitant SLA 99.99% (multi-zone)
  - Besoin de multi-share (10 shares par instance)
- Dev/test/staging n'ont PAS besoin de multi-zone HA
- Une instance 5 TB Enterprise pour dev = **$21,000/an gaspill√©s** vs Zonal

**R√®gles de D√©tection :**
```python
WRONG_TIER_RULES = {
    # Enterprise pour non-prod
    'enterprise_non_prod': {
        'tier': 'ENTERPRISE',
        'labels': ['env:dev', 'env:test', 'env:staging', 'env:qa'],
        'waste_severity': 'CRITICAL'
    },

    # Basic SSD pour cold data
    'ssd_for_cold_data': {
        'tier': 'BASIC_SSD',
        'iops_threshold': 100,  # <100 IOPS sustained = cold data
        'waste_severity': 'HIGH'
    },

    # High Scale SSD sous-utilis√©
    'high_scale_underused': {
        'tier': 'HIGH_SCALE_SSD',
        'throughput_threshold_mb': 500,  # <500 MB/s sustained
        'waste_severity': 'HIGH'
    }
}
```

**M√©trique Utilis√©e :**
- Labels d'instance (environment, application)
- `file.googleapis.com/nfs/server/read_ops_count` (IOPS)
- `file.googleapis.com/nfs/server/write_ops_count`

**Code de D√©tection Python :**

```python
from google.cloud import filestore_v1
from google.cloud import monitoring_v3
from datetime import datetime, timedelta
from typing import List, Dict
import logging

logger = logging.getLogger(__name__)


def detect_filestore_wrong_tier(
    project_id: str,
    lookback_days: int = 14
) -> List[Dict]:
    """
    D√©tecte les instances Filestore utilisant un tier inappropri√©.

    Cas d√©tect√©s:
    1. Enterprise pour dev/test/staging (label-based)
    2. Basic SSD pour cold data (<100 IOPS sustained)
    3. High Scale SSD sous-utilis√© (<500 MB/s throughput)

    Returns:
        Liste d'instances avec wrong tier et √©conomies potentielles
    """
    filestore_client = filestore_v1.CloudFilestoreManagerClient()
    monitoring_client = monitoring_v3.MetricServiceClient()

    wrong_tier_instances = []

    parent = f"projects/{project_id}/locations/-"

    try:
        instances = filestore_client.list_instances(parent=parent)
    except Exception as e:
        logger.error(f"Erreur r√©cup√©ration instances: {e}")
        return []

    for instance in instances:
        instance_name = instance.name.split('/')[-1]
        zone = instance.name.split('/')[3]
        tier = instance.tier.name
        labels = dict(instance.labels) if instance.labels else {}

        # Cas 1: Enterprise pour non-prod
        if tier == 'ENTERPRISE':
            wrong_tier_result = check_enterprise_for_non_prod(
                instance=instance,
                labels=labels
            )

            if wrong_tier_result:
                wrong_tier_instances.append(wrong_tier_result)

        # Cas 2: Basic SSD pour cold data
        elif tier == 'BASIC_SSD':
            iops_metrics = get_filestore_iops_metrics(
                project_id=project_id,
                instance_name=instance_name,
                zone=zone,
                lookback_days=lookback_days
            )

            if iops_metrics and iops_metrics['avg_total_iops'] < 100:
                wrong_tier_result = calculate_ssd_to_hdd_savings(
                    instance=instance,
                    avg_iops=iops_metrics['avg_total_iops']
                )
                wrong_tier_instances.append(wrong_tier_result)

        # Cas 3: High Scale SSD sous-utilis√©
        elif tier == 'HIGH_SCALE_SSD':
            throughput_metrics = get_filestore_throughput_metrics(
                project_id=project_id,
                instance_name=instance_name,
                zone=zone,
                lookback_days=lookback_days
            )

            if throughput_metrics and throughput_metrics['avg_throughput_mb'] < 500:
                wrong_tier_result = calculate_high_scale_downgrade_savings(
                    instance=instance,
                    avg_throughput=throughput_metrics['avg_throughput_mb']
                )
                wrong_tier_instances.append(wrong_tier_result)

    # Trie par waste annuel d√©croissant
    wrong_tier_instances.sort(key=lambda x: x['annual_waste'], reverse=True)

    return wrong_tier_instances


def check_enterprise_for_non_prod(
    instance: filestore_v1.Instance,
    labels: Dict[str, str]
) -> Dict:
    """
    V√©rifie si une instance Enterprise est utilis√©e pour non-prod.
    """
    # Labels non-prod typiques
    non_prod_labels = {
        'environment': ['dev', 'test', 'staging', 'qa', 'development'],
        'env': ['dev', 'test', 'staging', 'qa'],
        'tier': ['dev', 'test']
    }

    is_non_prod = False
    matching_label = None

    for label_key, non_prod_values in non_prod_labels.items():
        if label_key in labels:
            label_value = labels[label_key].lower()
            if label_value in non_prod_values:
                is_non_prod = True
                matching_label = f"{label_key}={label_value}"
                break

    # Heuristique: instance name contient dev/test/staging
    if not is_non_prod:
        instance_name = instance.name.split('/')[-1].lower()
        non_prod_keywords = ['dev', 'test', 'staging', 'qa', 'sandbox']

        for keyword in non_prod_keywords:
            if keyword in instance_name:
                is_non_prod = True
                matching_label = f"instance_name contains '{keyword}'"
                break

    if not is_non_prod:
        return None

    # Calcul du waste
    capacity_gb = instance.file_shares[0].capacity_gb

    # Enterprise price
    enterprise_price = 0.60
    current_monthly_cost = capacity_gb * enterprise_price

    # Zonal price (recommended)
    zonal_price = 0.18
    optimal_monthly_cost = capacity_gb * zonal_price

    monthly_waste = current_monthly_cost - optimal_monthly_cost
    annual_waste = monthly_waste * 12

    return {
        'instance_name': instance.name.split('/')[-1],
        'zone': instance.name.split('/')[3],
        'tier': 'ENTERPRISE',
        'recommended_tier': 'ZONAL',
        'reason': f"Non-prod environment detected ({matching_label})",
        'capacity_gb': capacity_gb,
        'current_monthly_cost': round(current_monthly_cost, 2),
        'optimal_monthly_cost': round(optimal_monthly_cost, 2),
        'monthly_waste': round(monthly_waste, 2),
        'annual_waste': round(annual_waste, 2),
        'waste_severity': 'CRITICAL',
        'confidence': 'HIGH',
        'labels': labels
    }


def get_filestore_iops_metrics(
    project_id: str,
    instance_name: str,
    zone: str,
    lookback_days: int
) -> Dict:
    """
    R√©cup√®re les m√©triques IOPS (read + write ops).
    """
    monitoring_client = monitoring_v3.MetricServiceClient()
    project_name = f"projects/{project_id}"

    end_time = datetime.utcnow()
    start_time = end_time - timedelta(days=lookback_days)

    interval = monitoring_v3.TimeInterval({
        "end_time": {"seconds": int(end_time.timestamp())},
        "start_time": {"seconds": int(start_time.timestamp())},
    })

    # Read ops
    read_ops = query_filestore_metric(
        monitoring_client,
        project_name,
        instance_name,
        zone,
        "file.googleapis.com/nfs/server/read_ops_count",
        interval
    )

    # Write ops
    write_ops = query_filestore_metric(
        monitoring_client,
        project_name,
        instance_name,
        zone,
        "file.googleapis.com/nfs/server/write_ops_count",
        interval
    )

    if not read_ops and not write_ops:
        return None

    # Calcul IOPS moyen (ops/seconde)
    total_read_ops = sum(read_ops) if read_ops else 0
    total_write_ops = sum(write_ops) if write_ops else 0

    total_seconds = lookback_days * 24 * 3600
    avg_read_iops = total_read_ops / total_seconds
    avg_write_iops = total_write_ops / total_seconds
    avg_total_iops = avg_read_iops + avg_write_iops

    return {
        'avg_read_iops': avg_read_iops,
        'avg_write_iops': avg_write_iops,
        'avg_total_iops': avg_total_iops
    }


def query_filestore_metric(
    monitoring_client,
    project_name: str,
    instance_name: str,
    zone: str,
    metric_type: str,
    interval
) -> List[float]:
    """Helper pour query une m√©trique Filestore."""
    filter_str = (
        f'resource.type = "filestore_instance" '
        f'AND resource.labels.instance_name = "{instance_name}" '
        f'AND resource.labels.zone = "{zone}" '
        f'AND metric.type = "{metric_type}"'
    )

    aggregation = monitoring_v3.Aggregation({
        "alignment_period": {"seconds": 3600},
        "per_series_aligner": monitoring_v3.Aggregation.Aligner.ALIGN_RATE,
    })

    try:
        results = monitoring_client.list_time_series(
            request={
                "name": project_name,
                "filter": filter_str,
                "interval": interval,
                "aggregation": aggregation,
            }
        )

        values = []
        for result in results:
            for point in result.points:
                values.append(point.value.double_value)

        return values

    except Exception as e:
        logger.error(f"Erreur query metric {metric_type}: {e}")
        return []


def calculate_ssd_to_hdd_savings(
    instance: filestore_v1.Instance,
    avg_iops: float
) -> Dict:
    """
    Calcule les √©conomies en migrant Basic SSD ‚Üí Basic HDD ou Zonal.
    """
    capacity_gb = instance.file_shares[0].capacity_gb

    # Basic SSD price
    ssd_price = 0.30
    current_monthly_cost = capacity_gb * ssd_price

    # Zonal price (meilleur choix)
    zonal_price = 0.18
    optimal_monthly_cost = capacity_gb * zonal_price

    monthly_waste = current_monthly_cost - optimal_monthly_cost
    annual_waste = monthly_waste * 12

    return {
        'instance_name': instance.name.split('/')[-1],
        'zone': instance.name.split('/')[3],
        'tier': 'BASIC_SSD',
        'recommended_tier': 'ZONAL',
        'reason': f"Low IOPS detected ({avg_iops:.1f} IOPS avg < 100 threshold)",
        'capacity_gb': capacity_gb,
        'avg_iops': round(avg_iops, 1),
        'current_monthly_cost': round(current_monthly_cost, 2),
        'optimal_monthly_cost': round(optimal_monthly_cost, 2),
        'monthly_waste': round(monthly_waste, 2),
        'annual_waste': round(annual_waste, 2),
        'waste_severity': 'HIGH',
        'confidence': 'MEDIUM'
    }


def get_filestore_throughput_metrics(
    project_id: str,
    instance_name: str,
    zone: str,
    lookback_days: int
) -> Dict:
    """
    R√©cup√®re les m√©triques de throughput (MB/s).

    Note: GCP ne fournit pas directement MB/s, on calcule via bytes/second
    """
    monitoring_client = monitoring_v3.MetricServiceClient()
    project_name = f"projects/{project_id}"

    end_time = datetime.utcnow()
    start_time = end_time - timedelta(days=lookback_days)

    interval = monitoring_v3.TimeInterval({
        "end_time": {"seconds": int(end_time.timestamp())},
        "start_time": {"seconds": int(start_time.timestamp())},
    })

    # Query read_bytes_count et write_bytes_count
    read_bytes = query_filestore_metric(
        monitoring_client,
        project_name,
        instance_name,
        zone,
        "file.googleapis.com/nfs/server/read_bytes_count",
        interval
    )

    write_bytes = query_filestore_metric(
        monitoring_client,
        project_name,
        instance_name,
        zone,
        "file.googleapis.com/nfs/server/write_bytes_count",
        interval
    )

    if not read_bytes and not write_bytes:
        return None

    # Calcul throughput moyen (MB/s)
    avg_read_bytes_per_sec = sum(read_bytes) / len(read_bytes) if read_bytes else 0
    avg_write_bytes_per_sec = sum(write_bytes) / len(write_bytes) if write_bytes else 0

    avg_read_mb_per_sec = avg_read_bytes_per_sec / (1024 * 1024)
    avg_write_mb_per_sec = avg_write_bytes_per_sec / (1024 * 1024)
    avg_throughput_mb = avg_read_mb_per_sec + avg_write_mb_per_sec

    return {
        'avg_read_mb_per_sec': avg_read_mb_per_sec,
        'avg_write_mb_per_sec': avg_write_mb_per_sec,
        'avg_throughput_mb': avg_throughput_mb
    }


def calculate_high_scale_downgrade_savings(
    instance: filestore_v1.Instance,
    avg_throughput: float
) -> Dict:
    """
    Calcule les √©conomies en downgrading High Scale SSD ‚Üí Basic SSD.
    """
    capacity_gb = instance.file_shares[0].capacity_gb

    # High Scale SSD et Basic SSD ont le m√™me prix
    # Mais High Scale a min capacity 10 TB
    # Recommandation: downgrade si capacity permet + faible throughput

    price = 0.30
    current_monthly_cost = capacity_gb * price

    # Si capacity > 10 TB et throughput faible, recommander Basic SSD
    if capacity_gb > 10240:  # 10 TB
        # Downgrade possible vers Basic SSD
        optimal_capacity_gb = 10240  # Max Basic SSD
        optimal_monthly_cost = optimal_capacity_gb * price
        monthly_waste = current_monthly_cost - optimal_monthly_cost
        annual_waste = monthly_waste * 12

        return {
            'instance_name': instance.name.split('/')[-1],
            'zone': instance.name.split('/')[3],
            'tier': 'HIGH_SCALE_SSD',
            'recommended_tier': 'BASIC_SSD',
            'reason': f"Low throughput ({avg_throughput:.1f} MB/s < 500 MB/s)",
            'capacity_gb': capacity_gb,
            'avg_throughput_mb': round(avg_throughput, 1),
            'current_monthly_cost': round(current_monthly_cost, 2),
            'optimal_monthly_cost': round(optimal_monthly_cost, 2),
            'monthly_waste': round(monthly_waste, 2),
            'annual_waste': round(annual_waste, 2),
            'waste_severity': 'HIGH',
            'confidence': 'MEDIUM'
        }

    # Pas de downgrade possible (capacit√© d√©j√† min)
    return None


# Exemple d'utilisation
if __name__ == "__main__":
    wrong_tier = detect_filestore_wrong_tier(
        project_id="my-gcp-project",
        lookback_days=14
    )

    print(f"Trouv√© {len(wrong_tier)} instances avec wrong tier")

    for instance in wrong_tier:
        print(f"\nInstance: {instance['instance_name']}")
        print(f"  Tier actuel: {instance['tier']}")
        print(f"  Tier recommand√©: {instance['recommended_tier']}")
        print(f"  Raison: {instance['reason']}")
        print(f"  Gaspillage: ${instance['monthly_waste']:.2f}/mois (${instance['annual_waste']:.2f}/an)")
        print(f"  S√©v√©rit√©: {instance['waste_severity']}")
```

**Exemples de D√©tection :**

**Exemple 1 : Enterprise pour Dev Environment**
```python
# Instance details
instance_name = "dev-shared-filestore"
tier = "ENTERPRISE"
capacity_gb = 5120  # 5 TB
labels = {'environment': 'development', 'team': 'backend'}

# Detection
matching_label = "environment=development"
is_non_prod = True

# Calcul
enterprise_price = 0.60
current_cost = 5120 * 0.60  # $3,072/mois

zonal_price = 0.18
optimal_cost = 5120 * 0.18  # $921.60/mois

monthly_waste = 3072 - 921.60  # $2,150.40/mois
annual_waste = monthly_waste * 12  # $25,804.80/an

print(f"WASTE D√âTECT√â:")
print(f"  Instance {instance_name} utilise Enterprise pour dev")
print(f"  Gaspillage: $25,805/an")
print(f"  Recommandation: Migrer vers Zonal (233% moins cher)")
print(f"  S√©v√©rit√©: CRITICAL")
```

**Exemple 2 : Basic SSD pour Cold Data**
```python
# Instance details
instance_name = "archive-filestore"
tier = "BASIC_SSD"
capacity_gb = 8192  # 8 TB
avg_iops = 45  # Tr√®s faible IOPS

# Detection
iops_threshold = 100
is_cold_data = avg_iops < iops_threshold  # True

# Calcul
ssd_price = 0.30
current_cost = 8192 * 0.30  # $2,457.60/mois

zonal_price = 0.18
optimal_cost = 8192 * 0.18  # $1,474.56/mois

monthly_waste = 2457.60 - 1474.56  # $983.04/mois
annual_waste = monthly_waste * 12  # $11,796.48/an

print(f"Instance {instance_name} avec IOPS faibles ({avg_iops})")
print(f"Recommandation: Basic SSD ‚Üí Zonal (67% moins cher)")
print(f"√âconomie: $11,796/an")
```

**Test d'Int√©gration Bash :**

```bash
#!/bin/bash
# test_filestore_wrong_tier.sh

PROJECT_ID="my-gcp-project"
ZONE="us-central1-a"
INSTANCE_NAME="test-dev-enterprise"

echo "=== Test Sc√©nario 2: Wrong Tier ==="

# 1. Cr√©er une instance Enterprise avec label dev
echo "Cr√©ation instance Enterprise pour dev..."
gcloud filestore instances create $INSTANCE_NAME \
    --zone=$ZONE \
    --tier=ENTERPRISE \
    --file-share=name="dev_share",capacity=2TB \
    --network=name="default" \
    --labels=environment=development,team=test \
    --project=$PROJECT_ID

# 2. Attendre que l'instance soit READY
echo "Attente instance READY..."
sleep 120

# 3. Ex√©cuter le detector
echo "Ex√©cution du detector..."
python3 - <<EOF
from detect_waste import detect_filestore_wrong_tier

results = detect_filestore_wrong_tier(
    project_id="$PROJECT_ID",
    lookback_days=1
)

for r in results:
    if r['instance_name'] == '$INSTANCE_NAME':
        print(f"‚úì Instance d√©tect√©e: {r['instance_name']}")
        print(f"  Tier: {r['tier']}")
        print(f"  Recommand√©: {r['recommended_tier']}")
        print(f"  Raison: {r['reason']}")
        print(f"  Waste: \${r['annual_waste']:.2f}/an")

        assert r['tier'] == 'ENTERPRISE', "Should be Enterprise"
        assert r['recommended_tier'] == 'ZONAL', "Should recommend Zonal"
        assert 'development' in r['reason'].lower(), "Should detect dev label"
        print("‚úì Test PASSED")
        exit(0)

print("‚úó Instance not detected")
exit(1)
EOF

# 4. Cleanup
echo "Suppression de l'instance..."
gcloud filestore instances delete $INSTANCE_NAME \
    --zone=$ZONE \
    --project=$PROJECT_ID \
    --quiet

echo "=== Test termin√© ==="
```

**Formule de Migration Cost :**

```python
def calculate_tier_migration_savings(
    current_tier: str,
    recommended_tier: str,
    capacity_gb: int
) -> Dict:
    """
    Calcule les √©conomies d'une migration de tier.
    """
    tier_pricing = {
        'ZONAL': 0.18,
        'BASIC_HDD': 0.20,
        'BASIC_SSD': 0.30,
        'HIGH_SCALE_SSD': 0.30,
        'ENTERPRISE': 0.60
    }

    current_price = tier_pricing[current_tier]
    recommended_price = tier_pricing[recommended_tier]

    current_monthly_cost = capacity_gb * current_price
    optimal_monthly_cost = capacity_gb * recommended_price

    monthly_savings = current_monthly_cost - optimal_monthly_cost
    annual_savings = monthly_savings * 12

    savings_percent = (monthly_savings / current_monthly_cost) * 100

    return {
        'current_monthly_cost': round(current_monthly_cost, 2),
        'optimal_monthly_cost': round(optimal_monthly_cost, 2),
        'monthly_savings': round(monthly_savings, 2),
        'annual_savings': round(annual_savings, 2),
        'savings_percent': round(savings_percent, 1)
    }


# Exemples
print(calculate_tier_migration_savings('ENTERPRISE', 'ZONAL', 5120))
# {'monthly_savings': 2150.40, 'annual_savings': 25804.80, 'savings_percent': 70.0}

print(calculate_tier_migration_savings('BASIC_SSD', 'ZONAL', 8192))
# {'monthly_savings': 983.04, 'annual_savings': 11796.48, 'savings_percent': 40.0}
```

---

### Sc√©nario 3 : Filestore Instances Idle (0 Connections)

**Description :**
Instances Filestore sans aucune connexion active et aucune op√©ration I/O pendant ‚â•7 jours cons√©cutifs. Ces instances sont compl√®tement inutilis√©es mais continuent de g√©n√©rer des co√ªts.

**Pourquoi c'est un probl√®me :**
- Instance idle = 100% du co√ªt gaspill√©
- Causes typiques :
  - Application migr√©e vers autre solution
  - Projet/POC abandonn√©
  - Instance cr√©√©e pour test et oubli√©e
- Une instance 5 TB Basic HDD idle = **$12,288/an gaspill√©s**

**Seuils de D√©tection :**
```python
IDLE_THRESHOLDS = {
    'critical': {
        'days': 90,
        'connections': 0,
        'total_iops': 0
    },
    'high': {
        'days': 30,
        'connections': 0,
        'total_iops': 10  # <10 IOPS = quasi-idle
    },
    'medium': {
        'days': 14,
        'connections': 0,
        'total_iops': 50
    },
    'low': {
        'days': 7,
        'connections': 0,
        'total_iops': 100
    }
}
```

**M√©triques Utilis√©es :**
- `file.googleapis.com/nfs/server/connections` (Gauge)
- `file.googleapis.com/nfs/server/read_ops_count` (Counter)
- `file.googleapis.com/nfs/server/write_ops_count` (Counter)

**Code de D√©tection Python :**

```python
from google.cloud import filestore_v1
from google.cloud import monitoring_v3
from datetime import datetime, timedelta
from typing import List, Dict
import logging

logger = logging.getLogger(__name__)


def detect_filestore_idle(
    project_id: str,
    lookback_days: int = 7,
    max_connections: int = 0,
    max_total_iops: float = 10
) -> List[Dict]:
    """
    D√©tecte les instances Filestore idle (0 connections + faible I/O).

    Args:
        project_id: GCP project ID
        lookback_days: P√©riode d'observation (7 jours par d√©faut)
        max_connections: Max connections moyennes (0 = strict idle)
        max_total_iops: Max IOPS moyen (10 = quasi-idle)

    Returns:
        Liste d'instances idle avec co√ªt total gaspill√©
    """
    filestore_client = filestore_v1.CloudFilestoreManagerClient()
    monitoring_client = monitoring_v3.MetricServiceClient()

    idle_instances = []

    parent = f"projects/{project_id}/locations/-"

    try:
        instances = filestore_client.list_instances(parent=parent)
    except Exception as e:
        logger.error(f"Erreur r√©cup√©ration instances: {e}")
        return []

    for instance in instances:
        instance_name = instance.name.split('/')[-1]
        zone = instance.name.split('/')[3]

        # V√©rifie connections
        connection_metrics = get_filestore_connection_metrics(
            project_id=project_id,
            instance_name=instance_name,
            zone=zone,
            lookback_days=lookback_days
        )

        if not connection_metrics:
            logger.warning(f"Pas de m√©triques pour {instance_name}")
            continue

        avg_connections = connection_metrics['avg_connections']

        # V√©rifie IOPS
        iops_metrics = get_filestore_iops_metrics(
            project_id=project_id,
            instance_name=instance_name,
            zone=zone,
            lookback_days=lookback_days
        )

        avg_total_iops = iops_metrics['avg_total_iops'] if iops_metrics else 0

        # D√©tecte si idle
        if avg_connections <= max_connections and avg_total_iops <= max_total_iops:
            # Calcule le waste
            waste_analysis = calculate_idle_filestore_waste(
                instance=instance,
                avg_connections=avg_connections,
                avg_total_iops=avg_total_iops,
                lookback_days=lookback_days
            )

            # Confidence level
            confidence = determine_idle_confidence_level(
                avg_connections=avg_connections,
                avg_total_iops=avg_total_iops,
                lookback_days=lookback_days
            )

            idle_instances.append({
                'instance_name': instance_name,
                'zone': zone,
                'tier': instance.tier.name,
                'capacity_gb': instance.file_shares[0].capacity_gb,
                'avg_connections': avg_connections,
                'avg_total_iops': round(avg_total_iops, 2),
                'monthly_cost': waste_analysis['monthly_cost'],
                'annual_cost': waste_analysis['annual_cost'],
                'already_wasted': waste_analysis['already_wasted'],
                'confidence': confidence,
                'idle_days': lookback_days,
                'created_at': instance.create_time.isoformat() if instance.create_time else None,
                'labels': dict(instance.labels) if instance.labels else {}
            })

    # Trie par annual cost d√©croissant
    idle_instances.sort(key=lambda x: x['annual_cost'], reverse=True)

    return idle_instances


def get_filestore_connection_metrics(
    project_id: str,
    instance_name: str,
    zone: str,
    lookback_days: int
) -> Dict:
    """
    R√©cup√®re les m√©triques de connexions actives.
    """
    monitoring_client = monitoring_v3.MetricServiceClient()
    project_name = f"projects/{project_id}"

    end_time = datetime.utcnow()
    start_time = end_time - timedelta(days=lookback_days)

    interval = monitoring_v3.TimeInterval({
        "end_time": {"seconds": int(end_time.timestamp())},
        "start_time": {"seconds": int(start_time.timestamp())},
    })

    filter_str = (
        f'resource.type = "filestore_instance" '
        f'AND resource.labels.instance_name = "{instance_name}" '
        f'AND resource.labels.zone = "{zone}" '
        f'AND metric.type = "file.googleapis.com/nfs/server/connections"'
    )

    aggregation = monitoring_v3.Aggregation({
        "alignment_period": {"seconds": 3600},  # 1 heure
        "per_series_aligner": monitoring_v3.Aggregation.Aligner.ALIGN_MEAN,
    })

    try:
        results = monitoring_client.list_time_series(
            request={
                "name": project_name,
                "filter": filter_str,
                "interval": interval,
                "aggregation": aggregation,
            }
        )

        connection_values = []
        for result in results:
            for point in result.points:
                connection_values.append(point.value.double_value)

        if not connection_values:
            return None

        avg_connections = sum(connection_values) / len(connection_values)
        max_connections = max(connection_values)

        return {
            'avg_connections': avg_connections,
            'max_connections': max_connections,
            'num_samples': len(connection_values)
        }

    except Exception as e:
        logger.error(f"Erreur query connections metric: {e}")
        return None


def calculate_idle_filestore_waste(
    instance: filestore_v1.Instance,
    avg_connections: float,
    avg_total_iops: float,
    lookback_days: int
) -> Dict:
    """
    Calcule le co√ªt total gaspill√© par une instance idle.
    """
    tier_pricing = {
        'STANDARD': 0.20,
        'PREMIUM': 0.30,
        'BASIC_HDD': 0.20,
        'BASIC_SSD': 0.30,
        'HIGH_SCALE_SSD': 0.30,
        'ENTERPRISE': 0.60,
        'ZONAL': 0.18
    }

    tier = instance.tier.name
    price_per_gb = tier_pricing.get(tier, 0.20)
    capacity_gb = instance.file_shares[0].capacity_gb

    # Co√ªt mensuel/annuel
    monthly_cost = capacity_gb * price_per_gb
    annual_cost = monthly_cost * 12

    # Calcul du waste d√©j√† accumul√© depuis cr√©ation
    if instance.create_time:
        created_at = instance.create_time
        age_days = (datetime.now(created_at.tzinfo) - created_at).days

        # Si idle depuis lookback_days, assume idle depuis min(age_days, lookback_days * 3)
        # (heuristique conservative)
        estimated_idle_days = min(age_days, lookback_days * 3)
        already_wasted = (monthly_cost / 30) * estimated_idle_days
    else:
        already_wasted = 0

    return {
        'monthly_cost': round(monthly_cost, 2),
        'annual_cost': round(annual_cost, 2),
        'already_wasted': round(already_wasted, 2)
    }


def determine_idle_confidence_level(
    avg_connections: float,
    avg_total_iops: float,
    lookback_days: int
) -> str:
    """
    D√©termine le niveau de confiance.
    """
    if avg_connections == 0 and avg_total_iops == 0 and lookback_days >= 90:
        return 'CRITICAL'
    elif avg_connections == 0 and avg_total_iops < 10 and lookback_days >= 30:
        return 'HIGH'
    elif avg_connections == 0 and avg_total_iops < 50 and lookback_days >= 14:
        return 'MEDIUM'
    else:
        return 'LOW'


# Exemple d'utilisation
if __name__ == "__main__":
    idle_instances = detect_filestore_idle(
        project_id="my-gcp-project",
        lookback_days=30,
        max_connections=0,
        max_total_iops=10
    )

    print(f"Trouv√© {len(idle_instances)} instances idle")

    total_monthly_waste = sum(i['monthly_cost'] for i in idle_instances)
    total_annual_waste = sum(i['annual_cost'] for i in idle_instances)

    print(f"Gaspillage total: ${total_monthly_waste:.2f}/mois (${total_annual_waste:.2f}/an)")

    for instance in idle_instances:
        print(f"\nInstance: {instance['instance_name']}")
        print(f"  Tier: {instance['tier']}")
        print(f"  Capacit√©: {instance['capacity_gb']} GB")
        print(f"  Connections moyennes: {instance['avg_connections']}")
        print(f"  IOPS moyen: {instance['avg_total_iops']}")
        print(f"  Co√ªt: ${instance['monthly_cost']:.2f}/mois (${instance['annual_cost']:.2f}/an)")
        print(f"  D√©j√† gaspill√©: ${instance['already_wasted']:.2f}")
        print(f"  Confiance: {instance['confidence']}")
```

**Exemples de D√©tection :**

**Exemple 1 : Instance Compl√®tement Idle (90 jours)**
```python
# Instance details
instance_name = "old-poc-filestore"
tier = "BASIC_HDD"
capacity_gb = 5120  # 5 TB
avg_connections = 0
avg_total_iops = 0
idle_days = 90

# Calcul
price_per_gb = 0.20
monthly_cost = 5120 * 0.20  # $1,024/mois
annual_cost = monthly_cost * 12  # $12,288/an

# Already wasted (assume idle depuis cr√©ation)
estimated_idle_days = 90
already_wasted = (monthly_cost / 30) * 90  # $3,072

print(f"WASTE D√âTECT√â:")
print(f"  Instance {instance_name} est compl√®tement idle")
print(f"  0 connections, 0 IOPS pendant 90 jours")
print(f"  Co√ªt: $1,024/mois ($12,288/an)")
print(f"  D√©j√† gaspill√©: $3,072")
print(f"  Recommandation: SUPPRIMER imm√©diatement")
print(f"  Confiance: CRITICAL")
```

**Exemple 2 : Instance Quasi-Idle (30 jours)**
```python
# Instance details
instance_name = "staging-filestore-unused"
tier = "ENTERPRISE"
capacity_gb = 3072  # 3 TB
avg_connections = 0
avg_total_iops = 8  # Tr√®s faible (monitoring checks)
idle_days = 30

# Calcul
price_per_gb = 0.60
monthly_cost = 3072 * 0.60  # $1,843.20/mois
annual_cost = monthly_cost * 12  # $22,118.40/an

already_wasted = (monthly_cost / 30) * 30  # $1,843.20

print(f"Instance {instance_name} quasi-idle")
print(f"8 IOPS avg (probablement monitoring seulement)")
print(f"Gaspillage: $22,118/an")
print(f"Recommandation: Supprimer ou investiguer usage")
```

**Test d'Int√©gration Bash :**

```bash
#!/bin/bash
# test_filestore_idle.sh

PROJECT_ID="my-gcp-project"
ZONE="us-central1-a"
INSTANCE_NAME="test-idle-filestore"

echo "=== Test Sc√©nario 3: Filestore Idle ==="

# 1. Cr√©er une instance test
echo "Cr√©ation instance Filestore..."
gcloud filestore instances create $INSTANCE_NAME \
    --zone=$ZONE \
    --tier=ZONAL \
    --file-share=name="idle_share",capacity=1TB \
    --network=name="default" \
    --project=$PROJECT_ID

# 2. Attendre READY mais NE PAS monter le share (reste idle)
echo "Attente instance READY (sans montage = idle)..."
sleep 120

# 3. Attendre p√©riode d'observation (min 1 heure pour m√©triques)
echo "Attente collecte m√©triques idle (60 min)..."
sleep 3600

# 4. Ex√©cuter le detector
echo "Ex√©cution du detector..."
python3 - <<EOF
from detect_waste import detect_filestore_idle

results = detect_filestore_idle(
    project_id="$PROJECT_ID",
    lookback_days=1,  # Test court
    max_connections=0,
    max_total_iops=10
)

for r in results:
    if r['instance_name'] == '$INSTANCE_NAME':
        print(f"‚úì Instance idle d√©tect√©e: {r['instance_name']}")
        print(f"  Connections: {r['avg_connections']}")
        print(f"  IOPS: {r['avg_total_iops']}")
        print(f"  Co√ªt annuel: \${r['annual_cost']:.2f}")

        assert r['avg_connections'] == 0, "Should have 0 connections"
        assert r['avg_total_iops'] < 10, "Should have <10 IOPS"
        print("‚úì Test PASSED")
        exit(0)

print("‚úó Instance not detected (peut n√©cessiter plus de temps pour m√©triques)")
exit(1)
EOF

TEST_RESULT=$?

# 5. Cleanup
echo "Suppression de l'instance..."
gcloud filestore instances delete $INSTANCE_NAME \
    --zone=$ZONE \
    --project=$PROJECT_ID \
    --quiet

if [ $TEST_RESULT -eq 0 ]; then
    echo "=== Test PASSED ==="
else
    echo "=== Test FAILED (peut √™tre faux n√©gatif si m√©triques pas encore disponibles) ==="
fi
```

**Recommandations Utilisateur :**

```python
def generate_idle_filestore_recommendation(instance: Dict) -> str:
    """G√©n√®re une recommandation pour une instance idle."""

    recommendation = f"""
üî¥ Filestore Instance Idle D√©tect√©e

Instance: {instance['instance_name']}
Tier: {instance['tier']}
Zone: {instance['zone']}
Capacit√©: {instance['capacity_gb']} GB ({instance['capacity_gb']/1024:.1f} TB)

üìä Activit√©:
  ‚Ä¢ Connections moyennes: {instance['avg_connections']} (aucune!)
  ‚Ä¢ IOPS moyen: {instance['avg_total_iops']} (quasi-nul)
  ‚Ä¢ P√©riode idle: {instance['idle_days']} jours cons√©cutifs

üí∞ Co√ªt:
  ‚Ä¢ Co√ªt mensuel: ${instance['monthly_cost']:.2f}
  ‚Ä¢ Co√ªt annuel: ${instance['annual_cost']:.2f}
  ‚Ä¢ D√©j√† gaspill√©: ${instance['already_wasted']:.2f}

‚úÖ Recommandation: SUPPRIMER L'INSTANCE

Cette instance est compl√®tement inutilis√©e. Avant suppression:

1. V√©rifier si donn√©es importantes stock√©es:
```bash
# Monter temporairement et v√©rifier contenu
sudo mount -t nfs {instance['instance_name']}.filestore.{instance['zone']}.c.YOUR_PROJECT.internal:/test_share /mnt/temp
ls -lah /mnt/temp
```

2. Backup si n√©cessaire:
```bash
# Cr√©er backup
gcloud filestore backups create idle-backup-$(date +%Y%m%d) \\
    --instance={instance['instance_name']} \\
    --zone={instance['zone']} \\
    --region={instance['zone'][:-2]}
```

3. Supprimer l'instance:
```bash
gcloud filestore instances delete {instance['instance_name']} \\
    --zone={instance['zone']} \\
    --project=YOUR_PROJECT_ID
```

‚ö†Ô∏è Note: Le backup co√ªte $0.10/GB/mois. Si les donn√©es ne sont jamais
utilis√©es, supprimer aussi les backups apr√®s v√©rification.

üí° √âconomie imm√©diate: ${instance['annual_cost']:.2f}/an
"""

    return recommendation
```

---

### Sc√©nario 4 : Overprovisioned Capacity

**Description :**
Instances Filestore avec une utilisation **< 10%** de la capacit√© provisionn√©e pendant ‚â•30 jours. Ces instances sont s√©v√®rement sur-dimensionn√©es et gaspillent un budget massif.

**Pourquoi c'est un probl√®me :**
- Diff√©rence avec Sc√©nario 1 (sous-utilisation) : Overprovisioning est **extr√™me** (<10% vs <30%)
- Causes typiques :
  - Provisionnement initial "par s√©curit√©" (10 TB au lieu de 1 TB)
  - Croissance de donn√©es surestim√©e
  - Donn√©es supprim√©es mais capacit√© jamais r√©duite
- Une instance 10 TB utilis√©e √† 5% (500 GB) gaspille **$16,000/an** (tier Zonal)

**Seuils de D√©tection :**
```python
OVERPROVISIONING_THRESHOLDS = {
    'critical': 0.05,   # <5% utilis√© pendant 60 jours
    'high': 0.08,       # <8% utilis√© pendant 45 jours
    'medium': 0.10,     # <10% utilis√© pendant 30 jours
}
```

**M√©trique Utilis√©e :**
- `file.googleapis.com/nfs/server/used_bytes_percent`

**Code de D√©tection Python :**

```python
from google.cloud import filestore_v1
from google.cloud import monitoring_v3
from datetime import datetime, timedelta
from typing import List, Dict
import logging

logger = logging.getLogger(__name__)


def detect_filestore_overprovisioned(
    project_id: str,
    utilization_threshold: float = 0.10,
    lookback_days: int = 30
) -> List[Dict]:
    """
    D√©tecte les instances Filestore s√©v√®rement sur-provisionn√©es (<10% utilization).

    Args:
        project_id: GCP project ID
        utilization_threshold: Seuil d'utilisation (0.10 = 10%)
        lookback_days: P√©riode d'observation (30 jours par d√©faut)

    Returns:
        Liste d'instances overprovisionn√©es avec √©conomies potentielles
    """
    filestore_client = filestore_v1.CloudFilestoreManagerClient()
    monitoring_client = monitoring_v3.MetricServiceClient()

    overprovisioned_instances = []

    parent = f"projects/{project_id}/locations/-"

    try:
        instances = filestore_client.list_instances(parent=parent)
    except Exception as e:
        logger.error(f"Erreur r√©cup√©ration instances: {e}")
        return []

    for instance in instances:
        instance_name = instance.name.split('/')[-1]
        zone = instance.name.split('/')[3]

        # R√©cup√®re m√©triques d'utilisation
        utilization_metrics = get_filestore_utilization_metrics(
            project_id=project_id,
            instance_name=instance_name,
            zone=zone,
            lookback_days=lookback_days
        )

        if not utilization_metrics:
            continue

        avg_utilization = utilization_metrics['avg_utilization_percent'] / 100
        max_utilization = utilization_metrics['max_utilization_percent'] / 100

        # V√©rifie overprovisioning
        if avg_utilization < utilization_threshold:
            waste_analysis = calculate_overprovisioning_waste(
                instance=instance,
                avg_utilization=avg_utilization,
                max_utilization=max_utilization
            )

            confidence = determine_overprovisioning_confidence(
                avg_utilization=avg_utilization,
                max_utilization=max_utilization,
                lookback_days=lookback_days
            )

            overprovisioned_instances.append({
                'instance_name': instance_name,
                'zone': zone,
                'tier': instance.tier.name,
                'provisioned_capacity_gb': instance.file_shares[0].capacity_gb,
                'used_capacity_gb': waste_analysis['used_capacity_gb'],
                'avg_utilization_percent': avg_utilization * 100,
                'max_utilization_percent': max_utilization * 100,
                'recommended_capacity_gb': waste_analysis['recommended_capacity_gb'],
                'current_monthly_cost': waste_analysis['current_monthly_cost'],
                'optimal_monthly_cost': waste_analysis['optimal_monthly_cost'],
                'monthly_waste': waste_analysis['monthly_waste'],
                'annual_waste': waste_analysis['annual_waste'],
                'waste_percent': waste_analysis['waste_percent'],
                'confidence': confidence,
                'lookback_days': lookback_days
            })

    overprovisioned_instances.sort(key=lambda x: x['annual_waste'], reverse=True)

    return overprovisioned_instances


def calculate_overprovisioning_waste(
    instance: filestore_v1.Instance,
    avg_utilization: float,
    max_utilization: float
) -> Dict:
    """
    Calcule le gaspillage d'une instance overprovisionn√©e.

    Strat√©gie: Dimensionner pour max_utilization + 50% buffer (vs 30% pour sous-utilisation).
    """
    tier_pricing = {
        'STANDARD': 0.20,
        'PREMIUM': 0.30,
        'BASIC_HDD': 0.20,
        'BASIC_SSD': 0.30,
        'HIGH_SCALE_SSD': 0.30,
        'ENTERPRISE': 0.60,
        'ZONAL': 0.18
    }

    tier = instance.tier.name
    price_per_gb = tier_pricing.get(tier, 0.20)
    provisioned_capacity_gb = instance.file_shares[0].capacity_gb

    # Capacit√© utilis√©e (moyenne)
    used_capacity_gb = int(provisioned_capacity_gb * avg_utilization)

    # Capacit√© optimale bas√©e sur max utilization + 50% buffer
    max_used_capacity_gb = int(provisioned_capacity_gb * max_utilization)
    recommended_capacity_gb = int(max_used_capacity_gb * 1.50)

    # Arrondi au multiple de 256 GB sup√©rieur
    recommended_capacity_gb = ((recommended_capacity_gb + 255) // 256) * 256

    # Min capacity par tier
    min_capacity = {
        'ZONAL': 1024,
        'BASIC_HDD': 1024,
        'BASIC_SSD': 2560,
        'HIGH_SCALE_SSD': 10240,
        'ENTERPRISE': 1024
    }

    recommended_capacity_gb = max(
        recommended_capacity_gb,
        min_capacity.get(tier, 1024)
    )

    # Co√ªts
    current_monthly_cost = provisioned_capacity_gb * price_per_gb
    optimal_monthly_cost = recommended_capacity_gb * price_per_gb
    monthly_waste = current_monthly_cost - optimal_monthly_cost
    annual_waste = monthly_waste * 12

    waste_percent = (monthly_waste / current_monthly_cost) * 100

    return {
        'used_capacity_gb': used_capacity_gb,
        'recommended_capacity_gb': recommended_capacity_gb,
        'current_monthly_cost': round(current_monthly_cost, 2),
        'optimal_monthly_cost': round(optimal_monthly_cost, 2),
        'monthly_waste': round(monthly_waste, 2),
        'annual_waste': round(annual_waste, 2),
        'waste_percent': round(waste_percent, 1)
    }


def determine_overprovisioning_confidence(
    avg_utilization: float,
    max_utilization: float,
    lookback_days: int
) -> str:
    """
    D√©termine le niveau de confiance pour overprovisioning.
    """
    if avg_utilization < 0.05 and max_utilization < 0.08 and lookback_days >= 60:
        return 'CRITICAL'
    elif avg_utilization < 0.08 and max_utilization < 0.12 and lookback_days >= 45:
        return 'HIGH'
    elif avg_utilization < 0.10 and lookback_days >= 30:
        return 'MEDIUM'
    else:
        return 'LOW'


# Exemple d'utilisation
if __name__ == "__main__":
    overprovisioned = detect_filestore_overprovisioned(
        project_id="my-gcp-project",
        utilization_threshold=0.10,
        lookback_days=30
    )

    print(f"Trouv√© {len(overprovisioned)} instances overprovisionn√©es")

    total_annual_waste = sum(i['annual_waste'] for i in overprovisioned)
    print(f"Gaspillage total: ${total_annual_waste:,.2f}/an")

    for instance in overprovisioned:
        print(f"\nInstance: {instance['instance_name']}")
        print(f"  Capacit√© provisionn√©e: {instance['provisioned_capacity_gb']} GB")
        print(f"  Utilisation moyenne: {instance['avg_utilization_percent']:.1f}%")
        print(f"  Utilisation max: {instance['max_utilization_percent']:.1f}%")
        print(f"  Recommandation: Downsize √† {instance['recommended_capacity_gb']} GB")
        print(f"  Gaspillage: ${instance['monthly_waste']:.2f}/mois (${instance['annual_waste']:.2f}/an)")
        print(f"  √âconomie: {instance['waste_percent']:.1f}%")
```

**Exemple de D√©tection :**

```python
# Instance 20 TB utilis√©e √† 3%
instance_name = "legacy-filestore-oversized"
tier = "BASIC_HDD"
provisioned_capacity_gb = 20480  # 20 TB
avg_utilization = 0.03  # 3%
max_utilization = 0.05  # 5% (pic)
used_capacity_gb = 614  # ~600 GB

# Calcul optimal
max_used_gb = 1024  # 1 TB (5% de 20 TB)
recommended_gb = int(1024 * 1.50)  # 1.5 TB ‚Üí 1536 GB arrondi √† 1536 GB

# Co√ªts
price_per_gb = 0.20
current_cost = 20480 * 0.20  # $4,096/mois
optimal_cost = 1536 * 0.20  # $307.20/mois

monthly_waste = 4096 - 307.20  # $3,788.80/mois
annual_waste = monthly_waste * 12  # $45,465.60/an
waste_percent = (monthly_waste / current_cost) * 100  # 92.5%

print(f"WASTE CRITIQUE D√âTECT√â:")
print(f"  Instance {instance_name}")
print(f"  Provisionn√©e: 20 TB, Utilis√©e: 600 GB (3%)")
print(f"  Gaspillage: $45,466/an (92.5% du budget!)")
print(f"  Recommandation: Downsize 20 TB ‚Üí 1.5 TB")
print(f"  Confiance: CRITICAL")
```

---

### Sc√©nario 5 : Filestore Instances Untagged

**Description :**
Instances Filestore sans labels/tags appropri√©s pour la cat√©gorisation, le cost allocation, ou la gouvernance. Les instances non-tagg√©es compliquent la gestion des co√ªts et emp√™chent l'identification rapide des ressources.

**Pourquoi c'est un probl√®me :**
- Impossible d'allouer les co√ªts par √©quipe/projet/environnement
- Risque de garder des instances orphelines (pas d'owner identifiable)
- Impossible de filtrer dev/test/prod pour appliquer policies
- Audit et compliance difficiles

**Labels Critiques Recommand√©s :**
```python
REQUIRED_LABELS = {
    'environment': ['prod', 'staging', 'dev', 'test'],  # Tier d'environnement
    'team': ['backend', 'frontend', 'data', 'ml'],      # √âquipe propri√©taire
    'application': ['app-name'],                         # Application utilisant le share
    'cost-center': ['cc-12345'],                        # Centre de co√ªt
    'owner': ['email@example.com']                      # Contact responsable
}
```

**D√©tection :**

```python
from google.cloud import filestore_v1
from typing import List, Dict
import logging

logger = logging.getLogger(__name__)


def detect_filestore_untagged(
    project_id: str,
    required_labels: List[str] = None
) -> List[Dict]:
    """
    D√©tecte les instances Filestore sans labels critiques.

    Args:
        project_id: GCP project ID
        required_labels: Liste de labels requis (ex: ['environment', 'team', 'owner'])

    Returns:
        Liste d'instances non-tagg√©es
    """
    if required_labels is None:
        required_labels = ['environment', 'team', 'owner']

    filestore_client = filestore_v1.CloudFilestoreManagerClient()

    untagged_instances = []

    parent = f"projects/{project_id}/locations/-"

    try:
        instances = filestore_client.list_instances(parent=parent)
    except Exception as e:
        logger.error(f"Erreur r√©cup√©ration instances: {e}")
        return []

    for instance in instances:
        instance_name = instance.name.split('/')[-1]
        zone = instance.name.split('/')[3]
        labels = dict(instance.labels) if instance.labels else {}

        # V√©rifie labels manquants
        missing_labels = []
        for required_label in required_labels:
            if required_label not in labels or not labels[required_label]:
                missing_labels.append(required_label)

        if missing_labels:
            # Calcule co√ªt annuel (important pour prioriser remediation)
            tier_pricing = {
                'STANDARD': 0.20,
                'PREMIUM': 0.30,
                'BASIC_HDD': 0.20,
                'BASIC_SSD': 0.30,
                'HIGH_SCALE_SSD': 0.30,
                'ENTERPRISE': 0.60,
                'ZONAL': 0.18
            }

            tier = instance.tier.name
            price_per_gb = tier_pricing.get(tier, 0.20)
            capacity_gb = instance.file_shares[0].capacity_gb
            annual_cost = capacity_gb * price_per_gb * 12

            untagged_instances.append({
                'instance_name': instance_name,
                'zone': zone,
                'tier': tier,
                'capacity_gb': capacity_gb,
                'annual_cost': round(annual_cost, 2),
                'existing_labels': labels,
                'missing_labels': missing_labels,
                'risk_level': determine_tagging_risk_level(missing_labels, annual_cost),
                'created_at': instance.create_time.isoformat() if instance.create_time else None
            })

    # Trie par annual cost d√©croissant
    untagged_instances.sort(key=lambda x: x['annual_cost'], reverse=True)

    return untagged_instances


def determine_tagging_risk_level(
    missing_labels: List[str],
    annual_cost: float
) -> str:
    """
    D√©termine le niveau de risque bas√© sur labels manquants et co√ªt.
    """
    critical_labels = ['owner', 'environment']
    num_critical_missing = sum(1 for label in missing_labels if label in critical_labels)

    if num_critical_missing >= 2 and annual_cost > 10000:
        return 'CRITICAL'
    elif num_critical_missing >= 1 and annual_cost > 5000:
        return 'HIGH'
    elif len(missing_labels) >= 2:
        return 'MEDIUM'
    else:
        return 'LOW'


def generate_tagging_recommendations(
    untagged_instances: List[Dict]
) -> str:
    """
    G√©n√®re un script de remediation pour appliquer les labels.
    """
    script = "#!/bin/bash\n"
    script += "# Script de remediation - Ajout de labels Filestore\n\n"

    for instance in untagged_instances:
        script += f"# Instance: {instance['instance_name']} (missing: {', '.join(instance['missing_labels'])})\n"
        script += f"gcloud filestore instances update {instance['instance_name']} \\\n"
        script += f"    --zone={instance['zone']} \\\n"

        # Suggestion de labels
        suggested_labels = {
            'environment': 'TO_BE_FILLED',
            'team': 'TO_BE_FILLED',
            'owner': 'TO_BE_FILLED'
        }

        # Pr√©serve les labels existants
        all_labels = {**instance['existing_labels'], **suggested_labels}

        labels_str = ','.join([f"{k}={v}" for k, v in all_labels.items()])
        script += f"    --update-labels={labels_str}\n\n"

    return script


# Exemple d'utilisation
if __name__ == "__main__":
    untagged = detect_filestore_untagged(
        project_id="my-gcp-project",
        required_labels=['environment', 'team', 'owner', 'cost-center']
    )

    print(f"Trouv√© {len(untagged)} instances non-tagg√©es")

    total_annual_cost = sum(i['annual_cost'] for i in untagged)
    print(f"Co√ªt annuel total non-allou√©: ${total_annual_cost:,.2f}")

    for instance in untagged:
        print(f"\nInstance: {instance['instance_name']}")
        print(f"  Labels manquants: {', '.join(instance['missing_labels'])}")
        print(f"  Co√ªt annuel: ${instance['annual_cost']:,.2f}")
        print(f"  Risque: {instance['risk_level']}")

    # G√©n√®re script de remediation
    remediation_script = generate_tagging_recommendations(untagged)
    with open('filestore_tagging_remediation.sh', 'w') as f:
        f.write(remediation_script)

    print("\nScript de remediation g√©n√©r√©: filestore_tagging_remediation.sh")
```

**Exemple de D√©tection :**

```python
# Instance sans labels critiques
instance_name = "prod-filestore-001"
tier = "ENTERPRISE"
capacity_gb = 8192  # 8 TB
labels = {'application': 'legacy-app'}  # Seulement 1 label
required_labels = ['environment', 'team', 'owner', 'cost-center']

# D√©tection
missing_labels = ['environment', 'team', 'owner', 'cost-center']

# Co√ªt annuel
annual_cost = 8192 * 0.60 * 12  # $59,064/an

# Risque
num_critical_missing = 2  # 'environment' et 'owner'
risk_level = 'CRITICAL'  # (2 critical labels missing + $59K/an)

print(f"GOUVERNANCE ISSUE D√âTECT√âE:")
print(f"  Instance {instance_name} (Enterprise, 8 TB)")
print(f"  Labels manquants: {', '.join(missing_labels)}")
print(f"  Co√ªt annuel: $59,064 (non allou√© √† un cost-center)")
print(f"  Risque: {risk_level}")
print(f"  Recommandation: Appliquer labels immediately")
```

---

### Sc√©nario 6 : No Backup Policy

**Description :**
Instances Filestore **sans backup policy configur√©e** ou avec une policy inad√©quate (r√©tention trop courte/longue, fr√©quence incorrecte). Les backups mal configur√©s g√©n√®rent soit un risque de perte de donn√©es, soit un surco√ªt inutile.

**Pourquoi c'est un probl√®me :**
- **Pas de backup** = Risque de perte de donn√©es (violation compliance)
- **Trop de backups** = Co√ªt excessif ($0.10/GB/mois par backup)
- **Mauvaise r√©tention** = Soit risque, soit gaspillage

**R√®gles de Backup Recommand√©es :**

```python
BACKUP_POLICY_RULES = {
    'prod': {
        'frequency_hours': 24,      # Daily
        'retention_days': 30,       # 30 jours
        'max_backups': 30           # ~1 mois de daily
    },
    'staging': {
        'frequency_hours': 168,     # Weekly
        'retention_days': 14,       # 2 semaines
        'max_backups': 2
    },
    'dev': {
        'frequency_hours': None,    # Pas de backup automatique
        'retention_days': 7,        # Si backup manuel
        'max_backups': 1
    }
}
```

**D√©tection :**

```python
from google.cloud import filestore_v1
from google.cloud import monitoring_v3
from datetime import datetime, timedelta
from typing import List, Dict
import logging

logger = logging.getLogger(__name__)


def detect_filestore_no_backup_policy(
    project_id: str
) -> List[Dict]:
    """
    D√©tecte les instances Filestore sans backup policy ou avec policy inad√©quate.

    Returns:
        Liste d'instances avec probl√®mes de backup
    """
    filestore_client = filestore_v1.CloudFilestoreManagerClient()

    issues = []

    parent = f"projects/{project_id}/locations/-"

    try:
        instances = filestore_client.list_instances(parent=parent)
    except Exception as e:
        logger.error(f"Erreur r√©cup√©ration instances: {e}")
        return []

    for instance in instances:
        instance_name = instance.name.split('/')[-1]
        zone = instance.name.split('/')[3]
        labels = dict(instance.labels) if instance.labels else {}
        environment = labels.get('environment', 'unknown').lower()

        # R√©cup√®re les backups existants pour cette instance
        backups = list_filestore_backups(
            project_id=project_id,
            instance_name=instance_name,
            zone=zone
        )

        # Analyse la policy de backup
        backup_analysis = analyze_backup_policy(
            instance=instance,
            backups=backups,
            environment=environment
        )

        if backup_analysis['has_issue']:
            issues.append({
                'instance_name': instance_name,
                'zone': zone,
                'tier': instance.tier.name,
                'capacity_gb': instance.file_shares[0].capacity_gb,
                'environment': environment,
                'num_backups': len(backups),
                'issue_type': backup_analysis['issue_type'],
                'issue_description': backup_analysis['issue_description'],
                'risk_level': backup_analysis['risk_level'],
                'monthly_backup_cost': backup_analysis['monthly_backup_cost'],
                'annual_backup_waste': backup_analysis['annual_backup_waste'],
                'recommended_action': backup_analysis['recommended_action']
            })

    # Trie par risk_level puis annual_backup_waste
    risk_order = {'CRITICAL': 0, 'HIGH': 1, 'MEDIUM': 2, 'LOW': 3}
    issues.sort(key=lambda x: (risk_order[x['risk_level']], -x['annual_backup_waste']))

    return issues


def list_filestore_backups(
    project_id: str,
    instance_name: str,
    zone: str
) -> List:
    """
    Liste les backups pour une instance Filestore.
    """
    filestore_client = filestore_v1.CloudFilestoreManagerClient()

    region = zone.rsplit('-', 1)[0]  # us-central1-a ‚Üí us-central1
    parent = f"projects/{project_id}/locations/{region}"

    try:
        backups = filestore_client.list_backups(parent=parent)

        # Filtre par instance
        instance_backups = [
            backup for backup in backups
            if instance_name in backup.source_instance
        ]

        return instance_backups

    except Exception as e:
        logger.error(f"Erreur r√©cup√©ration backups: {e}")
        return []


def analyze_backup_policy(
    instance: filestore_v1.Instance,
    backups: List,
    environment: str
) -> Dict:
    """
    Analyse la policy de backup et d√©tecte les probl√®mes.
    """
    capacity_gb = instance.file_shares[0].capacity_gb
    num_backups = len(backups)

    # R√®gles recommand√©es par environnement
    recommended_backups = {
        'prod': 30,      # Daily pendant 30 jours
        'production': 30,
        'staging': 2,    # Weekly pendant 2 semaines
        'dev': 0,        # Pas de backup
        'development': 0,
        'test': 0,
        'unknown': 7     # Conservative default
    }

    recommended = recommended_backups.get(environment, 7)

    # Calcul du co√ªt backup
    backup_price_per_gb = 0.10
    monthly_backup_cost = capacity_gb * num_backups * backup_price_per_gb
    annual_backup_cost = monthly_backup_cost * 12

    # D√©tection des probl√®mes
    issue_type = None
    issue_description = None
    risk_level = 'LOW'
    annual_backup_waste = 0

    # Probl√®me 1: Aucun backup pour prod
    if environment in ['prod', 'production'] and num_backups == 0:
        issue_type = 'NO_BACKUP_PROD'
        issue_description = f"Instance production sans aucun backup (risque de perte de donn√©es)"
        risk_level = 'CRITICAL'
        recommended_action = f"Cr√©er backup policy: daily, r√©tention 30 jours"

    # Probl√®me 2: Trop de backups
    elif num_backups > recommended * 2:
        issue_type = 'EXCESSIVE_BACKUPS'
        optimal_backups = recommended
        optimal_cost = capacity_gb * optimal_backups * backup_price_per_gb * 12
        annual_backup_waste = annual_backup_cost - optimal_cost

        issue_description = f"{num_backups} backups (recommand√©: {recommended}) - surco√ªt backup"
        risk_level = 'MEDIUM' if annual_backup_waste > 1000 else 'LOW'
        recommended_action = f"R√©duire r√©tention √† {recommended} backups"

    # Probl√®me 3: Backups pour dev/test
    elif environment in ['dev', 'development', 'test'] and num_backups > 1:
        issue_type = 'UNNECESSARY_BACKUPS_NON_PROD'
        annual_backup_waste = annual_backup_cost

        issue_description = f"{num_backups} backups pour environnement {environment} (non n√©cessaire)"
        risk_level = 'LOW' if annual_backup_waste < 500 else 'MEDIUM'
        recommended_action = f"Supprimer backups automatiques pour {environment}"

    # Probl√®me 4: Backups anciens jamais utilis√©s
    elif num_backups > 0:
        oldest_backup = min(backups, key=lambda b: b.create_time)
        age_days = (datetime.now(oldest_backup.create_time.tzinfo) - oldest_backup.create_time).days

        if age_days > 365 and environment != 'prod':
            issue_type = 'OLD_BACKUPS_NEVER_USED'
            annual_backup_waste = monthly_backup_cost * 12

            issue_description = f"Backups anciens (>{age_days} jours) probablement jamais restaur√©s"
            risk_level = 'LOW'
            recommended_action = "V√©rifier si backups toujours n√©cessaires, supprimer les plus anciens"

    # Pas de probl√®me d√©tect√©
    else:
        return {
            'has_issue': False
        }

    return {
        'has_issue': True,
        'issue_type': issue_type,
        'issue_description': issue_description,
        'risk_level': risk_level,
        'monthly_backup_cost': round(monthly_backup_cost, 2),
        'annual_backup_waste': round(annual_backup_waste, 2),
        'recommended_action': recommended_action
    }


# Exemple d'utilisation
if __name__ == "__main__":
    backup_issues = detect_filestore_no_backup_policy(
        project_id="my-gcp-project"
    )

    print(f"Trouv√© {len(backup_issues)} instances avec probl√®mes de backup")

    total_waste = sum(i['annual_backup_waste'] for i in backup_issues)
    print(f"Gaspillage backup total: ${total_waste:,.2f}/an")

    for issue in backup_issues:
        print(f"\nInstance: {issue['instance_name']}")
        print(f"  Environnement: {issue['environment']}")
        print(f"  Probl√®me: {issue['issue_description']}")
        print(f"  Backups actuels: {issue['num_backups']}")
        print(f"  Co√ªt backup: ${issue['monthly_backup_cost']:.2f}/mois")
        print(f"  Gaspillage: ${issue['annual_backup_waste']:.2f}/an")
        print(f"  Risque: {issue['risk_level']}")
        print(f"  Action: {issue['recommended_action']}")
```

**Exemple de D√©tection :**

```python
# Exemple 1: Prod sans backup
instance_name = "prod-critical-filestore"
environment = "prod"
capacity_gb = 5120  # 5 TB
num_backups = 0

# D√©tection
issue_type = "NO_BACKUP_PROD"
risk_level = "CRITICAL"
recommendation = "Cr√©er backup policy: daily, r√©tention 30 jours"

print(f"RISQUE CRITIQUE:")
print(f"  Instance production {instance_name} sans backup!")
print(f"  Capacit√©: 5 TB de donn√©es non prot√©g√©es")
print(f"  Action imm√©diate requise: Configurer backup policy")

# Exemple 2: Dev avec 50 backups
instance_name = "dev-test-filestore"
environment = "dev"
capacity_gb = 2048  # 2 TB
num_backups = 50

# Co√ªt
monthly_backup_cost = 2048 * 50 * 0.10  # $10,240/mois
annual_backup_cost = monthly_backup_cost * 12  # $122,880/an

print(f"\nGASPILLAGE BACKUP D√âTECT√â:")
print(f"  Instance dev {instance_name} avec 50 backups!")
print(f"  Co√ªt backup: $10,240/mois ($122,880/an)")
print(f"  Recommandation: Supprimer tous les backups (dev n'a pas besoin de backup)")
print(f"  √âconomie: $122,880/an")
```

---

### Sc√©nario 7 : Legacy Tier (Basic HDD vs Zonal)

**Description :**
Instances Filestore utilisant l'ancien tier **Basic HDD** ($0.20/GB/mois) alors que le nouveau tier **Zonal** ($0.18/GB/mois) offre les m√™mes performances pour 10% moins cher.

**Pourquoi c'est un probl√®me :**
- Zonal tier lanc√© en 2023 comme remplacement de Basic HDD
- **Identiques** en performance et disponibilit√© (m√™me SLA 99.9%)
- Zonal est 10% moins cher
- Migration support√©e sans downtime
- Aucune raison de rester sur Basic HDD

**Caract√©ristiques Identiques :**
```python
BASIC_HDD_VS_ZONAL = {
    'basic_hdd': {
        'price_per_gb': 0.20,
        'throughput_per_tb': 100,  # MB/s
        'iops_per_tb': 5000,
        'sla': 0.999,
        'availability': 'Single zone'
    },
    'zonal': {
        'price_per_gb': 0.18,
        'throughput_per_tb': 100,  # MB/s (identique)
        'iops_per_tb': 5000,       # (identique)
        'sla': 0.999,              # (identique)
        'availability': 'Single zone'  # (identique)
    }
}
```

**D√©tection :**

```python
from google.cloud import filestore_v1
from typing import List, Dict
import logging

logger = logging.getLogger(__name__)


def detect_filestore_legacy_tier(
    project_id: str
) -> List[Dict]:
    """
    D√©tecte les instances Filestore utilisant le tier legacy Basic HDD
    au lieu du tier Zonal moderne.

    Returns:
        Liste d'instances avec √©conomies potentielles de migration
    """
    filestore_client = filestore_v1.CloudFilestoreManagerClient()

    legacy_instances = []

    parent = f"projects/{project_id}/locations/-"

    try:
        instances = filestore_client.list_instances(parent=parent)
    except Exception as e:
        logger.error(f"Erreur r√©cup√©ration instances: {e}")
        return []

    for instance in instances:
        tier = instance.tier.name

        # D√©tecte tier legacy
        if tier in ['BASIC_HDD', 'STANDARD']:  # STANDARD = ancien nom de BASIC_HDD
            instance_name = instance.name.split('/')[-1]
            zone = instance.name.split('/')[3]
            capacity_gb = instance.file_shares[0].capacity_gb

            # Calcul √©conomies
            basic_hdd_price = 0.20
            zonal_price = 0.18

            current_monthly_cost = capacity_gb * basic_hdd_price
            zonal_monthly_cost = capacity_gb * zonal_price

            monthly_savings = current_monthly_cost - zonal_monthly_cost
            annual_savings = monthly_savings * 12
            savings_percent = (monthly_savings / current_monthly_cost) * 100

            legacy_instances.append({
                'instance_name': instance_name,
                'zone': zone,
                'current_tier': tier,
                'recommended_tier': 'ZONAL',
                'capacity_gb': capacity_gb,
                'current_monthly_cost': round(current_monthly_cost, 2),
                'zonal_monthly_cost': round(zonal_monthly_cost, 2),
                'monthly_savings': round(monthly_savings, 2),
                'annual_savings': round(annual_savings, 2),
                'savings_percent': round(savings_percent, 1),
                'migration_downtime': '0 seconds',
                'created_at': instance.create_time.isoformat() if instance.create_time else None
            })

    # Trie par annual savings d√©croissant
    legacy_instances.sort(key=lambda x: x['annual_savings'], reverse=True)

    return legacy_instances


def generate_migration_script(
    legacy_instances: List[Dict]
) -> str:
    """
    G√©n√®re un script de migration Basic HDD ‚Üí Zonal.
    """
    script = "#!/bin/bash\n"
    script += "# Script de migration Filestore: Basic HDD ‚Üí Zonal\n"
    script += "# Migration sans downtime, √©conomie imm√©diate de 10%\n\n"

    total_annual_savings = sum(i['annual_savings'] for i in legacy_instances)
    script += f"# √âconomie totale annuelle: ${total_annual_savings:,.2f}\n\n"

    for instance in legacy_instances:
        script += f"# Instance: {instance['instance_name']} ({instance['capacity_gb']} GB)\n"
        script += f"# √âconomie: ${instance['monthly_savings']:.2f}/mois (${instance['annual_savings']:.2f}/an)\n"
        script += f"echo 'Migration de {instance['instance_name']}...'\n"
        script += f"gcloud filestore instances update {instance['instance_name']} \\\n"
        script += f"    --zone={instance['zone']} \\\n"
        script += f"    --tier=ZONAL \\\n"
        script += f"    --project=YOUR_PROJECT_ID\n\n"

        script += f"# V√©rifier status\n"
        script += f"gcloud filestore instances describe {instance['instance_name']} \\\n"
        script += f"    --zone={instance['zone']} \\\n"
        script += f"    --format='value(tier)'\n\n"

    script += "echo 'Migration termin√©e!'\n"

    return script


# Exemple d'utilisation
if __name__ == "__main__":
    legacy_instances = detect_filestore_legacy_tier(
        project_id="my-gcp-project"
    )

    print(f"Trouv√© {len(legacy_instances)} instances sur tier legacy (Basic HDD)")

    total_annual_savings = sum(i['annual_savings'] for i in legacy_instances)
    print(f"√âconomie potentielle totale: ${total_annual_savings:,.2f}/an")

    for instance in legacy_instances:
        print(f"\nInstance: {instance['instance_name']}")
        print(f"  Tier actuel: {instance['current_tier']}")
        print(f"  Capacit√©: {instance['capacity_gb']} GB")
        print(f"  √âconomie: ${instance['monthly_savings']:.2f}/mois (${instance['annual_savings']:.2f}/an)")
        print(f"  Migration: 0 downtime")

    # G√©n√®re script de migration
    migration_script = generate_migration_script(legacy_instances)
    with open('filestore_migrate_to_zonal.sh', 'w') as f:
        f.write(migration_script)

    print("\nScript de migration g√©n√©r√©: filestore_migrate_to_zonal.sh")
    print("Ex√©cution recommand√©e: ./filestore_migrate_to_zonal.sh")
```

**Exemple de D√©tection :**

```python
# Instance 10 TB sur Basic HDD
instance_name = "prod-filestore-legacy"
tier = "BASIC_HDD"
capacity_gb = 10240  # 10 TB

# Calcul √©conomies
basic_hdd_price = 0.20
zonal_price = 0.18

current_cost = 10240 * 0.20  # $2,048/mois
zonal_cost = 10240 * 0.18  # $1,843.20/mois

monthly_savings = 2048 - 1843.20  # $204.80/mois
annual_savings = monthly_savings * 12  # $2,457.60/an
savings_percent = (monthly_savings / current_cost) * 100  # 10%

print(f"TIER LEGACY D√âTECT√â:")
print(f"  Instance {instance_name} sur Basic HDD")
print(f"  Capacit√©: 10 TB")
print(f"  Co√ªt actuel: $2,048/mois")
print(f"  Co√ªt avec Zonal: $1,843/mois")
print(f"  √âconomie: $2,458/an (10%)")
print(f"  Migration: 0 downtime, performances identiques")
print(f"  Recommandation: Migrer vers Zonal imm√©diatement")

# Commande de migration
print(f"\nCommande:")
print(f"gcloud filestore instances update {instance_name} \\")
print(f"    --zone=us-central1-a \\")
print(f"    --tier=ZONAL")
```

---

## Phase 2 : Sc√©narios d'Analyse Avanc√©e

### Sc√©nario 8 : Multi-Share Consolidation Opportunity

**Description :**
Plusieurs instances Filestore **single-share** pourraient √™tre consolid√©es sur une seule instance **Enterprise multi-share** pour r√©duire les co√ªts et simplifier la gestion. Le tier Enterprise supporte jusqu'√† 10 shares par instance.

**Pourquoi c'est un probl√®me :**
- 5 instances Zonal 2 TB = 5 √ó $368/mois = **$1,840/mois**
- 1 instance Enterprise 10 TB = **$6,144/mois** (mais pour 10 TB vs 10 TB)
- **Consolidation pertinente si** : plusieurs petites instances sous-utilis√©es

**Cas d'Usage pour Consolidation :**
```python
CONSOLIDATION_CRITERIA = {
    'min_instances': 3,  # Au moins 3 instances √† consolider
    'max_total_capacity_tb': 10,  # Total ‚â§10 TB (max Enterprise)
    'same_region': True,  # Doivent √™tre dans la m√™me r√©gion
    'similar_workload': True,  # Workloads compatibles (ex: tous dev/staging)
    'avg_utilization': 0.30  # Instances sous-utilis√©es (<30%)
}
```

**D√©tection :**

```python
from google.cloud import filestore_v1
from typing import List, Dict
from collections import defaultdict
import logging

logger = logging.getLogger(__name__)


def detect_filestore_multi_share_consolidation(
    project_id: str,
    min_instances_for_consolidation: int = 3
) -> List[Dict]:
    """
    D√©tecte les opportunit√©s de consolidation multi-share.

    Args:
        project_id: GCP project ID
        min_instances_for_consolidation: Nombre min d'instances pour consolider

    Returns:
        Liste de groupes d'instances candidates √† la consolidation
    """
    filestore_client = filestore_v1.CloudFilestoreManagerClient()

    parent = f"projects/{project_id}/locations/-"

    try:
        instances = list(filestore_client.list_instances(parent=parent))
    except Exception as e:
        logger.error(f"Erreur r√©cup√©ration instances: {e}")
        return []

    # Groupe instances par r√©gion et environnement
    groups = defaultdict(list)

    for instance in instances:
        zone = instance.name.split('/')[3]
        region = zone.rsplit('-', 1)[0]  # us-central1-a ‚Üí us-central1
        tier = instance.tier.name
        labels = dict(instance.labels) if instance.labels else {}
        environment = labels.get('environment', 'unknown')

        # Ignore instances d√©j√† Enterprise multi-share
        if tier == 'ENTERPRISE' and len(instance.file_shares) > 1:
            continue

        # Groupe par region + environment
        group_key = f"{region}_{environment}"

        capacity_gb = instance.file_shares[0].capacity_gb

        groups[group_key].append({
            'instance_name': instance.name.split('/')[-1],
            'zone': zone,
            'region': region,
            'tier': tier,
            'capacity_gb': capacity_gb,
            'environment': environment,
            'labels': labels
        })

    # Analyse chaque groupe pour consolidation
    consolidation_opportunities = []

    for group_key, group_instances in groups.items():
        if len(group_instances) < min_instances_for_consolidation:
            continue

        # V√©rifie si consolidation pertinente
        consolidation_analysis = analyze_consolidation_opportunity(
            instances=group_instances
        )

        if consolidation_analysis['is_consolidation_beneficial']:
            consolidation_opportunities.append(consolidation_analysis)

    # Trie par annual savings d√©croissant
    consolidation_opportunities.sort(key=lambda x: x['annual_savings'], reverse=True)

    return consolidation_opportunities


def analyze_consolidation_opportunity(
    instances: List[Dict]
) -> Dict:
    """
    Analyse si la consolidation est b√©n√©fique pour un groupe d'instances.
    """
    total_capacity_gb = sum(i['capacity_gb'] for i in instances)
    total_capacity_tb = total_capacity_gb / 1024

    # Limites Enterprise: 1-10 TB, max 10 shares
    if total_capacity_tb > 10 or len(instances) > 10:
        return {'is_consolidation_beneficial': False}

    # Calcul co√ªt actuel (assume majoritairement Zonal/Basic HDD)
    tier_pricing = {
        'ZONAL': 0.18,
        'BASIC_HDD': 0.20,
        'BASIC_SSD': 0.30,
        'ENTERPRISE': 0.60
    }

    current_monthly_cost = sum(
        i['capacity_gb'] * tier_pricing.get(i['tier'], 0.20)
        for i in instances
    )

    # Co√ªt avec consolidation Enterprise
    # Arrondir total capacity au TB sup√©rieur
    consolidated_capacity_tb = int((total_capacity_gb + 1023) / 1024)
    consolidated_capacity_gb = consolidated_capacity_tb * 1024

    enterprise_price = 0.60
    consolidated_monthly_cost = consolidated_capacity_gb * enterprise_price

    # V√©rifier si consolidation est b√©n√©fique
    monthly_savings = current_monthly_cost - consolidated_monthly_cost
    annual_savings = monthly_savings * 12

    is_beneficial = monthly_savings > 0

    if not is_beneficial:
        return {'is_consolidation_beneficial': False}

    # B√©n√©fices additionnels (non financiers)
    additional_benefits = [
        f"R√©duction de {len(instances)} instances √† 1 instance (gestion simplifi√©e)",
        "Multi-zone HA (SLA 99.99% vs 99.9%)",
        f"Consolidation de {len(instances)} shares sur 1 instance"
    ]

    return {
        'is_consolidation_beneficial': True,
        'region': instances[0]['region'],
        'environment': instances[0]['environment'],
        'num_instances': len(instances),
        'instance_names': [i['instance_name'] for i in instances],
        'total_current_capacity_gb': total_capacity_gb,
        'consolidated_capacity_gb': consolidated_capacity_gb,
        'current_monthly_cost': round(current_monthly_cost, 2),
        'consolidated_monthly_cost': round(consolidated_monthly_cost, 2),
        'monthly_savings': round(monthly_savings, 2),
        'annual_savings': round(annual_savings, 2),
        'additional_benefits': additional_benefits,
        'recommendation': generate_consolidation_recommendation(instances, consolidated_capacity_tb)
    }


def generate_consolidation_recommendation(
    instances: List[Dict],
    consolidated_capacity_tb: int
) -> str:
    """
    G√©n√®re une recommandation de consolidation.
    """
    region = instances[0]['region']
    environment = instances[0]['environment']

    recommendation = f"""
Consolidation: {len(instances)} instances ‚Üí 1 instance Enterprise multi-share

√âtapes:
1. Cr√©er instance Enterprise {consolidated_capacity_tb} TB avec {len(instances)} shares:
   gcloud filestore instances create consolidated-{environment}-filestore \\
       --zone={region}-a \\
       --tier=ENTERPRISE \\
       --file-share=name="share1",capacity={consolidated_capacity_tb}TB \\
       --network=name="default"

2. Cr√©er shares additionnels (max 10):
   gcloud filestore instances update consolidated-{environment}-filestore \\
       --zone={region}-a \\
       --add-file-share=name="share2",capacity=1TB

3. Migrer donn√©es depuis instances existantes (rsync via NFS)

4. Supprimer anciennes instances
"""

    for instance in instances:
        recommendation += f"   gcloud filestore instances delete {instance['instance_name']} --zone={instance['zone']}\n"

    return recommendation


# Exemple d'utilisation
if __name__ == "__main__":
    opportunities = detect_filestore_multi_share_consolidation(
        project_id="my-gcp-project",
        min_instances_for_consolidation=3
    )

    print(f"Trouv√© {len(opportunities)} opportunit√©s de consolidation")

    total_annual_savings = sum(o['annual_savings'] for o in opportunities)
    print(f"√âconomie totale potentielle: ${total_annual_savings:,.2f}/an")

    for opportunity in opportunities:
        print(f"\nGroupe: {opportunity['region']} - {opportunity['environment']}")
        print(f"  Instances: {opportunity['num_instances']} ({', '.join(opportunity['instance_names'])})")
        print(f"  Capacit√© totale: {opportunity['total_current_capacity_gb']} GB")
        print(f"  Co√ªt actuel: ${opportunity['current_monthly_cost']:.2f}/mois")
        print(f"  Co√ªt consolid√©: ${opportunity['consolidated_monthly_cost']:.2f}/mois")
        print(f"  √âconomie: ${opportunity['monthly_savings']:.2f}/mois (${opportunity['annual_savings']:.2f}/an)")
        print(f"  B√©n√©fices additionnels:")
        for benefit in opportunity['additional_benefits']:
            print(f"    - {benefit}")
```

**Exemple de D√©tection :**

```python
# 4 instances dev dans us-central1
instances = [
    {'name': 'dev-app1', 'tier': 'ZONAL', 'capacity_gb': 2048},  # 2 TB
    {'name': 'dev-app2', 'tier': 'ZONAL', 'capacity_gb': 1536},  # 1.5 TB
    {'name': 'dev-app3', 'tier': 'BASIC_HDD', 'capacity_gb': 2048},  # 2 TB
    {'name': 'dev-app4', 'tier': 'ZONAL', 'capacity_gb': 1536},  # 1.5 TB
]

# Total: 7 TB

# Co√ªt actuel
current_cost = (2048 * 0.18) + (1536 * 0.18) + (2048 * 0.20) + (1536 * 0.18)
# = $368.64 + $276.48 + $409.60 + $276.48 = $1,331.20/mois

# Co√ªt consolid√© (1 instance Enterprise 8 TB pour 4 shares)
consolidated_cost = 8192 * 0.60  # $4,915.20/mois

# Dans ce cas, consolidation N'EST PAS b√©n√©fique
# (Enterprise plus cher)

# MAIS: Si instances sous-utilis√©es √† 30%, on pourrait consolider √† 3 TB total
actual_total_used_gb = 7168 * 0.30  # 2,150 GB
consolidated_optimal_gb = 3072  # 3 TB
consolidated_optimal_cost = 3072 * 0.60  # $1,843.20/mois

monthly_savings = 1331.20 - 1843.20  # -$512/mois (pas b√©n√©fique)

print("Consolidation NON recommand√©e dans ce cas")
print("Raison: Enterprise trop cher pour ce use case")
print("Alternative: Downsize chaque instance individuellement")
```

---

### Sc√©nario 9 : Snapshot Waste (Old Snapshots)

**Description :**
Backups/snapshots Filestore anciens (>90 jours) qui n'ont jamais √©t√© restaur√©s et ne seront probablement jamais utilis√©s. Les snapshots co√ªtent **$0.10/GB/mois** et s'accumulent.

**Pourquoi c'est un probl√®me :**
- Backups rarement nettoy√©s automatiquement
- Co√ªt snapshot = **50% du co√ªt instance** (si ratio pricing)
- 100 backups de 5 TB = **$51,200/mois** de snapshots seuls!
- Compliance n√©cessite r√©tention limit√©e (GDPR: max 90 jours hors cas sp√©ciaux)

**R√®gles de D√©tection :**
```python
SNAPSHOT_WASTE_RULES = {
    'old_never_restored': {
        'age_days': 90,
        'never_restored': True,
        'severity': 'HIGH'
    },
    'excessive_retention': {
        'age_days': 365,
        'severity': 'MEDIUM'
    },
    'orphaned_snapshots': {
        'source_instance_deleted': True,
        'severity': 'HIGH'
    }
}
```

**D√©tection :**

```python
from google.cloud import filestore_v1
from datetime import datetime, timedelta
from typing import List, Dict
import logging

logger = logging.getLogger(__name__)


def detect_filestore_snapshot_waste(
    project_id: str,
    old_snapshot_threshold_days: int = 90
) -> List[Dict]:
    """
    D√©tecte les snapshots/backups Filestore wasteful.

    Args:
        project_id: GCP project ID
        old_snapshot_threshold_days: Age threshold pour "old" (90 jours)

    Returns:
        Liste de snapshots avec co√ªt gaspill√©
    """
    filestore_client = filestore_v1.CloudFilestoreManagerClient()

    wasteful_snapshots = []

    # Liste toutes les r√©gions
    regions = [
        'us-central1', 'us-east1', 'us-west1', 'us-west2',
        'europe-west1', 'europe-west2', 'europe-west3',
        'asia-east1', 'asia-southeast1'
    ]

    for region in regions:
        parent = f"projects/{project_id}/locations/{region}"

        try:
            backups = filestore_client.list_backups(parent=parent)

            for backup in backups:
                backup_analysis = analyze_backup_waste(
                    backup=backup,
                    old_threshold_days=old_snapshot_threshold_days
                )

                if backup_analysis['is_wasteful']:
                    wasteful_snapshots.append(backup_analysis)

        except Exception as e:
            # R√©gion sans backups ou erreur d'acc√®s
            continue

    # Trie par monthly cost d√©croissant
    wasteful_snapshots.sort(key=lambda x: x['monthly_cost'], reverse=True)

    return wasteful_snapshots


def analyze_backup_waste(
    backup: filestore_v1.Backup,
    old_threshold_days: int
) -> Dict:
    """
    Analyse si un backup est wasteful.
    """
    backup_name = backup.name.split('/')[-1]
    region = backup.name.split('/')[3]

    created_at = backup.create_time
    age_days = (datetime.now(created_at.tzinfo) - created_at).days

    # Capacit√© du backup (en GB)
    capacity_gb = backup.capacity_gb

    # Co√ªt mensuel
    backup_price_per_gb = 0.10
    monthly_cost = capacity_gb * backup_price_per_gb
    annual_cost = monthly_cost * 12

    # V√©rifie si source instance existe encore
    source_instance = backup.source_instance
    is_orphaned = False  # TODO: v√©rifier si instance existe

    # D√©tecte waste
    is_wasteful = False
    waste_reason = None
    severity = 'LOW'

    # Raison 1: Backup tr√®s ancien
    if age_days > old_threshold_days:
        is_wasteful = True
        waste_reason = f"Backup ancien ({age_days} jours > {old_threshold_days} threshold)"
        severity = 'HIGH' if age_days > 365 else 'MEDIUM'

    # Raison 2: Source instance supprim√©e (backup orphelin)
    # Note: N√©cessite check additionnel
    # if is_orphaned:
    #     is_wasteful = True
    #     waste_reason = "Backup orphelin (source instance supprim√©e)"
    #     severity = 'HIGH'

    if not is_wasteful:
        return {'is_wasteful': False}

    return {
        'is_wasteful': True,
        'backup_name': backup_name,
        'region': region,
        'capacity_gb': capacity_gb,
        'age_days': age_days,
        'created_at': created_at.isoformat(),
        'source_instance': source_instance.split('/')[-1],
        'monthly_cost': round(monthly_cost, 2),
        'annual_cost': round(annual_cost, 2),
        'waste_reason': waste_reason,
        'severity': severity,
        'recommendation': f"Supprimer backup si non n√©cessaire (√©conomie: ${annual_cost:.2f}/an)"
    }


def generate_snapshot_cleanup_script(
    wasteful_snapshots: List[Dict],
    dry_run: bool = True
) -> str:
    """
    G√©n√®re un script de cleanup des backups wasteful.
    """
    script = "#!/bin/bash\n"
    script += "# Script de cleanup - Backups Filestore anciens\n\n"

    if dry_run:
        script += "# MODE DRY-RUN: Review manual avant suppression!\n\n"

    total_annual_savings = sum(s['annual_cost'] for s in wasteful_snapshots)
    script += f"# √âconomie totale: ${total_annual_savings:,.2f}/an\n\n"

    for snapshot in wasteful_snapshots:
        script += f"# Backup: {snapshot['backup_name']} ({snapshot['capacity_gb']} GB, {snapshot['age_days']} jours)\n"
        script += f"# Raison: {snapshot['waste_reason']}\n"
        script += f"# √âconomie: ${snapshot['annual_cost']:.2f}/an\n"

        if dry_run:
            script += f"echo 'Dry-run: Suppression de {snapshot['backup_name']}'\n"
        else:
            script += f"gcloud filestore backups delete {snapshot['backup_name']} \\\n"
            script += f"    --region={snapshot['region']} \\\n"
            script += f"    --quiet\n"

        script += "\n"

    return script


# Exemple d'utilisation
if __name__ == "__main__":
    wasteful_snapshots = detect_filestore_snapshot_waste(
        project_id="my-gcp-project",
        old_snapshot_threshold_days=90
    )

    print(f"Trouv√© {len(wasteful_snapshots)} backups wasteful")

    total_monthly_waste = sum(s['monthly_cost'] for s in wasteful_snapshots)
    total_annual_waste = sum(s['annual_cost'] for s in wasteful_snapshots)

    print(f"Gaspillage total: ${total_monthly_waste:,.2f}/mois (${total_annual_waste:,.2f}/an)")

    for snapshot in wasteful_snapshots[:10]:  # Top 10
        print(f"\nBackup: {snapshot['backup_name']}")
        print(f"  Age: {snapshot['age_days']} jours")
        print(f"  Capacit√©: {snapshot['capacity_gb']} GB")
        print(f"  Co√ªt: ${snapshot['monthly_cost']:.2f}/mois")
        print(f"  Raison: {snapshot['waste_reason']}")
        print(f"  S√©v√©rit√©: {snapshot['severity']}")

    # G√©n√®re script de cleanup
    cleanup_script = generate_snapshot_cleanup_script(
        wasteful_snapshots=wasteful_snapshots,
        dry_run=True
    )

    with open('filestore_backup_cleanup.sh', 'w') as f:
        f.write(cleanup_script)

    print("\nScript de cleanup g√©n√©r√©: filestore_backup_cleanup.sh")
    print("Review manual recommand√© avant ex√©cution!")
```

**Exemple de D√©tection :**

```python
# Backup 5 TB cr√©√© il y a 2 ans
backup_name = "old-prod-backup-2023"
capacity_gb = 5120  # 5 TB
age_days = 730  # 2 ans
source_instance = "prod-filestore-old"  # Instance peut-√™tre d√©j√† supprim√©e

# Co√ªt
backup_price = 0.10
monthly_cost = 5120 * 0.10  # $512/mois
annual_cost = monthly_cost * 12  # $6,144/an

# Gaspillage sur 2 ans
total_wasted_2_years = monthly_cost * 24  # $12,288

print(f"BACKUP WASTEFUL D√âTECT√â:")
print(f"  Backup {backup_name}")
print(f"  Age: 730 jours (2 ans)")
print(f"  Capacit√©: 5 TB")
print(f"  Co√ªt actuel: $512/mois ($6,144/an)")
print(f"  D√©j√† gaspill√©: $12,288 (sur 2 ans)")
print(f"  Recommandation: Supprimer si non n√©cessaire")
print(f"  √âconomie future: $6,144/an")
```

---

### Sc√©nario 10 : Wrong NFS Protocol (NFSv3 vs v4.1)

**Description :**
Instances Filestore configur√©es avec **NFSv3** alors que **NFSv4.1** offre de meilleures performances et fonctionnalit√©s (file locking, meilleur caching, support ACLs).

**Pourquoi c'est un probl√®me :**
- NFSv4.1 offre **20-30% meilleures performances** sur workloads avec small files
- Meilleur caching c√¥t√© client = moins d'IOPS n√©cessaires = tier inf√©rieur possible
- NFSv3 est legacy protocol (ann√©es 1990)
- Pas de surco√ªt pour NFSv4.1

**B√©n√©fices NFSv4.1 :**
```python
NFSV4_BENEFITS = {
    'performance': '+20-30% throughput sur small files',
    'caching': 'Meilleur client-side caching',
    'security': 'Support Kerberos natif',
    'features': 'File locking, ACLs, delegations',
    'latency': 'Moins de round-trips r√©seau'
}
```

**Note Importante :** GCP ne fournit pas de m√©trique directe pour le protocol NFS utilis√©. La d√©tection se fait via:
1. Analyse des mount options sur les clients
2. Heuristiques bas√©es sur patterns d'IOPS (NFSv3 g√©n√®re plus d'IOPS)

**D√©tection (Heuristique) :**

```python
from google.cloud import filestore_v1
from google.cloud import monitoring_v3
from datetime import datetime, timedelta
from typing import List, Dict
import logging

logger = logging.getLogger(__name__)


def detect_filestore_wrong_nfs_protocol(
    project_id: str,
    lookback_days: int = 14
) -> List[Dict]:
    """
    D√©tecte les instances Filestore probablement utilis√©es avec NFSv3.

    Note: D√©tection heuristique bas√©e sur patterns d'IOPS.
    NFSv3 g√©n√®re typiquement 30-50% plus d'IOPS que NFSv4.1 pour m√™me workload.

    Returns:
        Liste d'instances candidates √† migration NFSv4.1
    """
    filestore_client = filestore_v1.CloudFilestoreManagerClient()
    monitoring_client = monitoring_v3.MetricServiceClient()

    candidates = []

    parent = f"projects/{project_id}/locations/-"

    try:
        instances = filestore_client.list_instances(parent=parent)
    except Exception as e:
        logger.error(f"Erreur r√©cup√©ration instances: {e}")
        return []

    for instance in instances:
        instance_name = instance.name.split('/')[-1]
        zone = instance.name.split('/')[3]

        # Analyse patterns IOPS
        iops_analysis = analyze_iops_pattern_for_nfs_protocol(
            project_id=project_id,
            instance_name=instance_name,
            zone=zone,
            lookback_days=lookback_days
        )

        if not iops_analysis:
            continue

        # Heuristique: High IOPS/MB ratio sugg√®re NFSv3
        if iops_analysis['likely_nfsv3']:
            # Calcule √©conomie potentielle si downgrade tier possible
            savings_analysis = calculate_nfsv4_migration_savings(
                instance=instance,
                current_iops=iops_analysis['avg_iops']
            )

            candidates.append({
                'instance_name': instance_name,
                'zone': zone,
                'tier': instance.tier.name,
                'capacity_gb': instance.file_shares[0].capacity_gb,
                'avg_iops': iops_analysis['avg_iops'],
                'avg_throughput_mb': iops_analysis['avg_throughput_mb'],
                'iops_per_mb_ratio': iops_analysis['iops_per_mb_ratio'],
                'likely_protocol': 'NFSv3',
                'recommended_protocol': 'NFSv4.1',
                'expected_performance_gain': '20-30%',
                'potential_tier_downgrade': savings_analysis['can_downgrade_tier'],
                'annual_savings': savings_analysis['annual_savings'],
                'confidence': iops_analysis['confidence']
            })

    # Trie par annual savings d√©croissant
    candidates.sort(key=lambda x: x['annual_savings'], reverse=True)

    return candidates


def analyze_iops_pattern_for_nfs_protocol(
    project_id: str,
    instance_name: str,
    zone: str,
    lookback_days: int
) -> Dict:
    """
    Analyse le ratio IOPS/throughput pour deviner le protocol NFS.

    NFSv3: High IOPS/MB ratio (metadata operations intensives)
    NFSv4.1: Lower IOPS/MB ratio (better caching)
    """
    monitoring_client = monitoring_v3.MetricServiceClient()
    project_name = f"projects/{project_id}"

    end_time = datetime.utcnow()
    start_time = end_time - timedelta(days=lookback_days)

    interval = monitoring_v3.TimeInterval({
        "end_time": {"seconds": int(end_time.timestamp())},
        "start_time": {"seconds": int(start_time.timestamp())},
    })

    # R√©cup√®re IOPS
    iops_values = query_filestore_iops(
        monitoring_client, project_name, instance_name, zone, interval
    )

    # R√©cup√®re throughput
    throughput_values = query_filestore_throughput(
        monitoring_client, project_name, instance_name, zone, interval
    )

    if not iops_values or not throughput_values:
        return None

    avg_iops = sum(iops_values) / len(iops_values)
    avg_throughput_mb = sum(throughput_values) / len(throughput_values)

    # Ratio IOPS per MB
    if avg_throughput_mb > 0:
        iops_per_mb_ratio = avg_iops / avg_throughput_mb
    else:
        return None

    # Heuristique: NFSv3 g√©n√®re 5-10 IOPS par MB/s (metadata intensive)
    # NFSv4.1 g√©n√®re 2-4 IOPS par MB/s (better caching)
    likely_nfsv3 = iops_per_mb_ratio > 4.5

    confidence = 'MEDIUM' if iops_per_mb_ratio > 6 else 'LOW'

    return {
        'avg_iops': round(avg_iops, 1),
        'avg_throughput_mb': round(avg_throughput_mb, 1),
        'iops_per_mb_ratio': round(iops_per_mb_ratio, 2),
        'likely_nfsv3': likely_nfsv3,
        'confidence': confidence
    }


def query_filestore_iops(
    monitoring_client, project_name, instance_name, zone, interval
) -> List[float]:
    """Query IOPS metrics."""
    # Combine read + write ops
    read_ops = query_metric(
        monitoring_client, project_name, instance_name, zone,
        "file.googleapis.com/nfs/server/read_ops_count", interval
    )
    write_ops = query_metric(
        monitoring_client, project_name, instance_name, zone,
        "file.googleapis.com/nfs/server/write_ops_count", interval
    )

    total_iops = [r + w for r, w in zip(read_ops, write_ops)]
    return total_iops


def query_filestore_throughput(
    monitoring_client, project_name, instance_name, zone, interval
) -> List[float]:
    """Query throughput metrics (MB/s)."""
    read_bytes = query_metric(
        monitoring_client, project_name, instance_name, zone,
        "file.googleapis.com/nfs/server/read_bytes_count", interval
    )
    write_bytes = query_metric(
        monitoring_client, project_name, instance_name, zone,
        "file.googleapis.com/nfs/server/write_bytes_count", interval
    )

    total_throughput_mb = [(r + w) / (1024 * 1024) for r, w in zip(read_bytes, write_bytes)]
    return total_throughput_mb


def query_metric(
    monitoring_client, project_name, instance_name, zone, metric_type, interval
) -> List[float]:
    """Helper to query a metric."""
    filter_str = (
        f'resource.type = "filestore_instance" '
        f'AND resource.labels.instance_name = "{instance_name}" '
        f'AND resource.labels.zone = "{zone}" '
        f'AND metric.type = "{metric_type}"'
    )

    aggregation = monitoring_v3.Aggregation({
        "alignment_period": {"seconds": 3600},
        "per_series_aligner": monitoring_v3.Aggregation.Aligner.ALIGN_RATE,
    })

    try:
        results = monitoring_client.list_time_series(
            request={
                "name": project_name,
                "filter": filter_str,
                "interval": interval,
                "aggregation": aggregation,
            }
        )

        values = []
        for result in results:
            for point in result.points:
                values.append(point.value.double_value)

        return values

    except Exception as e:
        logger.error(f"Erreur query metric: {e}")
        return []


def calculate_nfsv4_migration_savings(
    instance: filestore_v1.Instance,
    current_iops: float
) -> Dict:
    """
    Calcule les √©conomies potentielles avec NFSv4.1.

    NFSv4.1 r√©duit IOPS de 30%, peut permettre downgrade tier.
    """
    tier = instance.tier.name
    capacity_gb = instance.file_shares[0].capacity_gb

    # √âconomie directe: 0 (pas de co√ªt additionnel pour protocol)
    # √âconomie indirecte: Si IOPS r√©duits suffisamment, downgrade tier possible

    can_downgrade = False
    annual_savings = 0

    # Exemple: Basic SSD ‚Üí Zonal si IOPS requirement r√©duit
    if tier == 'BASIC_SSD':
        # Basic SSD: 8000 IOPS/TB
        # Zonal: 5000 IOPS/TB

        capacity_tb = capacity_gb / 1024
        zonal_iops_capacity = capacity_tb * 5000

        # Avec NFSv4.1, IOPS r√©duits de 30%
        expected_iops_with_v4 = current_iops * 0.70

        if expected_iops_with_v4 < zonal_iops_capacity:
            can_downgrade = True

            # Calcul √©conomies
            ssd_cost = capacity_gb * 0.30 * 12
            zonal_cost = capacity_gb * 0.18 * 12
            annual_savings = ssd_cost - zonal_cost

    return {
        'can_downgrade_tier': can_downgrade,
        'annual_savings': round(annual_savings, 2)
    }


# Exemple d'utilisation
if __name__ == "__main__":
    candidates = detect_filestore_wrong_nfs_protocol(
        project_id="my-gcp-project",
        lookback_days=14
    )

    print(f"Trouv√© {len(candidates)} instances probablement sur NFSv3")

    total_annual_savings = sum(c['annual_savings'] for c in candidates)
    print(f"√âconomie potentielle totale: ${total_annual_savings:,.2f}/an")

    for candidate in candidates:
        print(f"\nInstance: {candidate['instance_name']}")
        print(f"  Tier: {candidate['tier']}")
        print(f"  IOPS moyen: {candidate['avg_iops']:.1f}")
        print(f"  Throughput: {candidate['avg_throughput_mb']:.1f} MB/s")
        print(f"  Ratio IOPS/MB: {candidate['iops_per_mb_ratio']:.2f}")
        print(f"  Protocol probable: {candidate['likely_protocol']}")
        print(f"  Recommandation: Migrer vers {candidate['recommended_protocol']}")
        print(f"  Gain performance: {candidate['expected_performance_gain']}")

        if candidate['potential_tier_downgrade']:
            print(f"  Downgrade tier possible: Basic SSD ‚Üí Zonal")
            print(f"  √âconomie: ${candidate['annual_savings']:,.2f}/an")

        print(f"  Confiance: {candidate['confidence']}")
```

**Exemple de D√©tection :**

```python
# Instance Basic SSD avec high IOPS/MB ratio
instance_name = "app-filestore-ssd"
tier = "BASIC_SSD"
capacity_gb = 5120  # 5 TB
avg_iops = 15000  # IOPS √©lev√©s
avg_throughput_mb = 200  # MB/s

# Ratio IOPS/MB
iops_per_mb_ratio = 15000 / 200  # 75 IOPS par MB/s

# Heuristique: Ratio > 6 sugg√®re NFSv3
likely_nfsv3 = iops_per_mb_ratio > 6  # True (75 >> 6)

# Avec NFSv4.1, IOPS attendus
expected_iops_v4 = 15000 * 0.70  # 10,500 IOPS (30% r√©duction)

# Zonal capacity
capacity_tb = 5
zonal_iops_capacity = 5 * 5000  # 25,000 IOPS

# Downgrade possible?
can_downgrade = expected_iops_v4 < zonal_iops_capacity  # True (10,500 < 25,000)

# √âconomies
ssd_annual_cost = 5120 * 0.30 * 12  # $18,432/an
zonal_annual_cost = 5120 * 0.18 * 12  # $11,059/an
annual_savings = 18432 - 11059  # $7,373/an

print(f"NFS PROTOCOL ISSUE D√âTECT√â:")
print(f"  Instance {instance_name}")
print(f"  Ratio IOPS/MB: 75 (tr√®s √©lev√© = probablement NFSv3)")
print(f"  Recommandation:")
print(f"    1. Migrer clients vers NFSv4.1 (mount option vers=4.1)")
print(f"    2. IOPS attendus: 10,500 (vs 15,000 actuels)")
print(f"    3. Downgrade tier: Basic SSD ‚Üí Zonal")
print(f"    4. √âconomie: $7,373/an")
print(f"  Confiance: MEDIUM (bas√© sur heuristique)")
```

---

## Protocole de Test Complet

### Tests Unitaires (pytest)

```python
# tests/test_filestore_detection.py

import pytest
from unittest.mock import Mock, patch
from datetime import datetime, timedelta
from detect_waste import (
    detect_filestore_underutilized,
    detect_filestore_wrong_tier,
    detect_filestore_idle,
    detect_filestore_overprovisioned,
    detect_filestore_untagged,
    detect_filestore_no_backup_policy,
    detect_filestore_legacy_tier,
    detect_filestore_multi_share_consolidation,
    detect_filestore_snapshot_waste,
    detect_filestore_wrong_nfs_protocol
)


class TestFilestoreUnderutilized:
    """Tests pour Sc√©nario 1: Instances sous-utilis√©es."""

    @patch('detect_waste.filestore_v1.CloudFilestoreManagerClient')
    @patch('detect_waste.monitoring_v3.MetricServiceClient')
    def test_detect_underutilized_basic(self, mock_monitoring, mock_filestore):
        """Test d√©tection instance 20% utilis√©e."""
        # Mock instance 10 TB
        mock_instance = Mock()
        mock_instance.name = "projects/test/locations/us-central1-a/instances/test-fs"
        mock_instance.tier.name = "ZONAL"
        mock_instance.file_shares = [Mock(capacity_gb=10240)]
        mock_instance.labels = {}

        mock_filestore.return_value.list_instances.return_value = [mock_instance]

        # Mock m√©triques: 20% utilization
        mock_monitoring.return_value.list_time_series.return_value = [
            Mock(points=[Mock(value=Mock(double_value=20.0))])
        ]

        # Ex√©cute d√©tection
        results = detect_filestore_underutilized(
            project_id="test-project",
            utilization_threshold=0.30,
            lookback_days=14
        )

        # Assertions
        assert len(results) == 1
        assert results[0]['instance_name'] == 'test-fs'
        assert results[0]['utilization_percent'] < 30
        assert results[0]['annual_waste'] > 0
        assert results[0]['confidence'] in ['CRITICAL', 'HIGH', 'MEDIUM', 'LOW']

    def test_calculate_optimal_capacity(self):
        """Test calcul capacit√© optimale."""
        from detect_waste import calculate_optimal_capacity

        # Test 1: Small instance
        optimal = calculate_optimal_capacity(500, tier='ZONAL')
        assert optimal == 1024  # Min capacity

        # Test 2: Normal instance
        optimal = calculate_optimal_capacity(1500, tier='ZONAL')
        assert optimal == 2048  # 1500 * 1.30 = 1950, arrondi √† 2048

        # Test 3: Basic SSD min capacity
        optimal = calculate_optimal_capacity(2000, tier='BASIC_SSD')
        assert optimal == 2560  # Min capacity Basic SSD


class TestFilestoreWrongTier:
    """Tests pour Sc√©nario 2: Wrong tier."""

    @patch('detect_waste.filestore_v1.CloudFilestoreManagerClient')
    def test_detect_enterprise_for_dev(self, mock_filestore):
        """Test d√©tection Enterprise pour dev."""
        # Mock instance Enterprise avec label dev
        mock_instance = Mock()
        mock_instance.name = "projects/test/locations/us-central1-a/instances/dev-fs"
        mock_instance.tier.name = "ENTERPRISE"
        mock_instance.file_shares = [Mock(capacity_gb=5120)]
        mock_instance.labels = {'environment': 'development'}

        mock_filestore.return_value.list_instances.return_value = [mock_instance]

        # Ex√©cute d√©tection
        results = detect_filestore_wrong_tier(
            project_id="test-project",
            lookback_days=14
        )

        # Assertions
        assert len(results) == 1
        assert results[0]['tier'] == 'ENTERPRISE'
        assert results[0]['recommended_tier'] == 'ZONAL'
        assert 'development' in results[0]['reason'].lower()
        assert results[0]['annual_waste'] > 20000  # ~$25K/an


class TestFilestoreIdle:
    """Tests pour Sc√©nario 3: Instances idle."""

    @patch('detect_waste.filestore_v1.CloudFilestoreManagerClient')
    @patch('detect_waste.monitoring_v3.MetricServiceClient')
    def test_detect_idle_instance(self, mock_monitoring, mock_filestore):
        """Test d√©tection instance 0 connections."""
        # Mock instance
        mock_instance = Mock()
        mock_instance.name = "projects/test/locations/us-central1-a/instances/idle-fs"
        mock_instance.tier.name = "BASIC_HDD"
        mock_instance.file_shares = [Mock(capacity_gb=5120)]
        mock_instance.create_time = datetime.utcnow() - timedelta(days=90)

        mock_filestore.return_value.list_instances.return_value = [mock_instance]

        # Mock m√©triques: 0 connections, 0 IOPS
        mock_monitoring.return_value.list_time_series.return_value = [
            Mock(points=[Mock(value=Mock(double_value=0.0))])
        ]

        # Ex√©cute d√©tection
        results = detect_filestore_idle(
            project_id="test-project",
            lookback_days=30,
            max_connections=0,
            max_total_iops=10
        )

        # Assertions
        assert len(results) == 1
        assert results[0]['avg_connections'] == 0
        assert results[0]['avg_total_iops'] <= 10
        assert results[0]['confidence'] in ['CRITICAL', 'HIGH']


class TestFilestoreOverprovisioned:
    """Tests pour Sc√©nario 4: Overprovisioned."""

    def test_calculate_overprovisioning_waste(self):
        """Test calcul waste pour instance 5% utilis√©e."""
        from detect_waste import calculate_overprovisioning_waste

        # Mock instance 20 TB utilis√©e √† 5%
        mock_instance = Mock()
        mock_instance.tier.name = "BASIC_HDD"
        mock_instance.file_shares = [Mock(capacity_gb=20480)]

        waste = calculate_overprovisioning_waste(
            instance=mock_instance,
            avg_utilization=0.05,
            max_utilization=0.07
        )

        # Assertions
        assert waste['used_capacity_gb'] == 1024  # 5% de 20 TB
        assert waste['recommended_capacity_gb'] < 2560  # Much smaller
        assert waste['waste_percent'] > 80  # >80% waste


class TestFilestoreUntagged:
    """Tests pour Sc√©nario 5: Untagged."""

    @patch('detect_waste.filestore_v1.CloudFilestoreManagerClient')
    def test_detect_untagged_instance(self, mock_filestore):
        """Test d√©tection instance sans labels."""
        # Mock instance sans labels
        mock_instance = Mock()
        mock_instance.name = "projects/test/locations/us-central1-a/instances/unlabeled-fs"
        mock_instance.tier.name = "ENTERPRISE"
        mock_instance.file_shares = [Mock(capacity_gb=8192)]
        mock_instance.labels = {}  # Aucun label

        mock_filestore.return_value.list_instances.return_value = [mock_instance]

        # Ex√©cute d√©tection
        results = detect_filestore_untagged(
            project_id="test-project",
            required_labels=['environment', 'team', 'owner']
        )

        # Assertions
        assert len(results) == 1
        assert len(results[0]['missing_labels']) == 3
        assert results[0]['risk_level'] == 'CRITICAL'  # High cost + missing critical labels


class TestFilestoreLegacyTier:
    """Tests pour Sc√©nario 7: Legacy tier."""

    @patch('detect_waste.filestore_v1.CloudFilestoreManagerClient')
    def test_detect_basic_hdd_instance(self, mock_filestore):
        """Test d√©tection instance Basic HDD."""
        # Mock instance Basic HDD
        mock_instance = Mock()
        mock_instance.name = "projects/test/locations/us-central1-a/instances/legacy-fs"
        mock_instance.tier.name = "BASIC_HDD"
        mock_instance.file_shares = [Mock(capacity_gb=10240)]
        mock_instance.create_time = datetime.utcnow() - timedelta(days=365)

        mock_filestore.return_value.list_instances.return_value = [mock_instance]

        # Ex√©cute d√©tection
        results = detect_filestore_legacy_tier(project_id="test-project")

        # Assertions
        assert len(results) == 1
        assert results[0]['current_tier'] in ['BASIC_HDD', 'STANDARD']
        assert results[0]['recommended_tier'] == 'ZONAL'
        assert results[0]['savings_percent'] == 10.0  # Exactly 10%
        assert results[0]['annual_savings'] > 2000  # ~$2,458/an


# Run tests
if __name__ == "__main__":
    pytest.main([__file__, '-v', '--cov=detect_waste', '--cov-report=html'])
```

### Tests d'Int√©gration (bash)

```bash
#!/bin/bash
# integration_tests_filestore.sh
# Tests d'int√©gration end-to-end pour d√©tection Filestore

set -e

PROJECT_ID="cloudwaste-test-project"
ZONE="us-central1-a"
REGION="us-central1"

echo "========================================"
echo "Filestore Waste Detection - Integration Tests"
echo "========================================"

# Cleanup function
cleanup() {
    echo "Cleanup: Suppression des ressources de test..."

    # Supprimer instances
    for instance in test-underutilized test-idle test-wrong-tier test-legacy; do
        gcloud filestore instances delete $instance \
            --zone=$ZONE \
            --project=$PROJECT_ID \
            --quiet 2>/dev/null || true
    done

    echo "Cleanup termin√©"
}

trap cleanup EXIT

# Test 1: Instance Sous-Utilis√©e
echo "\n=== Test 1: Instance Sous-Utilis√©e ==="
echo "Cr√©ation instance 5 TB Zonal..."
gcloud filestore instances create test-underutilized \
    --zone=$ZONE \
    --tier=ZONAL \
    --file-share=name="share1",capacity=5TB \
    --network=name="default" \
    --project=$PROJECT_ID

# Monter et √©crire seulement 500 GB (10% utilization)
echo "Simulation: √âcriture 500 GB (10% de 5 TB)..."
# TODO: Monter NFS et √©crire donn√©es

sleep 1800  # 30 min pour m√©triques

echo "Ex√©cution detector..."
python3 - <<EOF
from detect_waste import detect_filestore_underutilized

results = detect_filestore_underutilized(
    project_id="$PROJECT_ID",
    utilization_threshold=0.30,
    lookback_days=1
)

assert any(r['instance_name'] == 'test-underutilized' for r in results), "Instance non d√©tect√©e"
print("‚úì Test 1 PASSED")
EOF

# Test 2: Instance Idle
echo "\n=== Test 2: Instance Idle ==="
echo "Cr√©ation instance 2 TB sans montage (idle)..."
gcloud filestore instances create test-idle \
    --zone=$ZONE \
    --tier=ZONAL \
    --file-share=name="idle_share",capacity=2TB \
    --network=name="default" \
    --project=$PROJECT_ID

sleep 1800  # 30 min pour m√©triques

python3 - <<EOF
from detect_waste import detect_filestore_idle

results = detect_filestore_idle(
    project_id="$PROJECT_ID",
    lookback_days=1,
    max_connections=0,
    max_total_iops=10
)

assert any(r['instance_name'] == 'test-idle' for r in results), "Instance idle non d√©tect√©e"
print("‚úì Test 2 PASSED")
EOF

# Test 3: Wrong Tier (Enterprise pour dev)
echo "\n=== Test 3: Wrong Tier ==="
echo "Cr√©ation instance Enterprise avec label dev..."
gcloud filestore instances create test-wrong-tier \
    --zone=$ZONE \
    --tier=ENTERPRISE \
    --file-share=name="dev_share",capacity=2TB \
    --network=name="default" \
    --labels=environment=development \
    --project=$PROJECT_ID

sleep 60

python3 - <<EOF
from detect_waste import detect_filestore_wrong_tier

results = detect_filestore_wrong_tier(
    project_id="$PROJECT_ID",
    lookback_days=1
)

matching = [r for r in results if r['instance_name'] == 'test-wrong-tier']
assert len(matching) > 0, "Wrong tier non d√©tect√©"
assert matching[0]['recommended_tier'] == 'ZONAL', "Recommandation incorrecte"
print("‚úì Test 3 PASSED")
EOF

# Test 4: Legacy Tier
echo "\n=== Test 4: Legacy Tier ==="
echo "Cr√©ation instance Basic HDD..."
gcloud filestore instances create test-legacy \
    --zone=$ZONE \
    --tier=BASIC_HDD \
    --file-share=name="legacy_share",capacity=3TB \
    --network=name="default" \
    --project=$PROJECT_ID

sleep 60

python3 - <<EOF
from detect_waste import detect_filestore_legacy_tier

results = detect_filestore_legacy_tier(project_id="$PROJECT_ID")

matching = [r for r in results if r['instance_name'] == 'test-legacy']
assert len(matching) > 0, "Legacy tier non d√©tect√©"
assert matching[0]['recommended_tier'] == 'ZONAL', "Recommandation incorrecte"
assert matching[0]['savings_percent'] == 10.0, "Savings percent incorrect"
print("‚úì Test 4 PASSED")
EOF

echo "\n========================================"
echo "Tous les tests d'int√©gration PASSED ‚úì"
echo "========================================"
```

---

## R√©f√©rences et Ressources

### Documentation Officielle GCP

1. **Cloud Filestore Documentation**
   - https://cloud.google.com/filestore/docs
   - https://cloud.google.com/filestore/docs/service-tiers

2. **Pricing**
   - https://cloud.google.com/filestore/pricing
   - Backup pricing: https://cloud.google.com/filestore/docs/backups

3. **Cloud Monitoring Metrics**
   - https://cloud.google.com/filestore/docs/monitoring
   - Metrics list: https://cloud.google.com/monitoring/api/metrics_gcp#gcp-file

4. **Migration Guides**
   - Tier migration: https://cloud.google.com/filestore/docs/upgrading-instances
   - NFSv4.1: https://cloud.google.com/filestore/docs/mounting-file-shares

### APIs et SDKs

**Python Client Libraries:**
```bash
pip install google-cloud-filestore
pip install google-cloud-monitoring
```

**Code examples:**
```python
from google.cloud import filestore_v1
from google.cloud import monitoring_v3

# Filestore client
filestore_client = filestore_v1.CloudFilestoreManagerClient()

# Monitoring client
monitoring_client = monitoring_v3.MetricServiceClient()
```

### gcloud Commands

**List instances:**
```bash
gcloud filestore instances list \
    --project=PROJECT_ID \
    --format="table(name,tier,capacityGb,state)"
```

**Describe instance:**
```bash
gcloud filestore instances describe INSTANCE_NAME \
    --zone=ZONE \
    --project=PROJECT_ID
```

**Update tier:**
```bash
gcloud filestore instances update INSTANCE_NAME \
    --zone=ZONE \
    --tier=ZONAL \
    --project=PROJECT_ID
```

**Update capacity:**
```bash
gcloud filestore instances update INSTANCE_NAME \
    --zone=ZONE \
    --file-share=name=SHARE_NAME,capacity=3TB \
    --project=PROJECT_ID
```

**Create backup:**
```bash
gcloud filestore backups create BACKUP_NAME \
    --instance=INSTANCE_NAME \
    --zone=ZONE \
    --region=REGION \
    --project=PROJECT_ID
```

**List backups:**
```bash
gcloud filestore backups list \
    --region=REGION \
    --project=PROJECT_ID
```

**Delete backup:**
```bash
gcloud filestore backups delete BACKUP_NAME \
    --region=REGION \
    --project=PROJECT_ID
```

**Add labels:**
```bash
gcloud filestore instances update INSTANCE_NAME \
    --zone=ZONE \
    --update-labels=environment=prod,team=backend \
    --project=PROJECT_ID
```

### IAM Permissions Requises

**Minimum permissions (read-only pour scanning):**
```json
{
  "permissions": [
    "file.instances.list",
    "file.instances.get",
    "file.backups.list",
    "file.backups.get",
    "monitoring.timeSeries.list"
  ]
}
```

**Custom role pour CloudWaste:**
```bash
gcloud iam roles create cloudwaste_filestore_scanner \
    --project=PROJECT_ID \
    --title="CloudWaste Filestore Scanner" \
    --description="Read-only access for waste detection" \
    --permissions=file.instances.list,file.instances.get,file.backups.list,file.backups.get,monitoring.timeSeries.list \
    --stage=GA
```

### Cloud Monitoring Metrics

**M√©triques cl√©s:**

| Metric | Type | Description |
|--------|------|-------------|
| `file.googleapis.com/nfs/server/used_bytes` | Gauge | Bytes utilis√©s |
| `file.googleapis.com/nfs/server/used_bytes_percent` | Gauge | % utilisation |
| `file.googleapis.com/nfs/server/free_bytes` | Gauge | Bytes disponibles |
| `file.googleapis.com/nfs/server/read_ops_count` | Counter | Read operations |
| `file.googleapis.com/nfs/server/write_ops_count` | Counter | Write operations |
| `file.googleapis.com/nfs/server/read_bytes_count` | Counter | Bytes lus |
| `file.googleapis.com/nfs/server/write_bytes_count` | Counter | Bytes √©crits |
| `file.googleapis.com/nfs/server/connections` | Gauge | Connexions actives |
| `file.googleapis.com/nfs/server/procedure_count` | Counter | NFS operations par type |

**Query example (gcloud):**
```bash
gcloud monitoring time-series list \
    --filter='resource.type="filestore_instance" AND resource.labels.instance_name="INSTANCE_NAME" AND metric.type="file.googleapis.com/nfs/server/used_bytes_percent"' \
    --project=PROJECT_ID \
    --format=json
```

### Best Practices

**1. Tagging Strategy:**
```python
RECOMMENDED_LABELS = {
    'environment': 'prod|staging|dev|test',
    'team': 'backend|frontend|data|ml',
    'application': 'app-name',
    'cost-center': 'cc-12345',
    'owner': 'email@example.com',
    'backup-required': 'true|false'
}
```

**2. Backup Policy:**
```python
BACKUP_POLICIES = {
    'prod': {
        'schedule': '0 2 * * *',  # Daily at 2 AM
        'retention_days': 30
    },
    'staging': {
        'schedule': '0 2 * * 0',  # Weekly on Sunday
        'retention_days': 14
    },
    'dev': {
        'schedule': None,  # No automatic backup
        'retention_days': 7
    }
}
```

**3. Capacity Planning:**
```python
# Provision with 20-30% buffer
def calculate_capacity_with_buffer(
    current_usage_gb: int,
    growth_buffer: float = 0.30
) -> int:
    """Calculate optimal capacity with growth buffer."""
    target_capacity_gb = int(current_usage_gb * (1 + growth_buffer))

    # Round up to 256 GB increments
    optimal_capacity_gb = ((target_capacity_gb + 255) // 256) * 256

    return optimal_capacity_gb
```

**4. Tier Selection Matrix:**
```python
TIER_SELECTION = {
    'workload': {
        'light_io': 'ZONAL',           # <100 IOPS/TB
        'moderate_io': 'BASIC_SSD',    # 100-500 IOPS/TB
        'heavy_io': 'HIGH_SCALE_SSD',  # >500 IOPS/TB
        'ha_required': 'ENTERPRISE'     # Multi-zone HA
    },
    'environment': {
        'prod': ['ZONAL', 'BASIC_SSD', 'ENTERPRISE'],
        'staging': ['ZONAL', 'BASIC_HDD'],
        'dev': ['ZONAL'],
        'test': ['ZONAL']
    }
}
```

### Exemples de Co√ªts R√©els

**Exemple 1: Instance production typique**
```python
# Instance 10 TB Zonal, 30% utilis√©e, 30 daily backups
provisioned_capacity_gb = 10240
used_capacity_gb = 3072  # 30%
tier_price = 0.18
num_backups = 30

# Co√ªts
instance_cost = provisioned_capacity_gb * 0.18  # $1,843.20/mois
backup_cost = used_capacity_gb * 30 * 0.10  # $9,216/mois
total_cost = instance_cost + backup_cost  # $11,059.20/mois ($132,710/an)

# Optimisation
optimal_capacity_gb = 4096  # 3 TB * 1.30 buffer = 4 TB
optimal_backups = 30  # OK pour prod
optimal_instance_cost = 4096 * 0.18  # $737.28/mois
optimal_backup_cost = 3072 * 30 * 0.10  # $9,216/mois (inchang√©)
optimal_total = optimal_instance_cost + optimal_backup_cost  # $9,953.28/mois

# √âconomie
annual_savings = (total_cost - optimal_total) * 12  # $13,270/an
```

**Exemple 2: Dev environment overprovisioned**
```python
# Instance 5 TB Enterprise pour dev, 10% utilis√©e, 10 backups
provisioned_capacity_gb = 5120
used_capacity_gb = 512  # 10%
tier_price = 0.60
num_backups = 10

# Co√ªts
instance_cost = 5120 * 0.60  # $3,072/mois
backup_cost = 512 * 10 * 0.10  # $512/mois
total_cost = instance_cost + backup_cost  # $3,584/mois ($43,008/an)

# Optimisation
# 1. Downsize: 5 TB ‚Üí 1 TB (512 GB * 1.30 = 666 GB ‚Üí 1 TB)
# 2. Downgrade: Enterprise ‚Üí Zonal
# 3. Remove backups (dev doesn't need backup)
optimal_capacity_gb = 1024
optimal_tier_price = 0.18
optimal_backups = 0

optimal_instance_cost = 1024 * 0.18  # $184.32/mois
optimal_backup_cost = 0
optimal_total = 184.32  # $184.32/mois

# √âconomie
annual_savings = (total_cost - optimal_total) * 12  # $40,798/an (95% r√©duction!)
```

### Troubleshooting

**1. M√©triques non disponibles:**
```python
# Les m√©triques prennent 5-10 minutes √† appara√Ætre
# Attendre au moins 1 heure avant d√©tection
```

**2. Migration tier failed:**
```bash
# V√©rifier si migration support√©e
# Enterprise ‚Üí Zonal: NON support√©
# Basic HDD ‚Üí Zonal: Support√©
gcloud filestore instances update INSTANCE_NAME \
    --zone=ZONE \
    --tier=ZONAL  # Peut √©chouer si downgrade non support√©
```

**3. Backup deletion failed:**
```bash
# V√©rifier si backup utilis√© pour restore en cours
gcloud filestore operations list --region=REGION
```

---

**Document complet: 3,678 lignes**
**Couverture: 100% des sc√©narios de gaspillage Filestore**
**Impact estim√©: $10,000 - $60,000/an par organisation**

